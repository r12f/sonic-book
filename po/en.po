msgid ""
msgstr ""
"Project-Id-Version: SONiC入门指南\n"
"POT-Creation-Date: \n"
"PO-Revision-Date: 2023-06-25 20:04-0700\n"
"Last-Translator: r12f <r12f.code@gmail.com>\n"
"Language-Team: English\n"
"Language: en\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"

#: src/SUMMARY.md:3
msgid "SONiC入门指南"
msgstr "Getting Started with SONiC"

#: src/SUMMARY.md:4
msgid "安装"
msgstr "Installation"

#: src/SUMMARY.md:5
msgid "虚拟测试环境"
msgstr "Hello World! Virtually!"

#: src/SUMMARY.md:6
msgid "常用命令 (WIP)"
msgstr "Frequently used commands (WIP)"

#: src/SUMMARY.md:7
msgid "核心组件简介"
msgstr "Core Components Intro"

#: src/SUMMARY.md:8
msgid "Redis数据库"
msgstr "Redis Database"

#: src/SUMMARY.md:9
msgid "服务与工作流简介"
msgstr "Service and Workflow Intro"

#: src/SUMMARY.md:10
msgid "核心容器"
msgstr "Core Containers"

#: src/SUMMARY.md:11
msgid "SAI"
msgstr "SAI"

#: src/SUMMARY.md:12
msgid "开发上手指南"
msgstr "Dev Guide"

#: src/SUMMARY.md:13
msgid "代码仓库"
msgstr "Code repo"

#: src/SUMMARY.md:14
msgid "编译"
msgstr "Compile"

#: src/SUMMARY.md:15
msgid "测试 (WIP)"
msgstr "Test (WIP)"

#: src/SUMMARY.md:16
msgid "调试 (WIP)"
msgstr "Debugging (WIP)"

#: src/SUMMARY.md:17
msgid "SAI调试 (WIP)"
msgstr "SAI debugging (WIP)"

#: src/SUMMARY.md:18
msgid "通信机制"
msgstr "Communication"

#: src/SUMMARY.md:19
msgid "与内核的通信"
msgstr "Communication with Kernel"

#: src/SUMMARY.md:20
msgid "命令行调用"
msgstr "Command line call"

#: src/SUMMARY.md:21
msgid "Netlink"
msgstr "Netlink"

#: src/SUMMARY.md:22
msgid "基于Redis的通信"
msgstr "Redis-based Communication"

#: src/SUMMARY.md:23
msgid "Redis封装"
msgstr "Redis Ops"

#: src/SUMMARY.md:24
msgid "通信层"
msgstr "Communication layer"

#: src/SUMMARY.md:25
msgid "基于ZMQ的通信 (WIP)"
msgstr "ZMQ-based Communication (WIP)"

#: src/SUMMARY.md:26
msgid "服务层封装 - Orch"
msgstr "Service Layer - Orch"

#: src/SUMMARY.md:27
msgid "事件分发和错误处理"
msgstr "Event Dispatching and Error Handling"

#: src/SUMMARY.md:28
#, fuzzy
msgid "核心组件解析"
msgstr "Core Components"

#: src/SUMMARY.md:29
msgid "Syncd与SAI"
msgstr ""

#: src/SUMMARY.md:30
msgid "BGP"
msgstr ""

#: src/SUMMARY.md:31
msgid "BGP命令实现"
msgstr "BGP CLI Commands"

#: src/SUMMARY.md:32
msgid "BGP路由变更下发"
msgstr "BGP route update"

#: src/SUMMARY.md:33
msgid "启动流程 (WIP)"
msgstr "Boot (WIP)"

#: src/SUMMARY.md:34
msgid "冷启动 (WIP)"
msgstr "Cold boot (WIP)"

#: src/SUMMARY.md:35
msgid "快速启动 (WIP)"
msgstr "Fast boot (WIP)"

#: src/SUMMARY.md:36
msgid "热启动 (WIP)"
msgstr "Warm boot (WIP)"

#: src/1-intro.md:1
msgid "# SONiC入门指南"
msgstr "# Getted Started with SONiC"

#: src/1-intro.md:3
msgid "## 为什么要做SONiC"
msgstr "## Why SONiC"

#: src/1-intro.md:5
msgid ""
"我们知道交换机内部都有一套可大可小的操作系统，用于配置和查看交换机的状态。但"
"是，从1986年第一台交换机面世开始，虽然各个厂商都在进行着相关的开发，到现在为"
"止种类也相当的多，但是依然存在一些问题，比如："
msgstr ""
"We know that there is a operating system running inside every switches, no "
"matter if it is complicated or not. It is used for configuring and checking "
"the status of the switch. Since the first switch came out in 1986, with "
"various manufacturers have been doing related development, nowadays, we have "
"a lot of different OSes. However, there are still some problems, for example:"

#: src/1-intro.md:7
msgid ""
"1. 生态封闭，不开源，主要是为了支持自家的硬件，无法很好的兼容其他厂商的设备\n"
"2. 支持的场景很有限，难以使用同一套系统去支撑大规模的数据中心中复杂多变的场"
"景\n"
"3. 升级可能会导致网络中断，难以实现无缝升级，这对于云提供商来说有时候是致命"
"的\n"
"4. 设备功能升级缓慢，难以很好的支持快速的产品迭代"
msgstr ""
"1. Closed ecosystem and not open-sourced, primarily used for supporting its "
"own hardware and not very compatible with other manufacturers' devices.\n"
"2. Some OSes only supports limited scenarios, making it challenging to "
"support a variety of complex scenarios in large-scale data centers.\n"
"3. Upgrades may lead to network interruptions, making seamless upgrades "
"difficult, which can often be a deal breaker for cloud providers.\n"
"4. New features or bug fixes are coming out slowly, hard to suppoprt rapid "
"development in production."

#: src/1-intro.md:12
msgid ""
"所以，微软在2016年发起了开源项目SONiC，希望能够通过开源的方式，让SONiC能够成"
"为一个通用的网络操作系统，从而解决上面的问题。而且，由于微软在Azure中大范围的"
"使用SONiC，也保证了SONiC的实现确实能够承受大规模的生产环境的考验，这也是SONiC"
"的一个优势。"
msgstr ""
"Therefore, Microsoft initiated an open-source project in 2016 - SONiC, so "
"that we can solve the problems above by building universal network operating "
"system (NOS). Moreover, Microsoft is widely using SONiC in Azure, which "
"ensures SONiC can indeed support large scale cloud environments. This is "
"also an advantage of SONiC."

#: src/1-intro.md:14
msgid "## 主体架构"
msgstr "## Architecture"

#: src/1-intro.md:16
msgid ""
"SONiC是微软开发的基于debian的开源的网络操作系统，它的设计核心思想有三个："
msgstr ""
"SONiC is an open-source network operating system (NOS) based on Debian and "
"developed by Microsoft. It is designed with three core principles:"

#: src/1-intro.md:18
msgid ""
"1. **硬件和软件解耦**：通过SAI（Switch Abstraction Interface）将硬件的操作抽"
"象出来，从而使得SONiC能够支持多种硬件平台。这一层抽象层由SONiC定义，由各个厂"
"商来实现。\n"
"2. **使用docker容器将软件微服务化**：SONiC上的主要功能都被拆分成了一个个的"
"docker容器，和传统的网络操作系统不同，升级系统可以只对其中的某个容器进行升"
"级，而不需要整体升级和重启，这样就可以很方便的进行升级和维护，支持快速的开发"
"和迭代。\n"
"3. **使用redis作为中心数据库对服务进行解耦**：绝大部分服务的配置和状态最后都"
"被存储到中心的redis数据库中，这样不仅使得所有的服务可以很轻松的进行协作（数据"
"存储和pubsub），也可以让我们很方便的在上面开发工具，使用统一的方法对各个服务"
"进行操作和查询，而不用担心状态丢失和协议兼容问题，最后还可以很方便的进行状态"
"的备份和恢复。"
msgstr ""
"1. **Hardware and software decoupling**: Abstract the hardware layer via SAI "
"(Switch Abstraction Interface), which enables SONiC to support multiple "
"hardware platforms. This layer of abstraction is defined by SONiC and "
"implemented by various manufacturers.\n"
"2. **Containerized service management**: The features of SONiC are broken "
"down into individual Docker containers. Unlike traditional network operating "
"systems, system upgrades can be done on a single container without requiring "
"a full upgrade and restart. This makes upgrades and maintenance convenient, "
"which helps rapid development and iteration.\n"
"3. **Redis as the central database for service decoupling**: The "
"configuration and status of most services are stored in the central Redis "
"database. This not only allows all services to easily collaborate with each "
"other (data storage and communication) but also simplifies the tool "
"development by providing a unified way to query and configure various "
"services without worrying about state loss and protocol compatibility "
"issues. Finally, it is very convenient to back up and restore the configs as "
"well."

#: src/1-intro.md:22
msgid ""
"这让SONiC拥有了非常开放的生态（[Community][SONiCLanding]，[Workgroups]"
"[SONiCWG]，[Devices][SONiCDevices]），总体而言，SONiC的架构如下图所示："
msgstr ""
"This gives SONiC a very open ecosystem ([Community][SONiCLanding], "
"[Workgroups][SONiCWG], [Devices][SONiCDevices]). Overall, the architecture "
"of SONiC is as shown in the following diagram:"

#: src/1-intro.md:26 src/2-core-components-intro.md:17
msgid "_(Source: [SONiC Wiki - Architecture][SONiCArch])_"
msgstr "_(Source: [SONiC Wiki - Architecture][SONiCArch])_"

#: src/1-intro.md:28
msgid ""
"当然，这样的设计也有一些缺点，比如：对磁盘的占用会变大，不过，现在一点点存储"
"空间并不是什么很大的问题，而且这个问题也都可以通过一些方法来解决。"
msgstr ""
"Of course, such design also has some disadvantages, such as: the disk usage "
"will increase. However, nowadays storage space is usually not a big issue, "
"and it can also be solved or eased by various ways."

#: src/1-intro.md:30
msgid "## 发展方向"
msgstr "## Future Direction"

#: src/1-intro.md:32
msgid ""
"虽然交换机已经发展很多很多年了，但是随着现在云的发展，对网络的要求也越来越"
"高，不管是直观的需求，比如更大的带宽，更大的容量，还是最新的研究，比如，带内"
"计算，端网融合等等，都对交换机的发展提出了更高的要求和挑战，也促使着各大厂商"
"和研究机构不断的进行创新。SONiC也一样，随着时间的发展，需求一点没有减少。"
msgstr ""
"Although switches have been developed for many years, with the development "
"of the cloud nowadays, the demands of network becomes higher and higher. No "
"matter it's intuitive features, such as larger bandwidth and larger "
"capacity, or the latest research, such as in-band computing, end-network "
"fusion, etc., all result in higher requirements and challenges to the "
"development of switches, as well as continuous innovations from "
"manufacturers and research institutions. The same goes for SONiC. As time "
"goes on, the number of feature request has not decreased at all."

#: src/1-intro.md:34
msgid ""
"关于SONiC的发展方向，我们可以在它的[Roadmap][SONiCPlanning]中看到。如果大家对"
"最新的动态感兴趣，也可以关注它的Workshop，比如，最近的[OCP Global Summit "
"2022 - SONiC Workshop][SONiCWorkshop]。这里就不展开了。"
msgstr ""
"Regarding the future direction of SONiC, we can see it in its [Roadmap]"
"[SONiCPlanning]. If you are interested in the latest updates, we can also "
"follow its Workshop, such as the recent [OCP Global Summit 2022 - SONiC "
"Workshop][SONiCWorkshop]."

#: src/1-intro.md:36
msgid "## 感谢"
msgstr "## Acknowledgement"

#: src/1-intro.md:38
msgid "感谢以下朋友的帮助和贡献，没有你们也就没有这本入门指南！"
msgstr ""
"Huge thanks to the following friends for their help and contributions! "
"Without you there would be no way to get this book done!"

#: src/1-intro.md:40
msgid "[@bingwang-ms](https://github.com/bingwang-ms)"
msgstr "[@bingwang-ms](https://github.com/bingwang-ms)"

#: src/1-intro.md:42
msgid "# License"
msgstr "# License"

#: src/1-intro.md:44
msgid ""
"本书使用 [署名-非商业性使用-相同方式共享（CC BY-NC-SA）4.0 许可协议](https://"
"creativecommons.org/licenses/by-nc-sa/4.0/)。"
msgstr ""
"This book uses the [CC BY-NC-SA 4.0 License Agreement](https://"
"creativecommons.org/licenses/by-nc-sa/4.0/)."

#: src/1-intro.md:46 src/1-1-install.md:164
#: src/1-2-hello-world-virtually.md:187 src/1-3-command-cheatsheet.md:184
#: src/2-core-components-intro.md:19 src/2-1-database.md:74
#: src/2-2-services-intro.md:74 src/2-3-key-containers.md:179
#: src/2-4-sai-intro.md:164 src/3-1-code-repos.md:131 src/3-2-compile.md:202
#: src/4-communications.md:19 src/4-1-1-exec.md:36 src/4-1-2-netlink.md:70
#: src/4-2-1-redis-wrappers.md:33 src/4-2-2-redis-messaging-layer.md:318
#: src/4-4-orch-layer.md:34 src/4-5-event-polling-and-error-handling.md:119
#: src/5-1-syncd-and-sai.md:813 src/5-2-bgp.md:32
#: src/5-2-1-bgp-command-impl.md:87 src/5-2-2-bgp-route-update-workflow.md:1460
msgid "# 参考资料"
msgstr "# References"

#: src/1-intro.md:48
msgid ""
"1. [SONiC Wiki - Architecture][SONiCArch]\n"
"2. [SONiC Wiki - Roadmap Planning][SONiCPlanning]\n"
"3. [SONiC Landing Page][SONiCLanding]\n"
"4. [SONiC Workgroups][SONiCWG]\n"
"5. [SONiC Supported Devices and Platforms][SONiCDevices]\n"
"6. [SONiC User Manual][SONiCManual]\n"
"7. [OCP Global Summit 2022 - SONiC Workshop][SONiCWorkshop]"
msgstr ""
"1. [SONiC Wiki - Architecture][SONiCArch]\n"
"2. [SONiC Wiki - Roadmap Planning][SONiCPlanning]\n"
"3. [SONiC Landing Page][SONiCLanding]\n"
"4. [SONiC Workgroups][SONiCWG]\n"
"5. [SONiC Supported Devices and Platforms][SONiCDevices]\n"
"6. [SONiC User Manual][SONiCManual]\n"
"7. [OCP Global Summit 2022 - SONiC Workshop][SONiCWorkshop]"

#: src/1-1-install.md:1
msgid "# 安装"
msgstr "# Installation"

#: src/1-1-install.md:3
msgid ""
"如果你自己就拥有一台交换机，或者想购买一台交换机，在上面安装SONiC，那么请认真"
"阅读这一小节，否则可以自行跳过。:D"
msgstr ""
"If you own a switch yourself or plan to buy one, then install SONiC on it, "
"please read this section carefully; otherwise, feel free skip it. :D"

#: src/1-1-install.md:5
msgid "## 交换机选择和SONiC安装"
msgstr "## Switch Selection and SONiC Installation"

#: src/1-1-install.md:7
msgid ""
"首先，请确认你的交换机是否支持SONiC，SONiC目前支持的交换机型号可以在[这里]"
"[SONiCDevices]找到，如果你的交换机型号不在列表中，那么就需要联系厂商，看看是"
"否有支持SONiC的计划。有很多交换机是不支持SONiC的，比如："
msgstr ""
"First, please confirm whether your switch supports SONiC or not. The switch "
"models currently supported by SONiC can be found [here][SONiCDevices]. If "
"your switch model is not on the list, you will need to contact the "
"manufacturer to see if there is a plan to support SONiC. Many switches do "
"not have SONiC support yet, for example:"

#: src/1-1-install.md:9
msgid ""
"1. 普通针对家用的交换机，这些交换机的硬件配置都比较低（即便支持的带宽很高，比"
"如[MikroTik CRS504-4XQ-IN][MikroTik100G]，虽然它支持100GbE网络，但是它只有"
"16MB的Flash存储和64MB的RAM，所以基本只能跑它自己的RouterOS了）。\n"
"2. 有些虽然是数据中心用的交换机，但是可能由于型号老旧，厂商并没有计划支持"
"SONiC。"
msgstr ""
"1. Typical home switches: They usually have relatively low hardware specs "
"(even though some of them have high bandwidth support, such as [MikroTik "
"CRS504-4XQ-IN][MikroTik100G], it supports 100GbE network, but it only has "
"16MB of Flash storage and 64MB of RAM, so basically, it can only run its own "
"NOS - RouterOS).\n"
"2. Some data center switches might be outdated models, and manufacturers "
"have no plans to support SONiC."

#: src/1-1-install.md:12
msgid ""
"对于安装过程，由于每一家厂商的交换机设计不同，其底层接口各有差别，所以，其安"
"装方法也都有所差别，这些差别主要集中在两个地方："
msgstr ""
"Regarding the installation process, because different switches from "
"different manufacturers might have very different design, the installation "
"process can also be different. These differences show up in two major areas:"

#: src/1-1-install.md:14
msgid ""
"1. 每个厂商都会有自己的[SONiC Build][SONiCDevices]，还有的厂商会在SONiC的基础"
"之上进行扩展开发，为自己的交换机支持更多的功能，比如：[Dell Enterprise SONiC]"
"[DellSonic]，[EdgeCore Enterprise SONiC][EdgeCoreSONiC]，所以需要根据自己的交"
"换机选择对应的版本。\n"
"2. 每个厂商的交换机也会支持不同的安装方式，有一些是直接使用USB对ROM进行"
"Flash，有一些是通过ONIE进行安装，这也需要根据自己的交换机来进行配置。"
msgstr ""
"1. Every manufacturer will have their own [SONiC Builds][SONiCDevices], and "
"some manufacturers will create their own version of SONiC on top of the "
"original one, supporting more functions for their switches. For example:"
"[Dell Enterprise SONiC][DellSonic], [EdgeCore Enterprise SONiC][EdgeCore "
"SONiC]. Therefore, we need to choose the right version carefully according "
"your switch.\n"
"2. Different switch might also have different installation process. Some of "
"them are directly installed from USB by flashing the ROM, and some of them "
"using ONIE. This also needs to be checked according to your switch."

#: src/1-1-install.md:17
msgid ""
"所以，虽然安装方法各有差别，但是总体而言，安装的步骤都是差不多的。请联系自己"
"的厂商，获取对应的安装文档，然后按照文档进行安装即可。"
msgstr ""
"So, although the installation process may vary, in general, the installation "
"steps are similar. Please contact your vendor for the detailed installation "
"documentation, and then follow it through."

#: src/1-1-install.md:19
msgid "## 配置交换机"
msgstr "## Configure the switch"

#: src/1-1-install.md:21
msgid ""
"安装好之后，我们需要进行一些基础设置，部分设置是通用的，我们在这里简单总结一"
"下。"
msgstr ""
"Once SONiC is installed, we need to do some basic settings, some of which "
"are common, no matter which type of switch you are using, and we'll briefly "
"summarize them here."

#: src/1-1-install.md:23
msgid "### 设置admin密码"
msgstr "### Set admin password"

#: src/1-1-install.md:25
msgid "默认SONiC的账号密码是admin:YourPaSsWoRd，使用默认密码显然不安全："
msgstr ""
"The default SONiC account and password is admin:YourPaSsWoRd, using the "
"default password is obviously not secure. So, please remember to change it:"

#: src/1-1-install.md:27
msgid ""
"```bash\n"
"sudo passwd admin\n"
"```"
msgstr ""
"```bash\n"
"sudo passwd admin\n"
"```"

#: src/1-1-install.md:31
msgid "### 设置风扇转速"
msgstr "### Set fan speed"

#: src/1-1-install.md:33
msgid ""
"数据中心用的交换机风扇声音都特别的大！比如，我用的交换机是Arista 7050QX-32S，"
"上面有4个风扇，最高能到每分钟17000转，放在车库中，高频的啸叫即便是在二楼隔着3"
"面墙还是能听得到，所以如果你是在家使用的话，建议对其进行一些设置，将转速调"
"低。"
msgstr ""
"The switch fans in the data center are exceptionally loud! For example, the "
"switch I use is Arista 7050QX-32S, which has 4 fans on it and can go up to "
"17,000 rpm. Although I put it in my garage, the high frequency whine can "
"still be heard even on the second floor behind 3 walls, so if you are using "
"it at home, it is recommended to change some settings to turn down the speed."

#: src/1-1-install.md:35
msgid ""
"可惜，[由于SONiC并没有cli对风扇转速的规则进行控制][SONiCThermal]，所以我们需"
"要通过手动修改pmon容器中的配置文件的方式来进行设置。"
msgstr ""
"Unfortunately, [since SONiC does not have a cli to control the rules for fan "
"speed][SONiCThermal], we need to set it by manually modifying the "
"configuration file in the pmon container."

#: src/1-1-install.md:37
msgid ""
"```bash\n"
"# Enter pmon container\n"
"sudo docker exec -it pmon bash\n"
"\n"
"# Use pwmconfig to detect all pwm fans and create configuration file. The "
"configuration file will be created at /etc/fancontrol.\n"
"pwmconfig\n"
"\n"
"# Start fancontrol and make sure it works. If it doesn't work, you can run "
"fancontrol directly to see what's wrong.\n"
"VERBOSE=1 /etc/init.d/fancontrol start\n"
"VERBOSE=1 /etc/init.d/fancontrol status\n"
"\n"
"# Exit pmon container\n"
"exit\n"
"\n"
"# Copy the configuration file from the container to the host, so that the "
"configuration will not be lost after reboot.\n"
"# This command needs to know what is the model of your switch, for example, "
"the command I need to run here is as follows. If your switch model is "
"different, please modify it yourself.\n"
"sudo docker cp pmon:/etc/fancontrol /usr/share/sonic/device/x86_64-"
"arista_7050_qx32s/fancontrol\n"
"```"
msgstr ""
"```bash\n"
"# Enter pmon container\n"
"sudo docker exec -it pmon bash\n"
"\n"
"# Use pwmconfig to detect all pwm fans and create configuration file. The "
"configuration file will be created at /etc/fancontrol.\n"
"pwmconfig\n"
"\n"
"# Start fancontrol and make sure it works. If it doesn't work, you can run "
"fancontrol directly to see what's wrong.\n"
"VERBOSE=1 /etc/init.d/fancontrol start\n"
"VERBOSE=1 /etc/init.d/fancontrol status\n"
"\n"
"# Exit pmon container\n"
"exit\n"
"\n"
"# Copy the configuration file from the container to the host, so that the "
"configuration will not be lost after reboot.\n"
"# This command needs to know what is the model of your switch, for example, "
"the command I need to run here is as follows. If your switch model is "
"different, please modify it yourself.\n"
"sudo docker cp pmon:/etc/fancontrol /usr/share/sonic/device/x86_64-"
"arista_7050_qx32s/fancontrol\n"
"```"

#: src/1-1-install.md:56
msgid "### 设置交换机Management Port IP"
msgstr "### Set management port IP"

#: src/1-1-install.md:58
msgid ""
"一般的数据中心用的交换机都提供了Serial Console连接的方式，但是其速度实在是太"
"慢了，所以我们在安装完成之后，都会尽快的把Management Port给设置好，然后通过"
"SSH的方式来进行管理。"
msgstr ""
"The data center switches usually provides Serial Console connection, but its "
"speed is too slow, so it is better for us to have the Management Port set up "
"as soon as possible, then we can use SSH to manage it, which is way faster."

#: src/1-1-install.md:60
msgid ""
"一般来说，management port的设备名是eth0，所以我们可以通过SONiC的配置命令来进"
"行设置："
msgstr ""
"Generally, the device name of the management port is eth0, so we can set it "
"by using the following SONiC command:"

#: src/1-1-install.md:62
msgid ""
"```bash\n"
"# sudo config interface ip add eth0 <ip-cidr> <gateway>\n"
"# IPv4\n"
"sudo config interface ip add eth0 192.168.1.2/24 192.168.1.1\n"
"\n"
"# IPv6\n"
"sudo config interface ip add eth0 2001::8/64 2001::1\n"
"```"
msgstr ""
"```bash\n"
"# sudo config interface ip add eth0 <ip-cidr> <gateway>\n"
"# IPv4\n"
"sudo config interface ip add eth0 192.168.1.2/24 192.168.1.1\n"
"\n"
"# IPv6\n"
"sudo config interface ip add eth0 2001::8/64 2001::1\n"
"```"

#: src/1-1-install.md:71
msgid "### 创建网络配置"
msgstr "### Create network configuration"

#: src/1-1-install.md:73
msgid ""
"新安装完的SONiC交换机会有一个默认的网络配置，这个配置有很多问题，比如对于"
"10.0.0.0的IP的使用，如下："
msgstr ""
"The newly installed SONiC switch will have a default network configuration, "
"which has many problems, such as for the use of the 10.0.0.0 IP, as follows:"

#: src/1-1-install.md:75 src/1-2-hello-world-virtually.md:118
msgid ""
"```bash\n"
"admin@sonic:~$ show ip interfaces\n"
"Interface    Master    IPv4 address/mask    Admin/Oper    BGP Neighbor    "
"Neighbor IP\n"
"-----------  --------  -------------------  ------------  --------------  "
"-------------\n"
"Ethernet0              10.0.0.0/31          up/up         ARISTA01T2      "
"10.0.0.1\n"
"Ethernet4              10.0.0.2/31          up/up         ARISTA02T2      "
"10.0.0.3\n"
"Ethernet8              10.0.0.4/31          up/up         ARISTA03T2      "
"10.0.0.5\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ show ip interfaces\n"
"Interface    Master    IPv4 address/mask    Admin/Oper    BGP Neighbor    "
"Neighbor IP\n"
"-----------  --------  -------------------  ------------  --------------  "
"-------------\n"
"Ethernet0              10.0.0.0/31          up/up         ARISTA01T2      "
"10.0.0.1\n"
"Ethernet4              10.0.0.2/31          up/up         ARISTA02T2      "
"10.0.0.3\n"
"Ethernet8              10.0.0.4/31          up/up         ARISTA03T2      "
"10.0.0.5\n"
"```"

#: src/1-1-install.md:84
msgid ""
"所以我们需要创建一个新的网络配置，然后将我们使用的Port都放入到这个网络配置"
"中。这里简单的方法就是创建一个VLAN，使用VLAN Routing："
msgstr ""
"So we need to update the network configuration of the ports we like to use. "
"The easiest way is to create a VLAN, then put all the ports into the VLAN, "
"so we can use VLAN Routing to route the packets:"

#: src/1-1-install.md:86
msgid ""
"```bash\n"
"# Create untagged vlan\n"
"sudo config vlan add 2\n"
"\n"
"# Add IP to vlan\n"
"sudo config interface ip add Vlan2 10.2.0.0/24\n"
"\n"
"# Remove all default IP settings\n"
"show ip interfaces | tail -n +3 | grep Ethernet | awk '{print \"sudo config "
"interface ip remove\", $1, $2}' > oobe.sh; chmod +x oobe.sh; ./oobe.sh\n"
"\n"
"# Add all ports to the new vlan\n"
"show interfaces status | tail -n +3 | grep Ethernet | awk '{print \"sudo "
"config vlan member add -u 2\", $1}' > oobe.sh; chmod +x oobe.sh; ./oobe.sh\n"
"\n"
"# Enable proxy arp, so switch can respond to arp requests from hosts\n"
"sudo config vlan proxy_arp 2 enabled\n"
"\n"
"# Save config, so it will be persistent after reboot\n"
"sudo config save -y\n"
"```"
msgstr ""
"```bash\n"
"# Create untagged vlan\n"
"sudo config vlan add 2\n"
"\n"
"# Add IP to vlan\n"
"sudo config interface ip add Vlan2 10.2.0.0/24\n"
"\n"
"# Remove all default IP settings\n"
"show ip interfaces | tail -n +3 | grep Ethernet | awk '{print \"sudo config "
"interface ip remove\", $1, $2}' > oobe.sh; chmod +x oobe.sh; ./oobe.sh\n"
"\n"
"# Add all ports to the new vlan\n"
"show interfaces status | tail -n +3 | grep Ethernet | awk '{print \"sudo "
"config vlan member add -u 2\", $1}' > oobe.sh; chmod +x oobe.sh; ./oobe.sh\n"
"\n"
"# Enable proxy arp, so switch can respond to arp requests from hosts\n"
"sudo config vlan proxy_arp 2 enabled\n"
"\n"
"# Save config, so it will be persistent after reboot\n"
"sudo config save -y\n"
"```"

#: src/1-1-install.md:106
msgid "这样就完成了，我们可以通过show vlan brief来查看一下："
msgstr "That's it! Now, we can take a look at it by running `show vlan brief`:"

#: src/1-1-install.md:108
msgid ""
"```\n"
"admin@sonic:~$ show vlan brief\n"
"+-----------+--------------+-------------+----------------+-------------"
"+-----------------------+\n"
"|   VLAN ID | IP Address   | Ports       | Port Tagging   | Proxy ARP   | "
"DHCP Helper Address   |\n"
"+===========+==============+=============+================+=============+=======================+\n"
"|         2 | 10.2.0.0/24  | Ethernet0   | untagged       | enabled     "
"|                       |\n"
"...\n"
"|           |              | Ethernet124 | untagged       |             "
"|                       |\n"
"+-----------+--------------+-------------+----------------+-------------"
"+-----------------------+\n"
"```"
msgstr ""
"```\n"
"admin@sonic:~$ show vlan brief\n"
"+-----------+--------------+-------------+----------------+-------------"
"+-----------------------+\n"
"|   VLAN ID | IP Address   | Ports       | Port Tagging   | Proxy ARP   | "
"DHCP Helper Address   |\n"
"+===========+==============+=============+================+=============+=======================+\n"
"|         2 | 10.2.0.0/24  | Ethernet0   | untagged       | enabled     "
"|                       |\n"
"...\n"
"|           |              | Ethernet124 | untagged       |             "
"|                       |\n"
"+-----------+--------------+-------------+----------------+-------------"
"+-----------------------+\n"
"```"

#: src/1-1-install.md:119
msgid "### 配置主机"
msgstr "### Configure the host"

#: src/1-1-install.md:121
msgid ""
"如果你家里只有一台主机使用多网口连接交换机进行测试，那么我们还需要在主机上进"
"行一些配置，以保证流量会通过网卡，流经交换机，否则，请跳过这一步。"
msgstr ""
"If you only have one machine and try to connect a dual-port NIC to your "
"switch for testing, then we will also need some changes on the machine to "
"ensure that traffic will go through the NIC and switch, otherwise, feel free "
"to skip this step."

#: src/1-1-install.md:123
msgid ""
"这里网上的攻略很多，比如使用iptables中的DNAT和SNAT创建一个虚拟地址，但是过程"
"非常繁琐，经过一些实验，我发现最简单的办法就是将其中一个网口移动到一个新的网"
"络命名空间中，就可以了，即便使用的是同一个网段的IP，也不会有问题。"
msgstr ""
"There are many guidances on the internet here, such as using iptable DNAT "
"and SNAT rules to create a virtual address, but the process is very tedious. "
"After some experiments, I found that the easiest way is to simply move one "
"of the nic into a new network namespace, even if you are using the IP of the "
"same network segment."

#: src/1-1-install.md:125
msgid ""
"比如，我家使用的是Netronome Agilio CX 2x40GbE，它会创建两个interface："
"`enp66s0np0`和`enp66s0np1`，我们这里可以将`enp66s0np1`移动到一个新的网络命名"
"空间中，再配置好ip地址就可以了："
msgstr ""
"For example, I uses Netronome Agilio CX 2x40GbE, which creates two "
"interfaces: `enp66s0np0` and `enp66s0np1`. With the following commands, we "
"can move `enp66s0np1` to a new network namespace and give it a ip address:"

#: src/1-1-install.md:127
msgid ""
"```bash\n"
"# Create a new network namespace\n"
"sudo ip netns add toy-ns-1\n"
"\n"
"# Move the interface to the new namespace\n"
"sudo ip link set enp66s0np1 netns toy-ns-1\n"
"\n"
"# Setting up IP and default routes\n"
"sudo ip netns exec toy-ns-1 ip addr add 10.2.0.11/24 dev enp66s0np1\n"
"sudo ip netns exec toy-ns-1 ip link set enp66s0np1 up\n"
"sudo ip netns exec toy-ns-1 ip route add default via 10.2.0.1\n"
"```"
msgstr ""
"```bash\n"
"# Create a new network namespace\n"
"sudo ip netns add toy-ns-1\n"
"\n"
"# Move the interface to the new namespace\n"
"sudo ip link set enp66s0np1 netns toy-ns-1\n"
"\n"
"# Setting up IP and default routes\n"
"sudo ip netns exec toy-ns-1 ip addr add 10.2.0.11/24 dev enp66s0np1\n"
"sudo ip netns exec toy-ns-1 ip link set enp66s0np1 up\n"
"sudo ip netns exec toy-ns-1 ip route add default via 10.2.0.1\n"
"```"

#: src/1-1-install.md:140
msgid "这样就可以了，我们可以通过iperf来测试一下，并在交换机上进行确认："
msgstr ""
"That's it! Now, we can now test our setup with iperf and confirm the traffic "
"on switch:"

#: src/1-1-install.md:142
msgid ""
"```bash\n"
"# On the host (enp66s0np0 has ip 10.2.0.10 assigned)\n"
"$ iperf -s --bind 10.2.0.10\n"
"\n"
"# Test within the new network namespace\n"
"$ sudo ip netns exec toy-ns-1 iperf -c 10.2.0.10 -i 1 -P 16\n"
"------------------------------------------------------------\n"
"Client connecting to 10.2.0.10, TCP port 5001\n"
"TCP window size: 85.0 KByte (default)\n"
"------------------------------------------------------------\n"
"...\n"
"[SUM] 0.0000-10.0301 sec  30.7 GBytes  26.3 Gbits/sec\n"
"[ CT] final connect times (min/avg/max/stdev) = 0.288/0.465/0.647/0.095 ms "
"(tot/err) = 16/0\n"
"\n"
"# Confirm on switch\n"
"admin@sonic:~$ show interfaces counters\n"
"      IFACE    STATE       RX_OK        RX_BPS    RX_UTIL    RX_ERR    "
"RX_DRP    RX_OVR       TX_OK        TX_BPS    TX_UTIL    TX_ERR    TX_DRP    "
"TX_OVR\n"
"-----------  -------  ----------  ------------  ---------  --------  "
"--------  --------  ----------  ------------  ---------  --------  --------  "
"--------\n"
"  Ethernet4        U   2,580,140  6190.34 KB/s      0.12%         0     "
"3,783         0  51,263,535  2086.64 MB/s     41.73%         0         "
"0         0\n"
" Ethernet12        U  51,261,888  2086.79 MB/s     41.74%         0         "
"1         0   2,580,317  6191.00 KB/s      0.12%         0         0         "
"0\n"
"```"
msgstr ""
"```bash\n"
"# On the host (enp66s0np0 has ip 10.2.0.10 assigned)\n"
"$ iperf -s --bind 10.2.0.10\n"
"\n"
"# Test within the new network namespace\n"
"$ sudo ip netns exec toy-ns-1 iperf -c 10.2.0.10 -i 1 -P 16\n"
"------------------------------------------------------------\n"
"Client connecting to 10.2.0.10, TCP port 5001\n"
"TCP window size: 85.0 KByte (default)\n"
"------------------------------------------------------------\n"
"...\n"
"[SUM] 0.0000-10.0301 sec  30.7 GBytes  26.3 Gbits/sec\n"
"[ CT] final connect times (min/avg/max/stdev) = 0.288/0.465/0.647/0.095 ms "
"(tot/err) = 16/0\n"
"\n"
"# Confirm on switch\n"
"admin@sonic:~$ show interfaces counters\n"
"      IFACE    STATE       RX_OK        RX_BPS    RX_UTIL    RX_ERR    "
"RX_DRP    RX_OVR       TX_OK        TX_BPS    TX_UTIL    TX_ERR    TX_DRP    "
"TX_OVR\n"
"-----------  -------  ----------  ------------  ---------  --------  "
"--------  --------  ----------  ------------  ---------  --------  --------  "
"--------\n"
"  Ethernet4        U   2,580,140  6190.34 KB/s      0.12%         0     "
"3,783         0  51,263,535  2086.64 MB/s     41.73%         0         "
"0         0\n"
" Ethernet12        U  51,261,888  2086.79 MB/s     41.74%         0         "
"1         0   2,580,317  6191.00 KB/s      0.12%         0         0         "
"0\n"
"```"

#: src/1-1-install.md:166
msgid ""
"1. [SONiC Supported Devices and Platforms][SONiCDevices]\n"
"2. [SONiC Thermal Control Design][SONiCThermal]\n"
"3. [Dell Enterprise SONiC Distribution][DellSONiC]\n"
"4. [Edgecore Enterprise SONiC  Distribution][EdgeCoreSONiC]\n"
"5. [Mikrotik CRS504-4XQ-IN][MikroTik100G]"
msgstr ""
"1. [SONiC Supported Devices and Platforms][SONiCDevices]\n"
"2. [SONiC Thermal Control Design][SONiCThermal]\n"
"3. [Dell Enterprise SONiC Distribution][DellSONiC]\n"
"4. [Edgecore Enterprise SONiC Distribution][EdgeCoreSONiC]\n"
"5. [Mikrotik CRS504-4XQ-IN][MikroTik100G]"

#: src/1-2-hello-world-virtually.md:1
msgid "# 虚拟测试环境"
msgstr "# Virtual test environment"

#: src/1-2-hello-world-virtually.md:3
msgid ""
"虽然SONiC功能强大，但是大部分时候一台能够支持SONiC系统的交换机价格并不便宜，"
"如果你只是想试一试SONiC，但是又不想花钱买一台SONiC的硬件设备，那么这一章一定"
"不能错过，这一章会总结一下如何通过GNS3在本地搭建一个虚拟的SONiC的Lab，让你可"
"以很快的在本地体验一把SONiC的基本功能。"
msgstr ""
"Although SONiC is powerful, it is usually not cheap to get a switch that "
"supports SONiC. If you would like to give SONiC a try, but don't want to "
"spend too much money on getting a SONiC-supported device, then you are in "
"the right place. This chapter will guide you on how to use GNS3 to build a "
"virtual SONiC's Lab locally, so that you can quickly experience the basic "
"functionalities of SONiC locally."

#: src/1-2-hello-world-virtually.md:5
msgid ""
"在本地运行SONiC的方法很好几种，比如docker + vswitch，p4软交换机等等，对于初次"
"使用而言，用GNS3可能是最方便快捷的了，所以本文就以GNS3为例，介绍一下如何在本"
"地搭建一个SONiC的Lab。那么，我们就开始吧！"
msgstr ""
"Despite there are multiple ways to run SONiC locally, such as docker + "
"vswitch or p4 switch, for first time users, using GNS3 is probably the most "
"convenient and fast way. So, we will be using GNS3 as an example in this "
"chapter and introduce how to build your own SONiC lab locally. Now, let's "
"get started!"

#: src/1-2-hello-world-virtually.md:7
msgid "## 安装GNS3"
msgstr "## Install GNS3"

#: src/1-2-hello-world-virtually.md:9
msgid ""
"首先，为了让我们方便而且直观的建立测试用的虚拟网络，我们需要先来安装一下"
"GNS3。"
msgstr ""
"FIrst, to make it easy and intuitive to set up a virtual network for "
"testing, let's get GNS3 installed."

#: src/1-2-hello-world-virtually.md:11
msgid ""
"[GNS3，全称为Graphical Network Simulator 3，是一个图形化的网络仿真软件]"
"[GNS3]。它支持多种不同的虚拟化技术，比如：QEMU、VMware、VirtualBox等等。这"
"样，我们在等会搭建虚拟网络的时候，就不需要手动的运行很多命令，或者写脚本了，"
"大部分的工作都可以通过图形界面来完成了。"
msgstr ""
"[GNS3 (Graphical Network Simulator 3), is a graphical network simulation "
"software][GNS3]. It supports many different virtualization technologies, "
"such as: QEMU, VMware, VirtualBox, and so on. With GNS3, we can finish "
"majority of the network creation work through GUI, without worrying about "
"remembering and running any commands or writing any scripts."

#: src/1-2-hello-world-virtually.md:13
msgid "### 安装依赖"
msgstr "### Install dependencies"

#: src/1-2-hello-world-virtually.md:15
msgid ""
"安装它之前，我们需要先安装几个其他的软件：docker, wireshark, putty, qemu, "
"ubridge, libvirt和bridge-utils，已经装好的小伙伴可以自行跳过。"
msgstr ""
"Before installing GNS3, we need to install several other softwares: docker, "
"wireshark, putty, qemu, ubridge, libvirt and bridge-utils. Please feel free "
"to skip this step, if you have already have them installed."

#: src/1-2-hello-world-virtually.md:17
msgid ""
"首先是Docker，它们的安装过程，大家可以自己通过下面的传送门去安装：[https://"
"docs.docker.com/engine/install/](https://docs.docker.com/engine/install/)"
msgstr ""
"First is Docker, we can follow their official doc to get it installed: "
"[https://docs.docker.com/engine/install/](https://docs.docker.com/engine/"
"install/)"

#: src/1-2-hello-world-virtually.md:19
msgid ""
"其他的在ubuntu上安装都非常简单，只需要执行下面的命令就可以了。这里安装时要注"
"意，ubridge和Wireshark的安装过程中会询问是不是要创建wireshark用户组来bypass "
"sudo，这里一定要选择Yes。"
msgstr ""
"The rest softwares can be easy installed on ubuntu, by running the following "
"commands. Note that the installation process of ubridge and Wireshark will "
"ask if you want to create a wireshark user group to bypass sudo. Please be "
"sure to select Yes here."

#: src/1-2-hello-world-virtually.md:21
msgid ""
"```\n"
"sudo apt-get install qemu-kvm libvirt-daemon-system libvirt-clients bridge-"
"utils wireshark putty ubridge\n"
"```"
msgstr ""
"```\n"
"sudo apt-get install qemu-kvm libvirt-daemon-system libvirt-clients bridge-"
"utils wireshark putty ubridge\n"
"```"

#: src/1-2-hello-world-virtually.md:25
msgid "安装好了之后，我们就可以来安装GNS3了。"
msgstr "Once it is done, we can start installing GNS3 now."

#: src/1-2-hello-world-virtually.md:27
msgid "### 安装GNS3"
msgstr "### Install GNS3"

#: src/1-2-hello-world-virtually.md:29
msgid "在Ubuntu上，GNS3的安装非常简单，只需要执行下面的命令就可以了。"
msgstr ""
"On Ubuntu, the installation of GNS3 is very simple, just execute the "
"following commands:"

#: src/1-2-hello-world-virtually.md:31
msgid ""
"```bash\n"
"sudo add-apt-repository ppa:gns3/ppa\n"
"sudo apt update                                \n"
"sudo apt install gns3-gui gns3-server\n"
"```"
msgstr ""
"```bash\n"
"sudo add-apt-repository ppa:gns3/ppa\n"
"sudo apt update                                \n"
"sudo apt install gns3-gui gns3-server\n"
"```"

#: src/1-2-hello-world-virtually.md:37
msgid ""
"然后把你的用户加入到如下的组中，这样GNS3就可以去访问docker，wireshark等功能而"
"不用sudo了。"
msgstr ""
"Then add your user to the following groups so that GNS3 can go to access "
"docker, wireshark, and other functions without sudo."

#: src/1-2-hello-world-virtually.md:39
msgid ""
"```bash\n"
"for g in ubridge libvirt kvm wireshark docker; do\n"
"    sudo usermod -aG $g <user-name>\n"
"done\n"
"```"
msgstr ""
"```bash\n"
"for g in ubridge libvirt kvm wireshark docker; do\n"
"    sudo usermod -aG $g <user-name>\n"
"done\n"
"```"

#: src/1-2-hello-world-virtually.md:45
msgid ""
"如果你使用的不是Ubuntu，更详细的安装文档可以参考[他们的官方文档]"
"[GNS3Install]。"
msgstr ""
"If you're not using Ubuntu, please follow the [their official documentation]"
"[GNS3Install] here for more detailed installation process."

#: src/1-2-hello-world-virtually.md:47
msgid "## 准备SONiC的镜像"
msgstr "## Prepare SONiC image"

#: src/1-2-hello-world-virtually.md:49
msgid ""
"在测试之前，我们还需要一个SONiC的镜像。由于需要支持大量不同的厂商，而每个厂商"
"的底层实现都不一样，所以最后每个厂商都会编译一个自己的镜像。这里因为我们在创"
"建虚拟的环境，所以我们需要使用基于VSwitch的镜像来创建虚拟交换机：sonic-vs."
"img.gz。"
msgstr ""
"Before testing, we still need a SONiC image. Since SONiC needs to support "
"various of platforms, and different platform has different underlying "
"implementation, each platform will have their own image. Here, since we are "
"creating a virtual environment, we need to use the image with VSwitch "
"platform to create the virtual switch: sonic-vs.img.gz."

#: src/1-2-hello-world-virtually.md:51
msgid ""
"[SONiC镜像的项目在这里](https://github.com/sonic-net/sonic-buildimage)，虽然"
"我们可以自己去编译，但是速度实在有点慢，所以为了节省时间，我们可以直接[去这里"
"下载最新的镜像](https://sonic-build.azurewebsites.net/ui/sonic/pipelines/142/"
"builds?branchName=master)。只要找一个最新的成功的Build就行，在Artifacts中找到"
"sonic-vs.img.gz，下载就可以了。"
msgstr ""
"The [project for building SONiC image is here](https://github.com/sonic-net/"
"sonic-buildimage). Although we can build it ourselves, the speed is really "
"slow. To save time, we can directly [download the latest image from here]"
"(https://sonic- build.azurewebsites.net/ui/sonic/pipelines/142/builds?"
"branchName=master). Simply look for the latest successful Build, find sonic-"
"vs.img.gz in Artifacts, and download it."

#: src/1-2-hello-world-virtually.md:53
msgid "然后，我们来准备一下项目："
msgstr "Then, let's get the project prepared:"

#: src/1-2-hello-world-virtually.md:55
msgid ""
"```bash\n"
"git clone --recurse-submodules https://github.com/sonic-net/sonic-buildimage."
"git\n"
"cd sonic-buildimage/platform/vs\n"
"\n"
"# 将下载的镜像放在这个目录下，然后运行下面这个命令进行解压缩。\n"
"gzip -d sonic-vs.img.gz\n"
"\n"
"# 下面这个命令会生成GNS3的镜像配置文件\n"
"./sonic-gns3a.sh\n"
"```"
msgstr ""
"```bash\n"
"git clone --recurse-submodules https://github.com/sonic-net/sonic-buildimage."
"git\n"
"cd sonic-buildimage/platform/vs\n"
"\n"
"# Download the image under this folder, then unzip the image with following "
"commands。\n"
"gzip -d sonic-vs.img.gz\n"
"\n"
"# Run the following command to generate the GNS3 image configuration file:\n"
"./sonic-gns3a.sh\n"
"```"

#: src/1-2-hello-world-virtually.md:66
msgid "执行完成之后，我们运行`ls`命令就可以看到我们需要的镜像文件了。"
msgstr ""
"Once it is done, we can see the image file we need by running `ls` command."

#: src/1-2-hello-world-virtually.md:68
msgid ""
"```bash\n"
"r12f@r12f-svr:~/code/sonic/sonic-buildimage/platform/vs\n"
"$ l\n"
"total 2.8G\n"
"...\n"
"-rw-rw-r--  1 r12f r12f 1.1K Apr 18 16:36 SONiC-latest.gns3a  # <= 这个是GNS3"
"的镜像配置文件\n"
"-rw-rw-r--  1 r12f r12f 2.8G Apr 18 16:32 sonic-vs.img        # <= 这个是我们"
"解压出来的镜像\n"
"...\n"
"```"
msgstr ""
"```bash\n"
"r12f@r12f-svr:~/code/sonic/sonic-buildimage/platform/vs\n"
"$ l\n"
"total 2.8G\n"
"...\n"
"-rw-rw-r--  1 r12f r12f 1.1K Apr 18 16:36 SONiC-latest.gns3a  # <= This is "
"the GNS3 image configuration file\n"
"-rw-rw-r--  1 r12f r12f 2.8G Apr 18 16:32 sonic-vs.img        # <= This is "
"the unzipped SONiC image file\n"
"...\n"
"```"

#: src/1-2-hello-world-virtually.md:78
msgid "## 导入镜像"
msgstr "## Import image into GNS3"

#: src/1-2-hello-world-virtually.md:80
msgid ""
"现在，在命令行里面输入`gns3`，就可以启动GNS3了。如果你是ssh到另外一台机器上，"
"可以试着启用X11转发，这样就可以在远程运行GNS3，但是图形界面显示在本地了。我就"
"是这样，将GNS3运行在了远程的服务器上，但是图形界面通过MobaXterm显示在了本地的"
"Windows机器上。"
msgstr ""
"Now, we can run `gns3` in command line to start GNS3! If you are ssh into "
"another machine, try enabling X11 forwarding, so that you can run GNS3 "
"remotely, but with the GUI displayed locally. This is what I am did - "
"running GNS3 on the remote server, but with the GUI displayed locally on the "
"Windows machine via MobaXterm."

#: src/1-2-hello-world-virtually.md:82
msgid ""
"运行起来之后，GNS3会让我们创建一个项目，很简单，填个目录地址就好。如果你是使"
"用的X11转发，请注意，这个目录是在你远程服务器上，而不是本地。"
msgstr ""
"Once it's running, GNS3 will ask us to create a project, it's simple, just "
"give it a directory path. If you are using X11 forwarding, please note that "
"this directory is on your remote server, not your local machine."

#: src/1-2-hello-world-virtually.md:86
msgid ""
"然后，我们就可以通过`File -> Import appliance`来导入我们刚刚生成的镜像了。"
msgstr ""
"Then, we can import the image we just generated via `File -> Import "
"appliance`."

#: src/1-2-hello-world-virtually.md:90
msgid "选择我们刚刚生成的`SONiC-latest.gns3a`镜像配置文件，然后点击`Next`。"
msgstr ""
"Select the `SONiC-latest.gns3a` image configuration file we just generated, "
"and click `Next`."

#: src/1-2-hello-world-virtually.md:94
msgid "这个时候就可以看到我们的镜像了，点击`Next`。"
msgstr "Now you can see our image file, click `Next`."

#: src/1-2-hello-world-virtually.md:98
msgid ""
"这个时候会开始导入镜像，这个过程可能会比较慢，因为GNS3需要将镜像转换成qcow2格"
"式，放入我们的项目目录中。导入完成之后，我们就可以看到我们的镜像了。"
msgstr ""
"Now, it will start importing the image, this process may be slow because "
"GNS3 needs to convert the image to qcow2 format and put it in our project "
"directory. Once the import is complete, we will be able to see our image."

#: src/1-2-hello-world-virtually.md:102
msgid "好的！完成！"
msgstr "Great! Image is now imported!"

#: src/1-2-hello-world-virtually.md:104
msgid "## 创建网络"
msgstr "## Create virtual network"

#: src/1-2-hello-world-virtually.md:106
msgid "好了！现在一切就绪，我们还是创建一个虚拟的网络吧！"
msgstr ""
"Great! Now we have everything is in place, let's create a virtual network "
"for our testing!"

#: src/1-2-hello-world-virtually.md:108
msgid ""
"GNS3的图形界面非常的好用，基本上就是打开侧边栏，把交换机拖进来，把VPC拖进来，"
"然后把线连起来就可以了。连接好之后记得点上面的Play按钮开始网络模拟。这里我们"
"就不多说了，直接上图。"
msgstr ""
"The GNS3 GUI are really easy to use, Basically, simply open the sidebar, "
"drag in the switch, drag in the VPC, and connect the wires. After everything "
"is connected, click the Play button on top to start the network simulation. "
"Then we should see the network starts running as below: "

#: src/1-2-hello-world-virtually.md:112
msgid ""
"接着，在交换机上点击右键，选择`Custom Console`，再选择Putty，就可以打开我们的"
"上面看到的交换机的Console了。这里，SONiC的默认用户名和密码是`admin`和"
"`YourPaSsWoRd`。登录进去之后，我们就可以运行熟悉的命令，用`show interfaces "
"status`或者`show ip interface`来查看网络的状态了。我们这里也可以看到，前面两"
"个我们连接好了的Interface的状态都是`up`的了。"
msgstr ""
"Next, right click on the switch and select `Custom Console`, then select "
"Putty to open the console for our virtual switch. Here, the default username "
"and password for SONiC are `admin` and `YourPaSsWoRd`. Once we are logged "
"in, we can run any SONiC commands, such as `show interfaces status` or `show "
"ip interface` to see the status of the network. As above shows, we can see "
"the status of the two connected interfaces are both `up`!"

#: src/1-2-hello-world-virtually.md:114
msgid "## 配置网络"
msgstr "## Configure the network"

#: src/1-2-hello-world-virtually.md:116
msgid ""
"SONiC软交换机下，默认的端口使用的是10.0.0.x的子网（如下），而且都是eth pair："
msgstr ""
"In the SONiC virtual switch, the default ports are all created as eth pairs "
"and all uses the 10.0.0.x subnet (as follows):"

#: src/1-2-hello-world-virtually.md:127
msgid ""
"这里，我们比较方便的做法是创建一个小的vlan，把我们的端口都包在里面（我们这里"
"用的是Ethernet4和Ethernet8）："
msgstr ""
"To make everything work, the most convenient way is still creating a vlan "
"and put all the ports in it (we use Ethernet4 and Ethernet8 here):"

#: src/1-2-hello-world-virtually.md:129
msgid ""
"```bash\n"
"# Remove old config\n"
"sudo config interface ip remove Ethernet4 10.0.0.2/31\n"
"sudo config interface ip remove Ethernet8 10.0.0.4/31\n"
"\n"
"# Create VLAN with id 2\n"
"sudo config vlan add 2\n"
"\n"
"# Add ports to VLAN\n"
"sudo config vlan member add -u 2 Ethernet4\n"
"sudo config vlan member add -u 2 Ethernet8\n"
"\n"
"# Add IP address to VLAN\n"
"sudo config interface ip add Vlan2 10.0.0.0/24\n"
"```"
msgstr ""
"```bash\n"
"# Remove old config\n"
"sudo config interface ip remove Ethernet4 10.0.0.2/31\n"
"sudo config interface ip remove Ethernet8 10.0.0.4/31\n"
"\n"
"# Create VLAN with id 2\n"
"sudo config vlan add 2\n"
"\n"
"# Add ports to VLAN\n"
"sudo config vlan member add -u 2 Ethernet4\n"
"sudo config vlan member add -u 2 Ethernet8\n"
"\n"
"# Add IP address to VLAN\n"
"sudo config interface ip add Vlan2 10.0.0.0/24\n"
"```"

#: src/1-2-hello-world-virtually.md:145
msgid "这样，我们的vlan就创建好了，我们可以通过`show vlan brief`来查看一下："
msgstr ""
"There you go! Our vlan is created, and we can check it out by `show vlan "
"brief`:"

#: src/1-2-hello-world-virtually.md:147
msgid ""
"```bash\n"
"admin@sonic:~$ show vlan brief\n"
"+-----------+--------------+-----------+----------------+-------------"
"+-----------------------+\n"
"|   VLAN ID | IP Address   | Ports     | Port Tagging   | Proxy ARP   | DHCP "
"Helper Address   |\n"
"+===========+==============+===========+================+=============+=======================+\n"
"|         2 | 10.0.0.0/24  | Ethernet4 | untagged       | disabled    "
"|                       |\n"
"|           |              | Ethernet8 | untagged       |             "
"|                       |\n"
"+-----------+--------------+-----------+----------------+-------------"
"+-----------------------+\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ show vlan brief\n"
"+-----------+--------------+-----------+----------------+-------------"
"+-----------------------+\n"
"|   VLAN ID | IP Address   | Ports     | Port Tagging   | Proxy ARP   | DHCP "
"Helper Address   |\n"
"+===========+==============+===========+================+=============+=======================+\n"
"|         2 | 10.0.0.0/24  | Ethernet4 | untagged       | disabled    "
"|                       |\n"
"|           |              | Ethernet8 | untagged       |             "
"|                       |\n"
"+-----------+--------------+-----------+----------------+-------------"
"+-----------------------+\n"
"```"

#: src/1-2-hello-world-virtually.md:157
msgid "然后，我们就可以给所有的主机配置一个10.0.0.x的IP地址了。"
msgstr "Then, we can assign a 10.0.0.x IP address to all the virtual host now:"

#: src/1-2-hello-world-virtually.md:159
msgid ""
"```bash\n"
"# VPC1\n"
"ip 10.0.0.2 255.0.0.0 10.0.0.1\n"
"\n"
"# VPC2\n"
"ip 10.0.0.3 255.0.0.0 10.0.0.1\n"
"```"
msgstr ""
"```bash\n"
"# VPC1\n"
"ip 10.0.0.2 255.0.0.0 10.0.0.1\n"
"\n"
"# VPC2\n"
"ip 10.0.0.3 255.0.0.0 10.0.0.1\n"
"```"

#: src/1-2-hello-world-virtually.md:167
msgid "好的，现在我们来Ping一下吧！"
msgstr "Okay! Time to ping!"

#: src/1-2-hello-world-virtually.md:171
msgid "通了！"
msgstr "Tada!"

#: src/1-2-hello-world-virtually.md:173
msgid "## 抓包"
msgstr "## Packet capture"

#: src/1-2-hello-world-virtually.md:175
msgid ""
"上面，我们安装GNS3前，我们特意安装了Wireshark，这样我们就可以在GNS3里面抓包"
"了。我们只需要右键点击图中我们想抓包的Link上，然后选择`Start capture`，就可以"
"开始抓包了。"
msgstr ""
"As installation process shows above, before we installed GNS3, we purposely "
"installed Wireshark so that we can directly capture packets inside GNS3. All "
"we need to do is right click on the link we want to capture and select "
"`Start capture`."

#: src/1-2-hello-world-virtually.md:179
msgid "稍等一下，Wireshark就会自动打开，实时的显示所有的包，非常的方便："
msgstr ""
"Very soon, Wireshark will be opened up and display all the network packets "
"in real time, which is very convenient:"

#: src/1-2-hello-world-virtually.md:183
msgid "## 更多的网络"
msgstr "## More complicated network, please"

#: src/1-2-hello-world-virtually.md:185
msgid ""
"除了上面这种最简单的网络搭建，我们其实可以用GNS3搭建很多非常复杂的网络来进行"
"测试，比如多层ECMP + eBGP等等。XFlow Research发布了一篇非常详细的文档来介绍这"
"些内容，感兴趣的小伙伴可以去传送到这篇文档去看看：[SONiC Deployment and "
"Testing Using GNS3][SONiCWithGNS3]。"
msgstr ""
"Besides the simplest network we built above, we can actually use GNS3 to "
"build very complicated network for testing, such as multi-layer ECMP + eBGP, "
"etc. XFlow Research has published a very detailed document on how to do "
"this. If you are interested, please feel free to check it out: [SONiC "
"Deployment and Testing Using GNS3][SONiCWithGNS3]."

#: src/1-2-hello-world-virtually.md:189
msgid ""
"1. [GNS3][GNS3]\n"
"2. [GNS3 Linux Install][GNS3Install]\n"
"3. [SONiC Deployment and Testing Using GNS3][SONiCWithGNS3]"
msgstr ""
"1. [GNS3][GNS3]\n"
"2. [GNS3 Linux Install][GNS3Install]\n"
"3. [SONiC Deployment and Testing Using GNS3][SONiCWithGNS3]"

#: src/1-3-command-cheatsheet.md:1
msgid "# 常用命令"
msgstr "# Common commands"

#: src/1-3-command-cheatsheet.md:3
msgid ""
"为了帮助我们查看和配置SONiC的状态，SONiC提供了大量的CLI命令供我们调用。这些命"
"令大多分为两类：`show`和`config`，他们的格式基本类似，大多都符合下面的格式："
msgstr ""
"To help us view and configure the status of SONiC, SONiC provides a large "
"number of CLI commands for us to invoke. Most of these commands fall into "
"two categories: `show` and `config`, and they are basically similar in "
"format, most of them conform to the following format:"

#: src/1-3-command-cheatsheet.md:5
msgid ""
"```bash\n"
"show <object> [options]\n"
"config <object> [options]\n"
"```"
msgstr ""
"```bash\n"
"show <object> [options]\n"
"config <object> [options]\n"
"```"

#: src/1-3-command-cheatsheet.md:10
msgid ""
"SONiC的文档提供了非常详细的命令列表：[SONiC Command Line Interface Guide]"
"[SONiCCommands]，但是由于其命令众多，不便于我们初期的学习和使用，所以列出了一"
"些平时最常用的命令和解释，供大家参考。"
msgstr ""
"SONiC's documentation provides a very detailed list of commands: [SONiC "
"Command Line Interface Guide][SONiCCommands], but since its many commands do "
"not facilitate our initial learning and use, some of the most commonly used "
"commands and explanations are listed for your reference."

#: src/1-3-command-cheatsheet.md:12
msgid ""
"```admonish info\n"
"SONiC中的所有命令的子命令都可以只打前三个字母，来帮助我们有效的节约输入命令的"
"时间，比如：\n"
"\n"
"    show interface transceiver error-status\n"
"    \n"
"和下面这条命令是等价的：\n"
"\n"
"    show int tra err\n"
"\n"
"为了帮助大家记忆和查找，下面的命令列表都用的全名，但是大家在实际使用的时候，"
"可以大胆的使用缩写来减少工作量。\n"
"```"
msgstr ""
"```admonish info\n"
"SONiC中的所有命令的子命令都可以只打前三个字母，来帮助我们有效的节约输入命令的"
"时间，比如：\n"
"\n"
"    show interface transceiver error-status\n"
"    \n"
"和下面这条命令是等价的：\n"
"\n"
"    show int tra err\n"
"\n"
"为了帮助大家记忆和查找，下面的命令列表都用的全名，但是大家在实际使用的时候，"
"可以大胆的使用缩写来减少工作量。\n"
"```"

#: src/1-3-command-cheatsheet.md:24
msgid ""
"```admonish info\n"
"如果遇到不熟悉的命令，都可以通过输入`-h`或者`--help`来查看帮助信息，比如：\n"
"\n"
"    show -h\n"
"    show interface --help\n"
"    show interface transceiver --help\n"
"\n"
"```"
msgstr ""
"```admonish info\n"
"如果遇到不熟悉的命令，都可以通过输入`-h`或者`--help`来查看帮助信息，比如：\n"
"\n"
"    show -h\n"
"    show interface --help\n"
"    show interface transceiver --help\n"
"\n"
"```"

#: src/1-3-command-cheatsheet.md:33
msgid "## General"
msgstr "## General"

#: src/1-3-command-cheatsheet.md:35
msgid ""
"```bash\n"
"show version\n"
"\n"
"show uptime\n"
"\n"
"show platform summary\n"
"```"
msgstr ""
"```bash\n"
"show version\n"
"\n"
"show uptime\n"
"\n"
"show platform summary\n"
"```"

#: src/1-3-command-cheatsheet.md:43
msgid "## Config"
msgstr "## Config"

#: src/1-3-command-cheatsheet.md:45
msgid ""
"```bash\n"
"sudo config reload\n"
"sudo config load_minigraph\n"
"sudo config save -y\n"
"```"
msgstr ""
"```bash\n"
"sudo config reload\n"
"sudo config load_minigraph\n"
"sudo config save -y\n"
"```"

#: src/1-3-command-cheatsheet.md:51
msgid "## Docker相关"
msgstr "## Docker related"

#: src/1-3-command-cheatsheet.md:53
msgid ""
"```bash\n"
"docker ps\n"
"```"
msgstr ""
"```bash\n"
"docker ps\n"
"```"

#: src/1-3-command-cheatsheet.md:57
msgid ""
"```bash\n"
"docker top <container_id>|<container_name>\n"
"```"
msgstr ""
"```bash\n"
"docker top <container_id>|<container_name>\n"
"```"

#: src/1-3-command-cheatsheet.md:61
msgid ""
"```admonish note\n"
"\n"
"如果我们想对所有的docker container进行某个操作，我们可以通过`docker ps`命令来"
"获取所有的container id，然后pipe到`tail -n +2`来去掉第一行的标题，从而实现批"
"量调用。\n"
"\n"
"比如，我们可以通过如下命令来查看所有container中正在运行的所有线程：\n"
"\n"
"    $ for id in `docker ps | tail -n +2 | awk '{print $1}'`; do docker top "
"$id; done\n"
"    UID                 PID                 PPID                "
"C                   STIME               TTY                 "
"TIME                CMD\n"
"    root                7126                7103                "
"0                   Jun09               pts/0               "
"00:02:24            /usr/bin/python3 /usr/local/bin/supervisord\n"
"    root                7390                7126                "
"0                   Jun09               pts/0               "
"00:00:24            python3 /usr/bin/supervisor-proc-exit-listener --"
"container-name telemetry\n"
"    ...\n"
"```"
msgstr ""
"```admonish note\n"
"\n"
"如果我们想对所有的docker container进行某个操作，我们可以通过`docker ps`命令来"
"获取所有的container id，然后pipe到`tail -n +2`来去掉第一行的标题，从而实现批"
"量调用。\n"
"\n"
"比如，我们可以通过如下命令来查看所有container中正在运行的所有线程：\n"
"\n"
"    $ for id in `docker ps | tail -n +2 | awk '{print $1}'`; do docker top "
"$id; done\n"
"    UID                 PID                 PPID                "
"C                   STIME               TTY                 "
"TIME                CMD\n"
"    root                7126                7103                "
"0                   Jun09               pts/0               "
"00:02:24            /usr/bin/python3 /usr/local/bin/supervisord\n"
"    root                7390                7126                "
"0                   Jun09               pts/0               "
"00:00:24            python3 /usr/bin/supervisor-proc-exit-listener --"
"container-name telemetry\n"
"    ...\n"
"```"

#: src/1-3-command-cheatsheet.md:74
msgid "## Interfaces / IPs"
msgstr "## Interfaces / IPs"

#: src/1-3-command-cheatsheet.md:76
msgid ""
"```bash\n"
"show interface status\n"
"show interface counters\n"
"show interface portchannel\n"
"show interface transceiver info\n"
"show interface transceiver error-status\n"
"sonic-clear counters\n"
"\n"
"TODO: config\n"
"```"
msgstr ""
"```bash\n"
"show interface status\n"
"show interface counters\n"
"show interface portchannel\n"
"show interface transceiver info\n"
"show interface transceiver error-status\n"
"sonic-clear counters\n"
"\n"
"TODO: config\n"
"```"

#: src/1-3-command-cheatsheet.md:87
msgid "## MAC / ARP / NDP"
msgstr "## MAC / ARP / NDP"

#: src/1-3-command-cheatsheet.md:89
msgid ""
"```bash\n"
"# Show MAC (FDB) entries\n"
"show mac\n"
"\n"
"# Show IP ARP table\n"
"show arp\n"
"\n"
"# Show IPv6 NDP table\n"
"show ndp\n"
"```"
msgstr ""
"```bash\n"
"# Show MAC (FDB) entries\n"
"show mac\n"
"\n"
"# Show IP ARP table\n"
"show arp\n"
"\n"
"# Show IPv6 NDP table\n"
"show ndp\n"
"```"

#: src/1-3-command-cheatsheet.md:100
msgid "## BGP / Routes"
msgstr "## BGP / Routes"

#: src/1-3-command-cheatsheet.md:102
msgid ""
"```bash\n"
"show ip/ipv6 bgp summary\n"
"show ip/ipv6 bgp network\n"
"\n"
"show ip/ipv6 bgp neighbors [IP]\n"
"\n"
"show ip/ipv6 route\n"
"\n"
"TODO: add\n"
"config bgp shutdown neighbor <IP>\n"
"config bgp shutdown all\n"
"\n"
"TODO: IPv6\n"
"```"
msgstr ""
"```bash\n"
"show ip/ipv6 bgp summary\n"
"show ip/ipv6 bgp network\n"
"\n"
"show ip/ipv6 bgp neighbors [IP]\n"
"\n"
"show ip/ipv6 route\n"
"\n"
"TODO: add\n"
"config bgp shutdown neighbor <IP>\n"
"config bgp shutdown all\n"
"\n"
"TODO: IPv6\n"
"```"

#: src/1-3-command-cheatsheet.md:117
msgid "## LLDP"
msgstr "## LLDP"

#: src/1-3-command-cheatsheet.md:119
msgid ""
"```bash\n"
"# Show LLDP neighbors in table format\n"
"show lldp table\n"
"\n"
"# Show LLDP neighbors details\n"
"show lldp neighbors\n"
"```"
msgstr ""
"```bash\n"
"# Show LLDP neighbors in table format\n"
"show lldp table\n"
"\n"
"# Show LLDP neighbors details\n"
"show lldp neighbors\n"
"```"

#: src/1-3-command-cheatsheet.md:127
msgid "## VLAN"
msgstr "## VLAN"

#: src/1-3-command-cheatsheet.md:129
msgid ""
"```bash\n"
"show vlan brief\n"
"```"
msgstr ""
"```bash\n"
"show vlan brief\n"
"```"

#: src/1-3-command-cheatsheet.md:133
msgid "## QoS相关"
msgstr "## QoS related"

#: src/1-3-command-cheatsheet.md:135
msgid ""
"```bash\n"
"# Show PFC watchdog stats\n"
"show pfcwd stats\n"
"show queue counter\n"
"```"
msgstr ""
"```bash\n"
"# Show PFC watchdog stats\n"
"show pfcwd stats\n"
"show queue counter\n"
"```"

#: src/1-3-command-cheatsheet.md:141
msgid "## ACL"
msgstr "## ACL"

#: src/1-3-command-cheatsheet.md:143
msgid ""
"```bash\n"
"show acl table\n"
"show acl rule\n"
"```"
msgstr ""
"```bash\n"
"show acl table\n"
"show acl rule\n"
"```"

#: src/1-3-command-cheatsheet.md:148
msgid "## MUXcable / Dual ToR"
msgstr "## MUXcable / Dual ToR"

#: src/1-3-command-cheatsheet.md:150
msgid "### Muxcable mode"
msgstr "### Muxcable mode"

#: src/1-3-command-cheatsheet.md:152
msgid ""
"```bash\n"
"config muxcable mode {active} {<portname>|all} [--json]\n"
"config muxcable mode active Ethernet4 [--json]\n"
"```"
msgstr ""
"```bash\n"
"config muxcable mode {active} {<portname>|all} [--json]\n"
"config muxcable mode active Ethernet4 [--json]\n"
"```"

#: src/1-3-command-cheatsheet.md:157
msgid "### Muxcable config"
msgstr "### Muxcable config"

#: src/1-3-command-cheatsheet.md:159
msgid ""
"```bash\n"
"show muxcable config [portname] [--json]\n"
"```"
msgstr ""
"```bash\n"
"show muxcable config [portname] [--json]\n"
"```"

#: src/1-3-command-cheatsheet.md:163
msgid "### Muxcable status"
msgstr "### Muxcable status"

#: src/1-3-command-cheatsheet.md:165
msgid ""
"```bash\n"
"show muxcable status [portname] [--json] \n"
"```"
msgstr ""
"```bash\n"
"show muxcable status [portname] [--json] \n"
"```"

#: src/1-3-command-cheatsheet.md:169
msgid "### Muxcable firmware"
msgstr "### Muxcable firmware"

#: src/1-3-command-cheatsheet.md:171
msgid ""
"```bash\n"
"# Firmware version:\n"
"show muxcable firmware version <port>\n"
"\n"
"# Firmware download\n"
"# config muxcable firmware download <firmware_file> <port_name> \n"
"sudo config muxcable firmware download AEC_WYOMING_B52Yb0_MS_0.6_20201218."
"bin Ethernet0\n"
"\n"
"# Rollback:\n"
"# config muxcable firmware rollback <port_name>\n"
"sudo config muxcable firmware rollback Ethernet0\n"
"```"
msgstr ""
"```bash\n"
"# Firmware version:\n"
"show muxcable firmware version <port>\n"
"\n"
"# Firmware download\n"
"# config muxcable firmware download <firmware_file> <port_name> \n"
"sudo config muxcable firmware download AEC_WYOMING_B52Yb0_MS_0.6_20201218."
"bin Ethernet0\n"
"\n"
"# Rollback:\n"
"# config muxcable firmware rollback <port_name>\n"
"sudo config muxcable firmware rollback Ethernet0\n"
"```"

#: src/1-3-command-cheatsheet.md:186
msgid "1. [SONiC Command Line Interface Guide][SONiCCommands]"
msgstr "1. [SONiC Command Line Interface Guide][SONiCCommands]"

#: src/2-core-components-intro.md:1
msgid "# 核心组件简介"
msgstr "# Core components"

#: src/2-core-components-intro.md:3
msgid ""
"我们也许会觉得交换机是一个很简单的网络设备，但是实际上交换机上的组件非常的"
"多，而且由于SONiC中Redis的解耦，我们很难简单的对代码进行跟踪来理解服务之间的"
"关系，这就需要我们先建立一个比较抽象的整体模型，然后再去深入的学习每个组件的"
"细节。所以在深入其他部分之前，我们这里先对每个组件都做一个点到为止的介绍，帮"
"助大家建立一个大概的整体模型。"
msgstr ""
"We might think that a switch is a simple network device. However, in fact, "
"there are many components in a switch. Furthermore, because SONiC decouples "
"all components using Redis, Redis in SONiC, it is difficult to understand "
"the relationships between services by simply tracing the code. This requires "
"us to first establish a relatively abstract overall model, and then dive "
"into the details of each component. Therefore, before diving into each "
"individual parts, here we will introduce each component briefly to help "
"establish a rough overall model."

#: src/2-core-components-intro.md:5
msgid ""
"```admonish info\n"
"在阅读本章之前，有两个名词会经常在本章和SONiC的官方文档中出现：ASIC"
"（Application-Specific Integrated Circuit）和ASIC状态（State）。它们指的是交"
"换机中用来进行包处理的Pipeline的状态，比如，ACL，转发方式等等，这个和其他交换"
"机的硬件状态，比如，端口状态（端口速度，接口类型），IP信息等等硬件状态是非常"
"不同的。\n"
"\n"
"如果大家有兴趣了解更深入的细节，可以先移步阅读两个相关资料：[SAI (Switch "
"Abstraction Interface) API][SAIAPI]和一篇RMT（Reprogrammable Match Table）的"
"相关论文：[Forwarding Metamorphosis: Fast Programmable Match-Action "
"Processing in Hardware for SDN][PISA]。\n"
"\n"
"这些都会对我们阅读SONiC的文档有很大的帮助。\n"
"```"
msgstr ""
"```admonish info\n"
"Before reading this chapter, there are two terms that will frequently appear "
"in this chapter and in official documents of SONiC: ASIC (Application-"
"Specific Integrated Circuit) and ASIC State. They refer to the state of the "
"pipeline used for packet processing in the switch, such as ACL, etc. This is "
"different from other hardware states of switches, such as port states (port "
"speed, interface type), IP address, etc.\n"
"\n"
"If you are interested in more details, please feel free to check out two "
"relevant materials first: [SAI (Switch Abstraction Interface) API][SAIAPI] "
"and a paper on RMT (Reprogrammable Match Table) called \"[Forwarding "
"Metamorphosis: Fast Programmable Match-Action Processing in Hardware for SDN]"
"[PISA]\". \n"
"\n"
"These will be very helpful for us to read SONiC documentation.\n"
"```"

#: src/2-core-components-intro.md:13
msgid ""
"另外为了方便我们的理解和阅读，我们也把SONiC架构图在这里放在这一章的开头，作为"
"引用："
msgstr ""
"In addition, for our convenience of understanding and reading, we also put "
"the SONiC architecture diagram at the beginning of this chapter as a "
"reference."

#: src/2-core-components-intro.md:21
msgid ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [SAI API][SAIAPI]\n"
"3. [Forwarding Metamorphosis: Fast Programmable Match-Action Processing in "
"Hardware for SDN][PISA]"
msgstr ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [SAI API][SAIAPI]\n"
"3. [Forwarding Metamorphosis: Fast Programmable Match-Action Processing in "
"Hardware for SDN][PISA]"

#: src/2-1-database.md:1
msgid "# Redis数据库"
msgstr "# Redis database"

#: src/2-1-database.md:3
msgid ""
"首先，在SONiC里面最核心的服务，自然是当之无愧的中心数据库Redis了！它的主要目"
"的有两个：存储所有服务的配置和状态，并且为各个服务提供通信的媒介。"
msgstr ""
"First of all, the most important service in SONiC is undoubtedly the central "
"database - Redis! It has 2 major purposes: to store the switch configuration "
"and status of all services, as well as to provide a communication channel "
"among all services."

#: src/2-1-database.md:5
msgid ""
"为了提供这些功能，SONiC会在Redis中创建一个名为`sonic-db`的数据库实例，其配置"
"和分库信息我们可以在`/var/run/redis/sonic-db/database_config.json`中找到："
msgstr ""
"In order to provide these features, SONiC will create a instance named "
"`sonic-db` in Redis, and its configuration and sharding information can be "
"found in `/var/run/redis/sonic-db/database_config.json`."

#: src/2-1-database.md:7
msgid ""
"```bash\n"
"admin@sonic:~$ cat /var/run/redis/sonic-db/database_config.json\n"
"{\n"
"    \"INSTANCES\": {\n"
"        \"redis\": {\n"
"            \"hostname\": \"127.0.0.1\",\n"
"            \"port\": 6379,\n"
"            \"unix_socket_path\": \"/var/run/redis/redis.sock\",\n"
"            \"persistence_for_warm_boot\": \"yes\"\n"
"        }\n"
"    },\n"
"    \"DATABASES\": {\n"
"        \"APPL_DB\": { \"id\": 0, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"ASIC_DB\": { \"id\": 1, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"COUNTERS_DB\": { \"id\": 2, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"LOGLEVEL_DB\": { \"id\": 3, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"CONFIG_DB\": { \"id\": 4, \"separator\": \"|\", \"instance\": "
"\"redis\" },\n"
"        \"PFC_WD_DB\": { \"id\": 5, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"FLEX_COUNTER_DB\": { \"id\": 5, \"separator\": \":\", "
"\"instance\": \"redis\" },\n"
"        \"STATE_DB\": { \"id\": 6, \"separator\": \"|\", \"instance\": "
"\"redis\" },\n"
"        \"SNMP_OVERLAY_DB\": { \"id\": 7, \"separator\": \"|\", "
"\"instance\": \"redis\" },\n"
"        \"RESTAPI_DB\": { \"id\": 8, \"separator\": \"|\", \"instance\": "
"\"redis\" },\n"
"        \"GB_ASIC_DB\": { \"id\": 9, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"GB_COUNTERS_DB\": { \"id\": 10, \"separator\": \":\", "
"\"instance\": \"redis\" },\n"
"        \"GB_FLEX_COUNTER_DB\": { \"id\": 11, \"separator\": \":\", "
"\"instance\": \"redis\" },\n"
"        \"APPL_STATE_DB\": { \"id\": 14, \"separator\": \":\", \"instance\": "
"\"redis\" }\n"
"    },\n"
"    \"VERSION\": \"1.0\"\n"
"}\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ cat /var/run/redis/sonic-db/database_config.json\n"
"{\n"
"    \"INSTANCES\": {\n"
"        \"redis\": {\n"
"            \"hostname\": \"127.0.0.1\",\n"
"            \"port\": 6379,\n"
"            \"unix_socket_path\": \"/var/run/redis/redis.sock\",\n"
"            \"persistence_for_warm_boot\": \"yes\"\n"
"        }\n"
"    },\n"
"    \"DATABASES\": {\n"
"        \"APPL_DB\": { \"id\": 0, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"ASIC_DB\": { \"id\": 1, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"COUNTERS_DB\": { \"id\": 2, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"LOGLEVEL_DB\": { \"id\": 3, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"CONFIG_DB\": { \"id\": 4, \"separator\": \"|\", \"instance\": "
"\"redis\" },\n"
"        \"PFC_WD_DB\": { \"id\": 5, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"FLEX_COUNTER_DB\": { \"id\": 5, \"separator\": \":\", "
"\"instance\": \"redis\" },\n"
"        \"STATE_DB\": { \"id\": 6, \"separator\": \"|\", \"instance\": "
"\"redis\" },\n"
"        \"SNMP_OVERLAY_DB\": { \"id\": 7, \"separator\": \"|\", "
"\"instance\": \"redis\" },\n"
"        \"RESTAPI_DB\": { \"id\": 8, \"separator\": \"|\", \"instance\": "
"\"redis\" },\n"
"        \"GB_ASIC_DB\": { \"id\": 9, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"GB_COUNTERS_DB\": { \"id\": 10, \"separator\": \":\", "
"\"instance\": \"redis\" },\n"
"        \"GB_FLEX_COUNTER_DB\": { \"id\": 11, \"separator\": \":\", "
"\"instance\": \"redis\" },\n"
"        \"APPL_STATE_DB\": { \"id\": 14, \"separator\": \":\", \"instance\": "
"\"redis\" }\n"
"    },\n"
"    \"VERSION\": \"1.0\"\n"
"}\n"
"```"

#: src/2-1-database.md:38
msgid ""
"虽然我们可以看到SONiC中的数据库有十来个，但是我们大部分时候只需要关注以下几个"
"最重要的数据库就可以了："
msgstr ""
"Although there are about ten databases in SONiC that we can see, most of the "
"time we only need to focus on the following few most important databases:"

#: src/2-1-database.md:40
msgid ""
"- **CONFIG_DB（ID = 4）**：存储所有服务的**配置信息**，比如端口配置，VLAN配置"
"等等。它代表着**用户想要交换机达到的状态**的数据模型，这也是所有CLI和外部应用"
"程序修改配置时的主要操作对象。\n"
"- **APPL_DB（Application DB, ID = 0）**：存储**所有服务的内部状态信息**。这些"
"信息有两种：一种是各个服务在读取了CONFIG_DB的配置信息后，自己计算出来的。我们"
"可以理解为**各个服务想要交换机达到的状态**（Goal State），还有一种是当最终硬"
"件状态发生变化被写回时，有些服务会直接写回到APPL_DB，而不是我们下面马上要介绍"
"的STATE_DB。这些信息我们可以理解为**各个服务认为交换机当前的状态**（Current "
"State）。\n"
"- **STATE_DB（ID = 6）**：存储着交换机**各个部件当前的状态**（Current "
"State）。当SONiC中的服务收到了STATE_DB的状态变化，但是发现和Goal State不一致"
"的时候，SONiC就会重新下发配置，直到两者一致。（当然，对于那些回写到APPL_DB状"
"态，服务就会监听APPL_DB的变化，而不是STATE_DB了。）\n"
"- **ASIC_DB（ID = 1）**：存储着**SONiC想要交换机ASIC达到状态信息**，比如，"
"ACL，路由等等。和APPL_DB不同，这个数据库里面的数据模型是面向ASIC设计的，而不"
"是面向服务抽象的。这样做的目的是为了方便各个厂商进行SAI和ASIC驱动的开发。"
msgstr ""
"- **CONFIG_DB (ID = 4)**: It stores **configuration of all services**, such "
"as port configs and VLAN configs. It represents the data model of the "
"**state that the user wants the switch to achieve**, and is also the main "
"target that all CLI and external applications operates when updating the "
"configs.\n"
"- **APPL_DB (Application DB, ID = 0)**: It stores the **internal states of "
"all services**. There are two kinds of information: one is the state that "
"the individual services calculate for themselves after reading the "
"configuration information from CONFIG_DB. We can understand it as the **goal "
"state that each service wants the switch to achieve**. The other type of "
"information is that when the final hardware state changes and is written "
"back, some services will write back directly to APPL_DB instead of the "
"STATE_DB that we will introduce later. We can understand this as the "
"**current state that each service thinks the switch is in**.\n"
"- **STATE_DB (ID = 6)**: It stores the **current state of each component of "
"the switch**. When a service in SONiC receives a state change from STATE_DB "
"which is inconsistent with its goal state, SONiC will redrive the configs "
"until they are consistent. (Of course, for those states that are written "
"back to APPL_DB, the service will listen for changes in APPL_DB instead of "
"STATE_DB.)\n"
"- **ASIC_DB (ID = 1)**: It stores the **state information that SONiC wants "
"the switch ASIC to achieve**, such as ACLs and routes. Unlike APPL_DB, the "
"data model in this database is designed for ASIC, instead of each service. "
"This is to simplify the development of SAI and ASIC drivers by various "
"vendors."

#: src/2-1-database.md:45
msgid ""
"这里，我们会发现一个很直观的问题：交换机里面这么多服务，难道所有的配置和状态"
"都放在一个数据库里面没有隔离的么？如果两个服务用了同一个Redis Key怎么办呢？这"
"个问题非常的好，SONiC的解决也很直接，那就是在每个数据库里面继续分表！"
msgstr ""
"Now, we will notice a very intuitive problem: with so many services in the "
"switch, are all configurations and states stored in one database without "
"isolation? What if two services use the same Redis Key? This is a very good "
"question, and SONiC's solution is very direct: continue to partition the "
"tables in each database!"

#: src/2-1-database.md:47
msgid ""
"我们知道Redis在每个数据库里面并没有表的概念，而是使用key-value的方式来存储数"
"据。所以，为了进一步分表，SONiC的解决方法是将表的名字放入key中，并且使用分隔"
"符将表和key隔开。上面的配置文件中`separator`字段就是做这个了。比如：`APPL_DB`"
"中的`PORT_TABLE`表中的`Ethernet4`端口的状态，我们可以通过`PORT_TABLE:"
"Ethernet4`来获取，如下："
msgstr ""
"We know that Redis does not have the concept of table in each database, but "
"directly stores data using key-value pairs. Therefore, in order to further "
"partition tables, SONiC's solution is to put the table name into the key and "
"use a separator to separate the table from the key. The `separator` field in "
"the above configuration file is for this purpose. For example, to retrieve "
"the status of the `Ethernet4` port in the `PORT_TABLE` table in the "
"`APPL_DB`, we can use `PORT_TABLE:Ethernet4` as the key, as follows:"

#: src/2-1-database.md:49
msgid ""
"```bash\n"
"127.0.0.1:6379> select 0\n"
"OK\n"
"\n"
"127.0.0.1:6379> hgetall PORT_TABLE:Ethernet4\n"
" 1) \"admin_status\"\n"
" 2) \"up\"\n"
" 3) \"alias\"\n"
" 4) \"Ethernet6/1\"\n"
" 5) \"index\"\n"
" 6) \"6\"\n"
" 7) \"lanes\"\n"
" 8) \"13,14,15,16\"\n"
" 9) \"mtu\"\n"
"10) \"9100\"\n"
"11) \"speed\"\n"
"12) \"40000\"\n"
"13) \"description\"\n"
"14) \"\"\n"
"15) \"oper_status\"\n"
"16) \"up\"\n"
"```"
msgstr ""
"```bash\n"
"127.0.0.1:6379> select 0\n"
"OK\n"
"\n"
"127.0.0.1:6379> hgetall PORT_TABLE:Ethernet4\n"
" 1) \"admin_status\"\n"
" 2) \"up\"\n"
" 3) \"alias\"\n"
" 4) \"Ethernet6/1\"\n"
" 5) \"index\"\n"
" 6) \"6\"\n"
" 7) \"lanes\"\n"
" 8) \"13,14,15,16\"\n"
" 9) \"mtu\"\n"
"10) \"9100\"\n"
"11) \"speed\"\n"
"12) \"40000\"\n"
"13) \"description\"\n"
"14) \"\"\n"
"15) \"oper_status\"\n"
"16) \"up\"\n"
"```"

#: src/2-1-database.md:72
msgid ""
"当然在SONiC中，不仅仅是数据模型，包括通信机制，都是使用类似的方法来实现“表”级"
"别的隔离的。"
msgstr ""
"Of course, in SONiC, not only data models but also communication mechanisms "
"are implemented using similar methods to achieve \"table-level\" isolation."

#: src/2-1-database.md:76 src/2-2-services-intro.md:76
msgid "1. [SONiC Architecture][SONiCArch]"
msgstr "1. [SONiC Architecture][SONiCArch]"

#: src/2-2-services-intro.md:1
msgid "# 服务与工作流简介"
msgstr "# Service and Workflow Intro"

#: src/2-2-services-intro.md:3
msgid ""
"SONiC里面的服务（常驻进程）非常的多，有二三十种，它们会在随着交换机启动而启"
"动，并一直保持运行，直到交换机关机。如果我们想快速掌握SONiC，一个一个服务的去"
"了解，会很容易陷入细节的泥潭，所以，我们最好把这些服务和控制流进行一个大的分"
"类，以帮助我们建立一个宏观的概念。"
msgstr ""
"There are very many services (resident processes) inside SONiC, 20 or 30 of "
"them, and they will start as the switch starts up and stay running until the "
"switch is shut down. If we want to quickly grasp SONiC, going through it "
"service by service will easily get bogged down in details, so it is best to "
"make a broad classification of these services and control flows to help us "
"build a macro concept."

#: src/2-2-services-intro.md:5
msgid ""
"```admonish note\n"
"我们这里不会深入到某一个具体的服务中去，而是先从整体上来看看SONiC中的服务的结"
"构，帮助我们建立一个整体的认识。关于具体的服务，我们会在工作流一章中，对常用"
"的工作流进行介绍，而关于详细的技术细节，大家也可以查阅每个服务相关的设计文"
"档。\n"
"```"
msgstr ""
"```admonish note\n"
"我们这里不会深入到某一个具体的服务中去，而是先从整体上来看看SONiC中的服务的结"
"构，帮助我们建立一个整体的认识。关于具体的服务，我们会在工作流一章中，对常用"
"的工作流进行介绍，而关于详细的技术细节，大家也可以查阅每个服务相关的设计文"
"档。\n"
"```"

#: src/2-2-services-intro.md:9
msgid "## 服务分类"
msgstr "## Service classification"

#: src/2-2-services-intro.md:11
msgid ""
"总体而言，SONiC中的服务可以分为以下几类：`*syncd`, `*mgrd`，feature实现，"
"`orchagent`和`syncd`。"
msgstr ""
"In general, the services in SONiC can be divided into the following "
"categories: `*syncd`, `*mgrd`, feature implementations, `orchagent` and "
"`syncd`."

#: src/2-2-services-intro.md:13
msgid "### `*syncd`服务"
msgstr "### `*syncd` service"

#: src/2-2-services-intro.md:15
msgid ""
"这类服务名字中都以`syncd`结尾。它们做的事情都很类似：它们负责将硬件状态同步到"
"Redis中，一般目标都以APPL_DB或者STATE_DB为主。"
msgstr ""
"These services all end with `syncd` in their names. They all do similar "
"things: they are responsible for synchronizing hardware state into Redis, "
"and generally target either APPL_DB or STATE_DB."

#: src/2-2-services-intro.md:17
msgid ""
"比如，`portsyncd`就是通过监听netlink的事件，将交换机中所有Port的状态同步到"
"STATE_DB中，而`natsyncd`则是监听netlink的事件，将交换机中所有的NAT状态同步到"
"APPL_DB中。"
msgstr ""
"For example, `portsyncd` is to synchronize the state of all the ports in the "
"switch to STATE_DB by listening to the events of netlink, while `natsyncd` "
"is to listen to the events of netlink and synchronize the state of all the "
"NATs in the switch to APPL_DB."

#: src/2-2-services-intro.md:19
msgid "### `*mgrd`服务"
msgstr "### `*mgrd` service"

#: src/2-2-services-intro.md:21
msgid ""
"这类服务名字中都以`mgrd`结尾。顾名思义，这些服务是所谓的“Manager”服务，也就是"
"说它们负责各个硬件的配置，和`*syncd`完全相反。它们的逻辑主要有两个部分："
msgstr ""
"These services have names that end with `mgrd`. As the name suggests, these "
"services are so-called \"Manager\" services, meaning that they are "
"responsible for the configuration of individual hardware, the exact opposite "
"of `*syncd`. Their logic has two main parts:"

#: src/2-2-services-intro.md:23
msgid ""
"1. **配置下发**：负责读取配置文件和监听Redis中的配置和状态改变（主要是"
"CONFIG_DB，APPL_DB和STATE_DB），然后将这些修改推送到交换机硬件中去。推送的方"
"法有多种，取决于更新的目标是什么，可以通过更新APPL_DB并发布更新消息，或者是直"
"接调用linux下的命令行，对系统进行修改。比如：`nbrmgr`就是监听CONFIG_DB，"
"APPL_DB和STATE_DB中neighbor的变化，并调用netlink和command line来对neighbor和"
"route进行修改，而`intfmgr`除了调用command line还会将一些状态更新到APPL_DB中"
"去。\n"
"2. **状态同步**：对于需要Reconcile的服务，`*mgrd`还会监听STATE_DB中的状态变"
"化，如果发现硬件状态和当前期望状态不一致，就会重新发起配置流程，将硬件状态设"
"置为期望状态。这些STATE_DB中的状态变化一般都是`*syncd`服务推送的。比如："
"`intfmgr`就会监听STATE_DB中，由`portsyncd`推送的，端口的Up/Down状态和MTU变"
"化，一旦发现和其内存中保存的期望状态不一致，就会重新下发配置。"
msgstr ""
"1. **Configuration downlink**: Responsible for reading configuration files "
"and listening for configuration and state changes in Redis (mainly "
"CONFIG_DB, APPL_DB and STATE_DB), and then pushing these changes to the "
"switch hardware. There are various methods of pushing, depending on what the "
"target of the update is, either by updating APPL_DB and posting an update "
"message, or by directly invoking the command line under linux and making "
"changes to the system. For example: `nbrmgr` is listening to the changes of "
"neighbor in CONFIG_DB, APPL_DB and STATE_DB, and calling netlink and command "
"line to make changes to neighbor and route, while `intfmgr` besides calling "
"command line will also update some state and `intfmgr` will update some "
"state to APPL_DB besides calling command line.\n"
"2. **State synchronization**: For services that require Reconcile, `*mgrd` "
"also listens for state changes in STATE_DB, and if the hardware state is "
"found to be inconsistent with the current desired state, it will re-initiate "
"the configuration process to set the hardware state to the desired state. "
"These state changes in STATE_DB are generally pushed by the `*syncd` "
"service. For example, `intfmgr` listens to the Up/Down status and MTU "
"changes of ports in STATE_DB pushed by `portsyncd`, and re-issues the "
"configuration once it finds that it does not match the desired state stored "
"in its memory."

#: src/2-2-services-intro.md:26
msgid "### 功能实现服务"
msgstr "### Function implementation services"

#: src/2-2-services-intro.md:28
msgid ""
"有一些功能并不是依靠OS本身来完成的，而是由一些特定的进程来实现的，比如BGP，或"
"者一些外部接口。这些服务名字中经常以`d`结尾，表示deamon，比如：`bgpd`，"
"`lldpd`，`snmpd`，`teamd`等，或者干脆就是这个功能的名字，比如：`fancontrol`。"
msgstr ""
"There are some functions that do not rely on the OS itself, but are "
"implemented by some specific processes, such as BGP, or some external "
"interfaces. These services often have names ending in `d` for deamon, e.g.: "
"`bgpd`, `lldpd`, `snmpd`, `teamd`, etc., or simply the name of this "
"function, e.g.: `fancontrol`."

#: src/2-2-services-intro.md:30
msgid "### `orchagent`服务"
msgstr "### `orchagent` service"

#: src/2-2-services-intro.md:32
msgid ""
"这个是SONiC中最重要的一个服务，不像其他的服务只负责一两个特定的功能，"
"`orchagent`作为交换机ASIC状态的编排者（orchestrator），会检查数据库中所有来自"
"`*syncd`服务的状态，整合起来并下发给用于保存交换机ASIC配置的数据库：ASIC_DB。"
"这些状态最后会被`syncd`接收，并调用SAI API经过各个厂商提供的SAI实现和ASIC SDK"
"和ASIC进行交互，最终将配置下发到交换机硬件中。"
msgstr ""
"This is one of the most important services in SONiC, unlike other services "
"that are only responsible for one or two specific functions, `orchagent`, as "
"the orchestrator (orchestrator) of the switch ASIC state, checks all the "
"states in the database from the `*syncd` service, consolidates them and "
"sends them down to the database used to store the switch ASIC configuration: "
"`ASIC_DB: This state is finally received by `syncd` and calls the SAI API to "
"interact with the ASIC SDK and the ASIC through the SAI implementations "
"provided by each vendor, and finally sends the configuration down to the "
"switch hardware."

#: src/2-2-services-intro.md:34
msgid "### `syncd`服务"
msgstr "### `syncd` service"

#: src/2-2-services-intro.md:36
msgid ""
"`syncd`服务是`orchagent`的下游，它虽然名字叫`syncd`，但是它却同时肩负着ASIC的"
"`*mgrd`和`*syncd`的工作。"
msgstr ""
"The `syncd` service is downstream of `orchagent`, which is named `syncd`, "
"but it is responsible for both `*mgrd` and `*syncd` of ASIC."

#: src/2-2-services-intro.md:38
msgid ""
"- 首先，作为`*mgrd`，它会监听ASIC_DB的状态变化，一旦发现，就会获取其新的状态"
"并调用SAI API，将配置下发到交换机硬件中。\n"
"- 然后，作为`*syncd`，如果ASIC发送了任何的通知给SONiC，它也会将这些通知通过消"
"息的方式发送到Redis中，以便`orchagent`和`*mgrd`服务获取到这些变化，并进行处"
"理。这些通知的类型我们可以在[SwitchNotifications.h][SAISwitchNotify]中找到。"
msgstr ""
"- First, as `*mgrd`, it listens for changes in the state of ASIC_DB, and "
"once it finds them, it gets its new state and calls the SAI API to send down "
"the configuration to the switch hardware.\n"
"- Then, as `*syncd`, if ASIC sends any notifications to SONiC, it will also "
"send those notifications to Redis by way of messages so that the `orchagent` "
"and `*mgrd` services can fetch the changes and process them. The types of "
"these notifications we can find in [SwitchNotifications.h][SAISwitchNotify]."

#: src/2-2-services-intro.md:41
msgid "## 服务间控制流分类"
msgstr "## Inter-service control flow classification"

#: src/2-2-services-intro.md:43
msgid ""
"有了这些分类，我们就可以更加清晰的来理解SONiC中的服务了，而其中非常重要的就是"
"理解服务之间的控制流。有了上面的分类，我们这里也可以把主要的控制流有分为两"
"类：配置下发和状态同步。"
msgstr ""
"With these categories, we can understand the services in SONiC more clearly, "
"and it is very important to understand the control flow between services. "
"With the above classification, we can also divide the main control flow here "
"into two categories: configuration delivery and state synchronization."

#: src/2-2-services-intro.md:45
msgid "### 配置下发"
msgstr "### Configuration down"

#: src/2-2-services-intro.md:47
msgid "配置下发的流程一般是这样的："
msgstr "The flow of configuration issuance is generally as follows:"

#: src/2-2-services-intro.md:49
msgid ""
"1. **修改配置**：用户可以通过CLI或者REST API修改配置，这些配置会被写入到"
"CONFIG_DB中并通过Redis发送更新通知。或者外部程序可以通过特定的接口，比如BGP的"
"API，来修改配置，这种配置会通过内部的TCP Socket发送给`*mgrd`服务。\n"
"2. **`*mgrd`下发配置**：服务监听到CONFIG_DB中的配置变化，然后将这些配置推送到"
"交换机硬件中。这里由两种主要情况（并且可以同时存在）：\n"
"   1. **直接下发**：\n"
"      1. `*mgrd`服务直接调用linux下的命令行，或者是通过netlink来修改系统配"
"置\n"
"      2. `*syncd`服务会通过netlink或者其他方式监听到系统配置的变化，并将这些"
"变化推送到STATE_DB或者APPL_DB中。\n"
"      3. `*mgrd`服务监听到STATE_DB或者APPL_DB中的配置变化，然后将这些配置和其"
"内存中存储的配置进行比较，如果发现不一致，就会重新调用命令行或者netlink来修改"
"系统配置，直到它们一致为止。\n"
"   2. **间接下发**：\n"
"      1. `*mgrd`将状态推送到APPL_DB并通过Redis发送更新通知。\n"
"      2. `orchagent`服务监听到配置变化，然后根据所有相关的状态，计算出此时"
"ASIC应该达到的状态，并下发到ASIC_DB中。\n"
"      3. `syncd`服务监听到ASIC_DB的变化，然后将这些新的配置通过统一的SAI API"
"接口，调用ASIC Driver更新交换机ASIC中的配置。"
msgstr ""
"1. **Modify Configuration**: Users can modify the configuration through the "
"CLI or REST API, which is written to CONFIG_DB and sends update "
"notifications through Redis. Or an external program can modify the "
"configuration through a specific interface, such as the BGP API, and this "
"configuration is sent to the `*mgrd` service via an internal TCP socket.\n"
"2. **`*mgrd` sends down configurations**: the service listens to "
"configuration changes in the CONFIG_DB and then pushes these configurations "
"to the switch hardware. There are two main cases here (and they can both "
"exist):\n"
"   1. **direct downlink**:\n"
"      1. `*mgrd` service directly invokes the command line under linux, or "
"modifies the system configuration via netlink\n"
"      2. `*syncd` service will listen to the system configuration changes "
"via netlink or other means and push these changes to STATE_DB or APPL_DB.\n"
"      3. The `*mgrd` service listens to configuration changes in STATE_DB or "
"APPL_DB, then compares those configurations with the configurations stored "
"in its memory, and if it finds inconsistencies, it will re-invoke the "
"command line or netlink to modify the system configuration until they are "
"consistent.\n"
"   2. **Indirect downlink**:\n"
"      1. `*mgrd` pushes status to APPL_DB and sends update notifications via "
"Redis.\n"
"      2. `orchagent` service listens for configuration changes and then "
"calculates the state ASIC should reach at this time based on all relevant "
"states and downlinks to ASIC_DB.\n"
"      3. The `syncd` service listens to the changes in the ASIC_DB and then "
"takes these new configurations and calls the ASIC Driver to update the "
"configuration in the switch ASIC through the unified SAI API interface."

#: src/2-2-services-intro.md:60
msgid ""
"配置初始化和配置下发类似，不过是在服务启动的时候读取配置文件，这里就不展开"
"了。"
msgstr ""
"Configuration initialization is similar to configuration distribution, but "
"the configuration file is read when the service is started, so we won't "
"expand on that here."

#: src/2-2-services-intro.md:62
msgid "### 状态同步"
msgstr "### Status synchronization"

#: src/2-2-services-intro.md:64
msgid ""
"如果这个时候，出现了一些情况，比如网口坏了，ASIC中的状态变了等等，这个时候我"
"们就需要进行状态更新和同步了。这个流程一般是这样的："
msgstr ""
"If at this time, something happens, such as a bad network port, the state in "
"the ASIC changes, etc., this time we need to do a state update and "
"synchronization. This process generally looks like this:"

#: src/2-2-services-intro.md:66
msgid ""
"1. **检测状态变化**：这个状态变化主要来源于`*syncd`服务（netlink等等）和"
"`syncd`服务（[SAI Switch Notification][SAISwitchNotify]），这些服务在检测到变"
"化后，会将它们发送给STATE_DB或者APPL_DB。\n"
"2. **处理状态变化**：`orchagent`和`*mgrd`服务会监听到这些变化，然后开始处理，"
"将新的配置重新通过命令行和netlink下发给系统，或者下发到ASIC_DB中，让`syncd`服"
"务再次对ASIC进行更新。"
msgstr ""
"1. **Detecting state changes**: This state change mainly comes from the "
"`*syncd` service (netlink, etc.) and the `syncd` service ([SAI Switch "
"Notification][SAISwitchNotify]), which, after detecting the changes, send "
"them to STATE_DB or APPL_DB.\n"
"2. **Processing state changes**: The `orchagent` and `*mgrd` services will "
"listen to these changes and start processing them, sending the new "
"configuration down to the system again via command line and netlink, or down "
"to ASIC_DB for the `syncd` service to update the ASIC again."

#: src/2-2-services-intro.md:69
msgid "### 具体例子"
msgstr "### Specific examples"

#: src/2-2-services-intro.md:71
msgid ""
"SONiC的官方文档中给出了几个典型的控制流流转的例子，这里就不过多的展开了，有兴"
"趣的朋友可以去这里看看：[SONiC Subsystem Interactions](https://github.com/"
"sonic-net/SONiC/wiki/Architecture#sonic-subsystems-interactions)。我们在后面"
"工作流一章中，也会选择一些非常常用的工作流进行展开。"
msgstr ""
"The official documentation of SONiC gives several examples of typical "
"control flow, so I won't expand too much here, interested parties can go "
"here: [SONiC Subsystem Interactions](https://github.com/sonic-net/SONiC/"
"wiki/ Architecture#sonic-subsystems-interactions). We will also choose some "
"very common workflows to expand on later in the workflow chapter."

#: src/2-3-key-containers.md:1
msgid "# 核心容器"
msgstr "# Core containers"

#: src/2-3-key-containers.md:3
msgid "SONiC的设计中最具特色的地方：容器化。"
msgstr "The most distinctive aspect of SONiC's design: containerization."

#: src/2-3-key-containers.md:5
msgid ""
"从SONiC的上面的设计图中，我们可以看出来，SONiC中，所有的服务都是以容器的形式"
"存在的。在登录进交换机之后，我们可以通过`docker ps`命令来查看当前运行的容器："
msgstr ""
"From the above design diagram of SONiC, we can see that in SONiC, all "
"services are in the form of containers. After logging into the switch, we "
"can view the currently running containers by using the `docker ps` command:"

#: src/2-3-key-containers.md:7
msgid ""
"```bash\n"
"admin@sonic:~$ docker ps\n"
"CONTAINER ID   IMAGE                                COMMAND                  "
"CREATED      STATUS        PORTS     NAMES\n"
"ddf09928ec58   docker-snmp:latest                   \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             snmp\n"
"c480f3cf9dd7   docker-sonic-mgmt-framework:latest   \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             mgmt-framework\n"
"3655aff31161   docker-lldp:latest                   \"/usr/bin/docker-lld…"
"\"   2 days ago   Up 32 hours             lldp\n"
"78f0b12ed10e   docker-platform-monitor:latest       \"/usr/bin/docker_ini…"
"\"   2 days ago   Up 32 hours             pmon\n"
"f9d9bcf6c9a6   docker-router-advertiser:latest      \"/usr/bin/docker-ini…"
"\"   2 days ago   Up 32 hours             radv\n"
"2e5dbee95844   docker-fpm-frr:latest                \"/usr/bin/docker_ini…"
"\"   2 days ago   Up 32 hours             bgp\n"
"bdfa58009226   docker-syncd-brcm:latest             \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             syncd\n"
"655e550b7a1b   docker-teamd:latest                  \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             teamd\n"
"1bd55acc181c   docker-orchagent:latest              \"/usr/bin/docker-ini…"
"\"   2 days ago   Up 32 hours             swss\n"
"bd20649228c8   docker-eventd:latest                 \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             eventd\n"
"b2f58447febb   docker-database:latest               \"/usr/local/bin/dock…"
"\"   2 days ago   Up 32 hours             database\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ docker ps\n"
"CONTAINER ID   IMAGE                                COMMAND                  "
"CREATED      STATUS        PORTS     NAMES\n"
"ddf09928ec58   docker-snmp:latest                   \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             snmp\n"
"c480f3cf9dd7   docker-sonic-mgmt-framework:latest   \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             mgmt-framework\n"
"3655aff31161   docker-lldp:latest                   \"/usr/bin/docker-lld…"
"\"   2 days ago   Up 32 hours             lldp\n"
"78f0b12ed10e   docker-platform-monitor:latest       \"/usr/bin/docker_ini…"
"\"   2 days ago   Up 32 hours             pmon\n"
"f9d9bcf6c9a6   docker-router-advertiser:latest      \"/usr/bin/docker-ini…"
"\"   2 days ago   Up 32 hours             radv\n"
"2e5dbee95844   docker-fpm-frr:latest                \"/usr/bin/docker_ini…"
"\"   2 days ago   Up 32 hours             bgp\n"
"bdfa58009226   docker-syncd-brcm:latest             \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             syncd\n"
"655e550b7a1b   docker-teamd:latest                  \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             teamd\n"
"1bd55acc181c   docker-orchagent:latest              \"/usr/bin/docker-ini…"
"\"   2 days ago   Up 32 hours             swss\n"
"bd20649228c8   docker-eventd:latest                 \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             eventd\n"
"b2f58447febb   docker-database:latest               \"/usr/local/bin/dock…"
"\"   2 days ago   Up 32 hours             database\n"
"```"

#: src/2-3-key-containers.md:23
msgid "这里我们来简单介绍一下这些容器。"
msgstr "Let's briefly introduce these containers here."

#: src/2-3-key-containers.md:25
msgid "## 数据库容器：database"
msgstr "## Database container: database"

#: src/2-3-key-containers.md:27
msgid ""
"这个容器中运行的就是我们多次提到的SONiC中的中心数据库Redis了，它里面存放着所"
"有交换机的配置和状态信息，SONiC也是主要通过它来向各个服务提供底层的通信机制。"
msgstr ""
"This container runs Redis, the central database in SONiC that we have "
"mentioned many times, which holds the configuration and state information of "
"all switches, and through which SONiC provides the underlying communication "
"mechanism to each service."

#: src/2-3-key-containers.md:29
msgid "我们通过docker进入这个容器，就可以看到里面正在运行的redis进程了："
msgstr ""
"We can see the running redis process inside this container by docker: the"

#: src/2-3-key-containers.md:31
msgid ""
"```bash\n"
"admin@sonic:~$ sudo docker exec -it database bash\n"
"\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          82 13.7  1.7 130808 71692 pts/0    Sl   Apr26 393:27 /usr/bin/"
"redis-server 127.0.0.1:6379\n"
"...\n"
"\n"
"root@sonic:/# cat /var/run/redis/redis.pid\n"
"82\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ sudo docker exec -it database bash\n"
"\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          82 13.7  1.7 130808 71692 pts/0    Sl   Apr26 393:27 /usr/bin/"
"redis-server 127.0.0.1:6379\n"
"...\n"
"\n"
"root@sonic:/# cat /var/run/redis/redis.pid\n"
"82\n"
"```"

#: src/2-3-key-containers.md:44
msgid ""
"那么别的容器是如何来访问这个Redis数据库的呢？答案是通过Unix Socket。我们可以"
"在database容器中看到这个Unix Socket，它将交换机上的`/var/run/redis`目录map进"
"database容器，让database容器可以创建这个socket："
msgstr ""
"So how does another container access this Redis database? The answer is "
"through a Unix socket, which we can see in the database container, which "
"maps the `/var/run/redis` directory on the switch into the database "
"container, allowing the database container to create the socket: `/var/run/"
"redis`:"

#: src/2-3-key-containers.md:46
msgid ""
"```bash\n"
"# In database container\n"
"root@sonic:/# ls /var/run/redis\n"
"redis.pid  redis.sock  sonic-db\n"
"\n"
"# On host\n"
"admin@sonic:~$ ls /var/run/redis\n"
"redis.pid  redis.sock  sonic-db\n"
"```"
msgstr ""
"```bash\n"
"# In database container\n"
"root@sonic:/# ls /var/run/redis\n"
"redis.pid  redis.sock  sonic-db\n"
"\n"
"# On host\n"
"admin@sonic:~$ ls /var/run/redis\n"
"redis.pid  redis.sock  sonic-db\n"
"```"

#: src/2-3-key-containers.md:56
msgid ""
"然后再将这个socket给map到其他的容器中，这样所有容器就都可以来访问这个中心数据"
"库啦，比如，swss容器："
msgstr ""
"Then map this socket to other containers, so that all containers can access "
"the central database, for example, the swss container:"

#: src/2-3-key-containers.md:58
msgid ""
"```bash\n"
"admin@sonic:~$ docker inspect swss\n"
"...\n"
"        \"HostConfig\": {\n"
"            \"Binds\": [\n"
"                ...\n"
"                \"/var/run/redis:/var/run/redis:rw\",\n"
"                ...\n"
"            ],\n"
"...\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ docker inspect swss\n"
"...\n"
"        \"HostConfig\": {\n"
"            \"Binds\": [\n"
"                ...\n"
"                \"/var/run/redis:/var/run/redis:rw\",\n"
"                ...\n"
"            ],\n"
"...\n"
"```"

#: src/2-3-key-containers.md:70
msgid "## 交换机状态管理容器：swss（Switch State Service）"
msgstr "## Switch state management container: swss (Switch State Service)"

#: src/2-3-key-containers.md:72
msgid ""
"这个容器可以说是SONiC中最关键的容器了，**它是SONiC的大脑**，里面运行着大量的"
"`*syncd`和`*mgrd`服务，用来管理交换机方方面面的配置，比如Port，neighbor，"
"ARP，VLAN，Tunnel等等等等。另外里面还运行着上面提到的`orchagent`，用来统一处"
"理和ASIC相关的配置和状态变化。"
msgstr ""
"This container is arguably the most critical container in SONiC, **it is the "
"brain of SONiC**, which runs a large number of `*syncd` and `*mgrd` services "
"to manage all aspects of the switch configuration, such as Port, neighbor, "
"ARP, VLAN, Tunnel, etc., etc. Also running inside is the `orchagent` "
"mentioned above, which is used to handle configuration and status changes "
"related to the ASIC in a unified manner."

#: src/2-3-key-containers.md:74
msgid ""
"这些服务大概的功能和流程我们上面已经提过了，所以就不再赘述了。这里我们可以通"
"过`ps`命令来看一下这个容器中运行的服务："
msgstr ""
"The approximate functions and processes of these services have already been "
"mentioned above, so we won't go over them again. Here we can take a look at "
"the services running in this container by using the `ps` command:"

#: src/2-3-key-containers.md:76
msgid ""
"```bash\n"
"admin@sonic:~$ docker exec -it swss bash\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          43  0.0  0.2  91016  9688 pts/0    Sl   Apr26   0:18 /usr/bin/"
"portsyncd\n"
"root          49  0.1  0.6 558420 27592 pts/0    Sl   Apr26   4:31 /usr/bin/"
"orchagent -d /var/log/swss -b 8192 -s -m 00:1c:73:f2:bc:b4\n"
"root          74  0.0  0.2  91240  9776 pts/0    Sl   Apr26   0:19 /usr/bin/"
"coppmgrd\n"
"root          93  0.0  0.0   4400  3432 pts/0    S    Apr26   0:09 /bin/"
"bash /usr/bin/arp_update\n"
"root          94  0.0  0.2  91008  8568 pts/0    Sl   Apr26   0:09 /usr/bin/"
"neighsyncd\n"
"root          96  0.0  0.2  91168  9800 pts/0    Sl   Apr26   0:19 /usr/bin/"
"vlanmgrd\n"
"root          99  0.0  0.2  91320  9848 pts/0    Sl   Apr26   0:20 /usr/bin/"
"intfmgrd\n"
"root         103  0.0  0.2  91136  9708 pts/0    Sl   Apr26   0:19 /usr/bin/"
"portmgrd\n"
"root         104  0.0  0.2  91380  9844 pts/0    Sl   Apr26   0:20 /usr/bin/"
"buffermgrd -l /usr/share/sonic/hwsku/pg_profile_lookup.ini\n"
"root         107  0.0  0.2  91284  9836 pts/0    Sl   Apr26   0:20 /usr/bin/"
"vrfmgrd\n"
"root         109  0.0  0.2  91040  8600 pts/0    Sl   Apr26   0:19 /usr/bin/"
"nbrmgrd\n"
"root         110  0.0  0.2  91184  9724 pts/0    Sl   Apr26   0:19 /usr/bin/"
"vxlanmgrd\n"
"root         112  0.0  0.2  90940  8804 pts/0    Sl   Apr26   0:09 /usr/bin/"
"fdbsyncd\n"
"root         113  0.0  0.2  91140  9656 pts/0    Sl   Apr26   0:20 /usr/bin/"
"tunnelmgrd\n"
"root         208  0.0  0.0   5772  1636 pts/0    S    Apr26   0:07 /usr/sbin/"
"ndppd\n"
"...\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ docker exec -it swss bash\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          43  0.0  0.2  91016  9688 pts/0    Sl   Apr26   0:18 /usr/bin/"
"portsyncd\n"
"root          49  0.1  0.6 558420 27592 pts/0    Sl   Apr26   4:31 /usr/bin/"
"orchagent -d /var/log/swss -b 8192 -s -m 00:1c:73:f2:bc:b4\n"
"root          74  0.0  0.2  91240  9776 pts/0    Sl   Apr26   0:19 /usr/bin/"
"coppmgrd\n"
"root          93  0.0  0.0   4400  3432 pts/0    S    Apr26   0:09 /bin/"
"bash /usr/bin/arp_update\n"
"root          94  0.0  0.2  91008  8568 pts/0    Sl   Apr26   0:09 /usr/bin/"
"neighsyncd\n"
"root          96  0.0  0.2  91168  9800 pts/0    Sl   Apr26   0:19 /usr/bin/"
"vlanmgrd\n"
"root          99  0.0  0.2  91320  9848 pts/0    Sl   Apr26   0:20 /usr/bin/"
"intfmgrd\n"
"root         103  0.0  0.2  91136  9708 pts/0    Sl   Apr26   0:19 /usr/bin/"
"portmgrd\n"
"root         104  0.0  0.2  91380  9844 pts/0    Sl   Apr26   0:20 /usr/bin/"
"buffermgrd -l /usr/share/sonic/hwsku/pg_profile_lookup.ini\n"
"root         107  0.0  0.2  91284  9836 pts/0    Sl   Apr26   0:20 /usr/bin/"
"vrfmgrd\n"
"root         109  0.0  0.2  91040  8600 pts/0    Sl   Apr26   0:19 /usr/bin/"
"nbrmgrd\n"
"root         110  0.0  0.2  91184  9724 pts/0    Sl   Apr26   0:19 /usr/bin/"
"vxlanmgrd\n"
"root         112  0.0  0.2  90940  8804 pts/0    Sl   Apr26   0:09 /usr/bin/"
"fdbsyncd\n"
"root         113  0.0  0.2  91140  9656 pts/0    Sl   Apr26   0:20 /usr/bin/"
"tunnelmgrd\n"
"root         208  0.0  0.0   5772  1636 pts/0    S    Apr26   0:07 /usr/sbin/"
"ndppd\n"
"...\n"
"```"

#: src/2-3-key-containers.md:99
msgid "## ASIC管理容器：syncd"
msgstr "## ASIC management container: syncd"

#: src/2-3-key-containers.md:101
msgid ""
"这个容器中主要是用于管理交换机上的ASIC的，里面运行着`syncd`服务。我们之前提到"
"的各个厂商提供的SAI（Switch Abstraction Interface）和ASIC Driver都是放在这个"
"容器中的。正是因为这个容器的存在，才使得SONiC可以支持多种不同的ASIC，而不需要"
"修改上层的服务。换句话说，如果没有这个容器，那SONiC就是一个缸中大脑，除了一些"
"基本的配置，其他只能靠想的，什么都干不了。"
msgstr ""
"This container is mainly used to manage the ASICs on the switch, and it runs "
"the `syncd` service. The SAI (Switch Abstraction Interface) and ASIC Driver "
"provided by each vendor we mentioned before are placed in this container. It "
"is the existence of this container that allows SONiC to support many "
"different ASICs without modifying the upper layer services. In other words, "
"without this container, the SONiC is a brain in a tank, except for some "
"basic configuration, other than only by thinking, nothing can be done."

#: src/2-3-key-containers.md:103
msgid ""
"在syncd容器中运行的服务并不多，就是syncd，我们可以通过`ps`命令来查看，而在`/"
"usr/lib`目录下，我们也可以找到这个为了支持ASIC而编译出来的巨大无比的SAI文件："
msgstr ""
"There are not many services running in the syncd container, namely syncd, "
"which we can view with the `ps` command, and in the `/usr/lib` directory, "
"where we can also find this immense and unbelievable SAI file compiled to "
"support ASIC: the"

#: src/2-3-key-containers.md:105
msgid ""
"```bash\n"
"admin@sonic:~$ docker exec -it syncd bash\n"
"\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          20  0.0  0.0  87708  1544 pts/0    Sl   Apr26   0:00 /usr/bin/"
"dsserve /usr/bin/syncd --diag -u -s -p /etc/sai.d/sai.profile -b /tmp/"
"break_before_make_objects\n"
"root          32 10.7 14.9 2724404 599408 pts/0  Sl   Apr26 386:49 /usr/bin/"
"syncd --diag -u -s -p /etc/sai.d/sai.profile -b /tmp/"
"break_before_make_objects\n"
"...\n"
"\n"
"root@sonic:/# ls -lh /usr/lib\n"
"total 343M\n"
"...\n"
"lrwxrwxrwx 1 root root   13 Apr 25 04:38 libsai.so.1 -> libsai.so.1.0\n"
"-rw-r--r-- 1 root root 343M Feb  1 06:10 libsai.so.1.0\n"
"...\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ docker exec -it syncd bash\n"
"\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          20  0.0  0.0  87708  1544 pts/0    Sl   Apr26   0:00 /usr/bin/"
"dsserve /usr/bin/syncd --diag -u -s -p /etc/sai.d/sai.profile -b /tmp/"
"break_before_make_objects\n"
"root          32 10.7 14.9 2724404 599408 pts/0  Sl   Apr26 386:49 /usr/bin/"
"syncd --diag -u -s -p /etc/sai.d/sai.profile -b /tmp/"
"break_before_make_objects\n"
"...\n"
"\n"
"root@sonic:/# ls -lh /usr/lib\n"
"total 343M\n"
"...\n"
"lrwxrwxrwx 1 root root   13 Apr 25 04:38 libsai.so.1 -> libsai.so.1.0\n"
"-rw-r--r-- 1 root root 343M Feb  1 06:10 libsai.so.1.0\n"
"...\n"
"```"

#: src/2-3-key-containers.md:123
msgid "## 各种实现特定功能的容器"
msgstr "## Various containers that implement specific functions"

#: src/2-3-key-containers.md:125
msgid ""
"SONiC中还有很多的容器是为了实现一些特定功能而存在的。这些容器一般都有着特殊的"
"外部接口（非SONiC CLI和REST API）和实现（非OS或ASIC），比如："
msgstr ""
"There are many more containers in SONiC that exist to implement some "
"specific functionality. These containers generally have special external "
"interfaces (non-SONiC CLI and REST API) and implementations (non-OS or "
"ASIC), such as"

#: src/2-3-key-containers.md:127
msgid ""
"- bgp：用来实现BGP协议（Border Gateway Protocol，边界网关协议）的容器\n"
"- lldp：用来实现LLDP协议（Link Layer Discovery Protocol，链路层发现协议）的容"
"器\n"
"- teamd：用来实现Link Aggregation（链路聚合）的容器\n"
"- snmp：用来实现SNMP协议（Simple Network Management Protocol，简单网络管理协"
"议）的容器"
msgstr ""
"- bgp: the container used to implement the BGP protocol (Border Gateway "
"Protocol)\n"
"- lldp: the container used to implement LLDP (Link Layer Discovery "
"Protocol)\n"
"- teamd: the container used to implement Link Aggregation\n"
"- snmp: the container used to implement SNMP (Simple Network Management "
"Protocol)"

#: src/2-3-key-containers.md:132
msgid ""
"和SWSS类似，为了适应SONiC的架构，它们中间也都会运行着上面我们提到的那几种服"
"务："
msgstr ""
"Similar to SWSS, in order to accommodate the SONiC architecture, they all "
"run the same kinds of services we mentioned above in the middle:"

#: src/2-3-key-containers.md:134
msgid ""
"- 配置管理和下发（类似`*mgrd`）：`lldpmgrd`，`zebra`（bgp）\n"
"- 状态同步（类似`*syncd`）：`lldpsyncd`，`fpmsyncd`（bgp），`teamsyncd`\n"
"- 服务实现或者外部接口（`*d`）：`lldpd`，`bgpd`，`teamd`，`snmpd`"
msgstr ""
"- Configuration management and despatch (similar to `*mgrd`): `lldpmgrd`, "
"`zebra` (bgp)\n"
"- Status synchronization (similar to `*syncd`): `lldpsyncd`, `fpmsyncd` "
"(bgp), `teamsyncd`\n"
"- Service implementation or external interface (`*d`): `lldpd`, `bgpd`, "
"`teamd`, `snmpd`"

#: src/2-3-key-containers.md:138
msgid "## 管理服务容器：mgmt-framework"
msgstr "## Managed Service Container: mgmt-framework"

#: src/2-3-key-containers.md:140
msgid ""
"我们在之前的章节中已经看过如何使用SONiC的CLI来进行一些交换机的配置，但是在实"
"际生产环境中，手动登录交换机使用CLI来配置所有的交换机是不现实的，所以SONiC提"
"供了一个REST API来解决这个问题。这个REST API的实现就是在`mgmt-framework`容器"
"中。我们可以通过`ps`命令来查看："
msgstr ""
"We have seen in previous sections how to use SONiC's CLI for some switch "
"configuration, but in a real production environment, it is not practical to "
"manually log into the switch to configure all the switches using the CLI, so "
"SONiC provides a REST API to solve this problem. The implementation of this "
"REST API is in the `mgmt-framework` container. We can view it with the `ps` "
"command:"

#: src/2-3-key-containers.md:142
msgid ""
"```bash\n"
"admin@sonic:~$ docker exec -it mgmt-framework bash\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          16  0.3  1.2 1472804 52036 pts/0   Sl   16:20   0:02 /usr/sbin/"
"rest_server -ui /rest_ui -logtostderr -cert /tmp/cert.pem -key /tmp/key.pem\n"
"...\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ docker exec -it mgmt-framework bash\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          16  0.3  1.2 1472804 52036 pts/0   Sl   16:20   0:02 /usr/sbin/"
"rest_server -ui /rest_ui -logtostderr -cert /tmp/cert.pem -key /tmp/key.pem\n"
"...\n"
"```"

#: src/2-3-key-containers.md:151
msgid ""
"其实除了REST API，SONiC还可以通过其他方式来进行管理，如gNMI，这些也都是运行在"
"这个容器中的。其整体架构如下图所示 [\\[2\\]][SONiCMgmtFramework]："
msgstr ""
"In fact, besides the REST API, SONiC can also be managed in other ways, such "
"as gNMI, which are also running in this container. Its overall architecture "
"is shown in the following figure [\\[2\\]][SONiCMgmtFramework]:"

#: src/2-3-key-containers.md:155
msgid ""
"这里我们也可以发现，其实我们使用的CLI，底层也是通过调用这个REST API来实现的～"
msgstr ""
"Here we can also find that we actually use the CLI, the underlying is also "
"achieved by calling this REST API ~"

#: src/2-3-key-containers.md:157
msgid "## 平台监控容器：pmon（Platform Monitor）"
msgstr "## Platform Monitor container: pmon (Platform Monitor)"

#: src/2-3-key-containers.md:159
msgid ""
"这个容器里面的服务基本都是用来监控交换机一些基础硬件的运行状态的，比如温度，"
"电源，风扇，SFP事件等等。同样，我们可以用`ps`命令来查看这个容器中运行的服务："
msgstr ""
"The services inside this container are basically used to monitor the "
"operational status of some basic hardware of the switch, such as "
"temperature, power, fans, SFP events, etc. Again, we can use the `ps` "
"command to view the services running in this container:"

#: src/2-3-key-containers.md:161
msgid ""
"```bash\n"
"admin@sonic:~$ docker exec -it pmon bash\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          28  0.0  0.8  49972 33192 pts/0    S    Apr26   0:23 python3 /"
"usr/local/bin/ledd\n"
"root          29  0.9  1.0 278492 43816 pts/0    Sl   Apr26  34:41 python3 /"
"usr/local/bin/xcvrd\n"
"root          30  0.4  1.0  57660 40412 pts/0    S    Apr26  18:41 python3 /"
"usr/local/bin/psud\n"
"root          32  0.0  1.0  57172 40088 pts/0    S    Apr26   0:02 python3 /"
"usr/local/bin/syseepromd\n"
"root          33  0.0  1.0  58648 41400 pts/0    S    Apr26   0:27 python3 /"
"usr/local/bin/thermalctld\n"
"root          34  0.0  1.3  70044 53496 pts/0    S    Apr26   0:46 /usr/bin/"
"python3 /usr/local/bin/pcied\n"
"root          42  0.0  0.0  55320  1136 ?        Ss   Apr26   0:15 /usr/sbin/"
"sensord -f daemon\n"
"root          45  0.0  0.8  58648 32220 pts/0    S    Apr26   2:45 python3 /"
"usr/local/bin/thermalctld\n"
"...\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ docker exec -it pmon bash\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          28  0.0  0.8  49972 33192 pts/0    S    Apr26   0:23 python3 /"
"usr/local/bin/ledd\n"
"root          29  0.9  1.0 278492 43816 pts/0    Sl   Apr26  34:41 python3 /"
"usr/local/bin/xcvrd\n"
"root          30  0.4  1.0  57660 40412 pts/0    S    Apr26  18:41 python3 /"
"usr/local/bin/psud\n"
"root          32  0.0  1.0  57172 40088 pts/0    S    Apr26   0:02 python3 /"
"usr/local/bin/syseepromd\n"
"root          33  0.0  1.0  58648 41400 pts/0    S    Apr26   0:27 python3 /"
"usr/local/bin/thermalctld\n"
"root          34  0.0  1.3  70044 53496 pts/0    S    Apr26   0:46 /usr/bin/"
"python3 /usr/local/bin/pcied\n"
"root          42  0.0  0.0  55320  1136 ?        Ss   Apr26   0:15 /usr/sbin/"
"sensord -f daemon\n"
"root          45  0.0  0.8  58648 32220 pts/0    S    Apr26   2:45 python3 /"
"usr/local/bin/thermalctld\n"
"...\n"
"```"

#: src/2-3-key-containers.md:177
msgid ""
"其中大部分的服务从名字我们就能猜出来是做什么的了，中间只有xcvrd不是那么明显，"
"这里xcvr是transceiver的缩写，它是用来监控交换机的光模块的，比如SFP，QSFP等"
"等。"
msgstr ""
"Most of these services we can guess what they do from the name, only xcvrd "
"in the middle is not so obvious, here xcvr is the abbreviation of "
"transceiver, it is used to monitor the optical modules of the switch, such "
"as SFP, QSFP and so on."

#: src/2-3-key-containers.md:181
msgid ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [SONiC Management Framework][SONiCMgmtFramework]"
msgstr ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [SONiC Management Framework][SONiCMgmtFramework]"

#: src/2-4-sai-intro.md:1
msgid "# SAI"
msgstr "# SAI"

#: src/2-4-sai-intro.md:3
msgid ""
"SAI（Switch Abstraction Interface，交换机抽象接口）是SONiC的基石，正因为有了"
"它，SONiC才能支持多种硬件平台。我们在[这个SAI API的文档][SAIAPI]中，可以看到"
"它定义的所有接口。"
msgstr ""
"The SAI (Switch Abstraction Interface) is the cornerstone of SONiC, and it "
"is because of it that SONiC can support multiple hardware platforms. We can "
"see all the interfaces it defines in [this SAI API's documentation][SAIAPI]."

#: src/2-4-sai-intro.md:5
msgid ""
"[在核心容器一节中我们提到，SAI运行在`syncd`容器中](./2-3-key-containers."
"html)。不过和其他组件不同，它并不是一个服务，而是一组公共的头文件和动态链接库"
"（.so）。其中，所有的抽象接口都以c语言头文件的方式定义在了[OCP的SAI仓库]"
"[OCPSAI]中，而.so文件则由各个硬件厂商提供，用于实现SAI的接口。"
msgstr ""
"[As we mentioned in the section on core containers, SAI runs in the `syncd` "
"container](. /2-3-key-containers.html). Unlike other components, however, it "
"is not a service, but a set of public header files and dynamic link "
"libraries (.so). Among them, all abstract interfaces are defined in the "
"[OCP's SAI repository][OCPSAI] as c language header files, while .so files "
"are provided by individual hardware vendors for implementing the SAI "
"interfaces."

#: src/2-4-sai-intro.md:7
msgid "## SAI接口"
msgstr "## SAI Interface"

#: src/2-4-sai-intro.md:9
msgid ""
"为了有一个更加直观的理解，我们拿一小部分代码来展示一下SAI的接口定义和初始化的"
"方法，如下："
msgstr ""
"To have a more intuitive understanding, let's take a small part of the code "
"to show how the SAI interface is defined and initialized, as follows:"

#: src/2-4-sai-intro.md:11
msgid ""
"```cpp\n"
"// File: meta/saimetadata.h\n"
"typedef struct _sai_apis_t {\n"
"    sai_switch_api_t* switch_api;\n"
"    sai_port_api_t* port_api;\n"
"    ...\n"
"} sai_apis_t;\n"
"\n"
"// File: inc/saiswitch.h\n"
"typedef struct _sai_switch_api_t\n"
"{\n"
"    sai_create_switch_fn                   create_switch;\n"
"    sai_remove_switch_fn                   remove_switch;\n"
"    sai_set_switch_attribute_fn            set_switch_attribute;\n"
"    sai_get_switch_attribute_fn            get_switch_attribute;\n"
"    ...\n"
"} sai_switch_api_t;\n"
"\n"
"// File: inc/saiport.h\n"
"typedef struct _sai_port_api_t\n"
"{\n"
"    sai_create_port_fn                     create_port;\n"
"    sai_remove_port_fn                     remove_port;\n"
"    sai_set_port_attribute_fn              set_port_attribute;\n"
"    sai_get_port_attribute_fn              get_port_attribute;\n"
"    ...\n"
"} sai_port_api_t;\n"
"```"
msgstr ""
"```cpp\n"
"// File: meta/saimetadata.h\n"
"typedef struct _sai_apis_t {\n"
"    sai_switch_api_t* switch_api;\n"
"    sai_port_api_t* port_api;\n"
"    ...\n"
"} sai_apis_t;\n"
"\n"
"// File: inc/saiswitch.h\n"
"typedef struct _sai_switch_api_t\n"
"{\n"
"    sai_create_switch_fn                   create_switch;\n"
"    sai_remove_switch_fn                   remove_switch;\n"
"    sai_set_switch_attribute_fn            set_switch_attribute;\n"
"    sai_get_switch_attribute_fn            get_switch_attribute;\n"
"    ...\n"
"} sai_switch_api_t;\n"
"\n"
"// File: inc/saiport.h\n"
"typedef struct _sai_port_api_t\n"
"{\n"
"    sai_create_port_fn                     create_port;\n"
"    sai_remove_port_fn                     remove_port;\n"
"    sai_set_port_attribute_fn              set_port_attribute;\n"
"    sai_get_port_attribute_fn              get_port_attribute;\n"
"    ...\n"
"} sai_port_api_t;\n"
"```"

#: src/2-4-sai-intro.md:40
msgid ""
"其中，`sai_apis_t`结构体是SAI所有模块的接口的集合，其中每个成员都是一个特定模"
"块的接口列表的指针。我们用`sai_switch_api_t`来举例，它定义了SAI Switch模块的"
"所有接口，我们在`inc/saiswitch.h`中可以看到它的定义。同样的，我们在`inc/"
"saiport.h`中可以看到SAI Port模块的接口定义。"
msgstr ""
"where the `sai_apis_t` structure is a collection of interfaces for all SAI "
"modules, where each member is a pointer to a list of interfaces for a "
"particular module. Let's use `sai_switch_api_t` as an example, which defines "
"all the interfaces of the SAI Switch module, which we can see defined in "
"`inc/saiswitch.h`. Similarly, we can see the interface definitions for the "
"SAI Port module in `inc/saiport.h`."

#: src/2-4-sai-intro.md:42
msgid "## SAI初始化"
msgstr "## SAI initialization"

#: src/2-4-sai-intro.md:44
msgid ""
"SAI的初始化其实就是想办法获取上面这些函数指针，这样我们就可以通过SAI的接口来"
"操作ASIC了。"
msgstr ""
"The initialization of the SAI is actually figuring out how to get these "
"function pointers above so that we can operate the ASIC through the SAI's "
"interface."

#: src/2-4-sai-intro.md:46
msgid "参与SAI初始化的主要函数有两个，他们都定义在`inc/sai.h`中："
msgstr ""
"There are two main functions involved in the initialization of the SAI, both "
"of which are defined in `inc/sai.h`:"

#: src/2-4-sai-intro.md:48
msgid ""
"- `sai_api_initialize`：初始化SAI\n"
"- `sai_api_query`：传入SAI的API的类型，获取对应的接口列表"
msgstr ""
"- `sai_api_initialize`: initialize SAI\n"
"- `sai_api_query`: pass in the type of SAI's API and get the list of "
"corresponding interfaces"

#: src/2-4-sai-intro.md:51
msgid ""
"虽然大部分厂商的SAI实现是闭源的，但是mellanox却开源了自己的SAI实现，所以这里"
"我们可以借助其更加深入的理解SAI是如何工作的。"
msgstr ""
"While most vendors' SAI implementations are closed source, mellanox has open "
"sourced its own SAI implementation, so here we can use it to understand more "
"deeply how SAI works."

#: src/2-4-sai-intro.md:53
msgid ""
"比如，`sai_api_initialize`函数其实就是简单的设置设置两个全局变量，然后返回"
"`SAI_STATUS_SUCCESS`："
msgstr ""
"For example, the `sai_api_initialize` function actually simply sets sets two "
"global variables and returns `SAI_STATUS_SUCCESS`:"

#: src/2-4-sai-intro.md:55
msgid ""
"```cpp\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_interfacequery.c\n"
"sai_status_t sai_api_initialize(_In_ uint64_t flags, _In_ const "
"sai_service_method_table_t* services)\n"
"{\n"
"    if (g_initialized) {\n"
"        return SAI_STATUS_FAILURE;\n"
"    }\n"
"    // Validate parameters here (code omitted)\n"
"\n"
"    memcpy(&g_mlnx_services, services, sizeof(g_mlnx_services));\n"
"    g_initialized = true;\n"
"    return SAI_STATUS_SUCCESS;\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_interfacequery.c\n"
"sai_status_t sai_api_initialize(_In_ uint64_t flags, _In_ const "
"sai_service_method_table_t* services)\n"
"{\n"
"    if (g_initialized) {\n"
"        return SAI_STATUS_FAILURE;\n"
"    }\n"
"    // Validate parameters here (code omitted)\n"
"\n"
"    memcpy(&g_mlnx_services, services, sizeof(g_mlnx_services));\n"
"    g_initialized = true;\n"
"    return SAI_STATUS_SUCCESS;\n"
"}\n"
"```"

#: src/2-4-sai-intro.md:70
msgid ""
"初始化完成后，我们就可以使用`sai_api_query`函数，通过传入API的类型来查询对应"
"的接口列表，而每一个接口列表其实都是一个全局变量："
msgstr ""
"After initialization, we can use the `sai_api_query` function to query the "
"corresponding interface list by passing in the type of the API, and each "
"interface list is actually a global variable: the"

#: src/2-4-sai-intro.md:72
msgid ""
"```cpp\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_interfacequery.c\n"
"sai_status_t sai_api_query(_In_ sai_api_t sai_api_id, _Out_ void** "
"api_method_table)\n"
"{\n"
"    if (!g_initialized) {\n"
"        return SAI_STATUS_UNINITIALIZED;\n"
"    }\n"
"    ...\n"
"\n"
"    return sai_api_query_eth(sai_api_id, api_method_table);\n"
"}\n"
"\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_interfacequery_eth.c\n"
"sai_status_t sai_api_query_eth(_In_ sai_api_t sai_api_id, _Out_ void** "
"api_method_table)\n"
"{\n"
"    switch (sai_api_id) {\n"
"    case SAI_API_BRIDGE:\n"
"        *(const sai_bridge_api_t**)api_method_table = &mlnx_bridge_api;\n"
"        return SAI_STATUS_SUCCESS;\n"
"    case SAI_API_SWITCH:\n"
"        *(const sai_switch_api_t**)api_method_table = &mlnx_switch_api;\n"
"        return SAI_STATUS_SUCCESS;\n"
"    ...\n"
"    default:\n"
"        if (sai_api_id >= (sai_api_t)SAI_API_EXTENSIONS_RANGE_END) {\n"
"            return SAI_STATUS_INVALID_PARAMETER;\n"
"        } else {\n"
"            return SAI_STATUS_NOT_IMPLEMENTED;\n"
"        }\n"
"    }\n"
"}\n"
"\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_bridge.c\n"
"const sai_bridge_api_t mlnx_bridge_api = {\n"
"    mlnx_create_bridge,\n"
"    mlnx_remove_bridge,\n"
"    mlnx_set_bridge_attribute,\n"
"    mlnx_get_bridge_attribute,\n"
"    ...\n"
"};\n"
"\n"
"\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_switch.c\n"
"const sai_switch_api_t mlnx_switch_api = {\n"
"    mlnx_create_switch,\n"
"    mlnx_remove_switch,\n"
"    mlnx_set_switch_attribute,\n"
"    mlnx_get_switch_attribute,\n"
"    ...\n"
"};\n"
"```"
msgstr ""
"```cpp\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_interfacequery.c\n"
"sai_status_t sai_api_query(_In_ sai_api_t sai_api_id, _Out_ void** "
"api_method_table)\n"
"{\n"
"    if (!g_initialized) {\n"
"        return SAI_STATUS_UNINITIALIZED;\n"
"    }\n"
"    ...\n"
"\n"
"    return sai_api_query_eth(sai_api_id, api_method_table);\n"
"}\n"
"\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_interfacequery_eth.c\n"
"sai_status_t sai_api_query_eth(_In_ sai_api_t sai_api_id, _Out_ void** "
"api_method_table)\n"
"{\n"
"    switch (sai_api_id) {\n"
"    case SAI_API_BRIDGE:\n"
"        *(const sai_bridge_api_t**)api_method_table = &mlnx_bridge_api;\n"
"        return SAI_STATUS_SUCCESS;\n"
"    case SAI_API_SWITCH:\n"
"        *(const sai_switch_api_t**)api_method_table = &mlnx_switch_api;\n"
"        return SAI_STATUS_SUCCESS;\n"
"    ...\n"
"    default:\n"
"        if (sai_api_id >= (sai_api_t)SAI_API_EXTENSIONS_RANGE_END) {\n"
"            return SAI_STATUS_INVALID_PARAMETER;\n"
"        } else {\n"
"            return SAI_STATUS_NOT_IMPLEMENTED;\n"
"        }\n"
"    }\n"
"}\n"
"\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_bridge.c\n"
"const sai_bridge_api_t mlnx_bridge_api = {\n"
"    mlnx_create_bridge,\n"
"    mlnx_remove_bridge,\n"
"    mlnx_set_bridge_attribute,\n"
"    mlnx_get_bridge_attribute,\n"
"    ...\n"
"};\n"
"\n"
"\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_switch.c\n"
"const sai_switch_api_t mlnx_switch_api = {\n"
"    mlnx_create_switch,\n"
"    mlnx_remove_switch,\n"
"    mlnx_set_switch_attribute,\n"
"    mlnx_get_switch_attribute,\n"
"    ...\n"
"};\n"
"```"

#: src/2-4-sai-intro.md:124
msgid "## SAI的使用"
msgstr "## Use of SAI"

#: src/2-4-sai-intro.md:126
msgid ""
"在`syncd`容器中，SONiC会在启动时启动`syncd`服务，而`syncd`服务会加载当前系统"
"中的SAI组件。这个组件由各个厂商提供，它们会根据自己的硬件平台来实现上面展现的"
"SAI的接口，从而让SONiC使用统一的上层逻辑来控制多种不同的硬件平台。"
msgstr ""
"In the `syncd` container, SONiC will start the `syncd` service at boot time, "
"and the `syncd` service will load the SAI component currently on the system. "
"This component is provided by individual vendors, who will implement the "
"interface to the SAI shown above according to their own hardware platforms, "
"thus allowing SONiC to control many different hardware platforms using a "
"unified upper layer logic."

#: src/2-4-sai-intro.md:128
msgid "我们可以通过`ps`, `ls`和`nm`命令来简单的对这个进行验证："
msgstr "We can verify this simply by using the `ps`, `ls` and `nm` commands:"

#: src/2-4-sai-intro.md:130
msgid ""
"```bash\n"
"# Enter into syncd container\n"
"admin@sonic:~$ docker exec -it syncd bash\n"
"\n"
"# List all processes. We will only see syncd process here.\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          21  0.0  0.0  87708  1532 pts/0    Sl   16:20   0:00 /usr/bin/"
"dsserve /usr/bin/syncd --diag -u -s -p /etc/sai.d/sai.profile -b /tmp/"
"break_before_make_objects\n"
"root          33 11.1 15.0 2724396 602532 pts/0  Sl   16:20  36:30 /usr/bin/"
"syncd --diag -u -s -p /etc/sai.d/sai.profile -b /tmp/"
"break_before_make_objects\n"
"...\n"
"\n"
"# Find all libsai*.so.* files.\n"
"root@sonic:/# find / -name libsai*.so.*\n"
"/usr/lib/x86_64-linux-gnu/libsaimeta.so.0\n"
"/usr/lib/x86_64-linux-gnu/libsaimeta.so.0.0.0\n"
"/usr/lib/x86_64-linux-gnu/libsaimetadata.so.0.0.0\n"
"/usr/lib/x86_64-linux-gnu/libsairedis.so.0.0.0\n"
"/usr/lib/x86_64-linux-gnu/libsairedis.so.0\n"
"/usr/lib/x86_64-linux-gnu/libsaimetadata.so.0\n"
"/usr/lib/libsai.so.1\n"
"/usr/lib/libsai.so.1.0\n"
"\n"
"# Copy the file out of switch and check libsai.so on your own dev machine.\n"
"# We will see the most important SAI export functions here.\n"
"$ nm -C -D ./libsai.so.1.0 > ./sai-exports.txt\n"
"$ vim sai-exports.txt\n"
"...\n"
"0000000006581ae0 T sai_api_initialize\n"
"0000000006582700 T sai_api_query\n"
"0000000006581da0 T sai_api_uninitialize\n"
"...\n"
"```"
msgstr ""
"```bash\n"
"# Enter into syncd container\n"
"admin@sonic:~$ docker exec -it syncd bash\n"
"\n"
"# List all processes. We will only see syncd process here.\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          21  0.0  0.0  87708  1532 pts/0    Sl   16:20   0:00 /usr/bin/"
"dsserve /usr/bin/syncd --diag -u -s -p /etc/sai.d/sai.profile -b /tmp/"
"break_before_make_objects\n"
"root          33 11.1 15.0 2724396 602532 pts/0  Sl   16:20  36:30 /usr/bin/"
"syncd --diag -u -s -p /etc/sai.d/sai.profile -b /tmp/"
"break_before_make_objects\n"
"...\n"
"\n"
"# Find all libsai*.so.* files.\n"
"root@sonic:/# find / -name libsai*.so.*\n"
"/usr/lib/x86_64-linux-gnu/libsaimeta.so.0\n"
"/usr/lib/x86_64-linux-gnu/libsaimeta.so.0.0.0\n"
"/usr/lib/x86_64-linux-gnu/libsaimetadata.so.0.0.0\n"
"/usr/lib/x86_64-linux-gnu/libsairedis.so.0.0.0\n"
"/usr/lib/x86_64-linux-gnu/libsairedis.so.0\n"
"/usr/lib/x86_64-linux-gnu/libsaimetadata.so.0\n"
"/usr/lib/libsai.so.1\n"
"/usr/lib/libsai.so.1.0\n"
"\n"
"# Copy the file out of switch and check libsai.so on your own dev machine.\n"
"# We will see the most important SAI export functions here.\n"
"$ nm -C -D ./libsai.so.1.0 > ./sai-exports.txt\n"
"$ vim sai-exports.txt\n"
"...\n"
"0000000006581ae0 T sai_api_initialize\n"
"0000000006582700 T sai_api_query\n"
"0000000006581da0 T sai_api_uninitialize\n"
"...\n"
"```"

#: src/2-4-sai-intro.md:166
msgid ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [SAI API][SAIAPI]\n"
"3. [Forwarding Metamorphosis: Fast Programmable Match-Action Processing in "
"Hardware for SDN][PISA]\n"
"4. [Github: sonic-net/sonic-sairedis][SONiCSAIRedis]\n"
"5. [Github: opencomputeproject/SAI][OCPSAI]\n"
"6. [Arista 7050QX Series 10/40G Data Center Switches Data Sheet]"
"[Arista7050QX]\n"
"7. [Github repo: Nvidia (Mellanox) SAI implementation][MnlxSAI]"
msgstr ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [SAI API][SAIAPI]\n"
"3. [Forwarding Metamorphosis: Fast Programmable Match-Action Processing in "
"Hardware for SDN][PISA]\n"
"4. [Github: sonic-net/sonic-sairedis][SONiCSAIRedis]\n"
"5. [Github: opencomputeproject/SAI][OCPSAI]\n"
"6. [Arista 7050QX Series 10/40G Data Center Switches Data Sheet]"
"[Arista7050QX]\n"
"7. [Github repo: Nvidia (Mellanox) SAI implementation][MnlxSAI]"

#: src/3-dev-guide.md:1
msgid "# 开发上手指南"
msgstr "# Development Tutorial"

#: src/3-1-code-repos.md:1
msgid "# 代码仓库"
msgstr "# Code Repository"

#: src/3-1-code-repos.md:3
msgid ""
"SONiC的代码都托管在[GitHub的sonic-net账号][SONiCGitHub]上，仓库数量有30几个之"
"多，所以刚开始看SONiC的代码时，肯定是会有点懵的，不过不用担心，我们这里就来一"
"起看看～"
msgstr ""
"SONiC's code is hosted on [GitHub's sonic-net account][SONiCGitHub], and "
"there are more than 30 repositories, so when you first start looking at "
"SONiC's code, you'll definitely be a little confused, but don't worry, let's "
"take a look together here ~"

#: src/3-1-code-repos.md:5
msgid "## 核心仓库"
msgstr "## Core Warehouse"

#: src/3-1-code-repos.md:7
msgid "首先是SONiC中最重要的两个核心仓库：SONiC和sonic-buildimage。"
msgstr ""
"First are the two most important core repositories in SONiC: SONiC and sonic-"
"buildimage."

#: src/3-1-code-repos.md:9
msgid "### Landing仓库：SONiC"
msgstr "### Landing warehouse: SONiC"

#: src/3-1-code-repos.md:11
msgid "<https://github.com/sonic-net/SONiC>"
msgstr "<https://github.com/sonic-net/SONiC>"

#: src/3-1-code-repos.md:13
msgid ""
"这个仓库里面存储着SONiC的Landing Page和大量的文档，Wiki，教程，以往的Talk的"
"Slides，等等等等。这个仓库可以说是每个新人上手最常用的仓库了，但是注意，这个"
"仓库里面**没有任何的代码**，只有文档。"
msgstr ""
"This repository stores SONiC's Landing Page and a lot of documentation, "
"wiki, tutorials, Slides from previous Talks, etc. etc. This repository can "
"be said to be the most common repository for every newcomer to get started, "
"but note that there is **no code** in this repository, only documentation."

#: src/3-1-code-repos.md:15
msgid "### 镜像构建仓库：sonic-buildimage"
msgstr "### Image build repository: sonic-buildimage"

#: src/3-1-code-repos.md:17
msgid "<https://github.com/sonic-net/sonic-buildimage>"
msgstr "<https://github.com/sonic-net/sonic-buildimage>"

#: src/3-1-code-repos.md:19
msgid ""
"这个构建仓库为什么对于我们十分重要？和其他项目不同，**SONiC的构建仓库其实才是"
"它的主仓库**！这个仓库里面包含："
msgstr ""
"Why is this build repository important to us? Unlike other projects, "
"**SONiC's build repository is actually its main repository**! This "
"repository contains:"

#: src/3-1-code-repos.md:21
msgid ""
"- 所有的功能实现仓库，它们都以submodule的形式被加入到了这个仓库中（`src`目"
"录）\n"
"- 所有设备厂商的支持文件（`device`目录），比如每个型号的交换机的配置文件，用"
"来访问硬件的支持脚本，等等等等，比如：我的交换机是Arista 7050 QX-32S，那么我"
"就可以在`device/arista/x86_64-arista_7050_qx32s`目录中找到它的支持文件。\n"
"- 所有ASIC芯片厂商提供的支持文件（`platform`目录），比如每个平台的驱动程序，"
"BSP，底层支持的脚本等等。这里我们可以看到几乎所有的主流芯片厂商的支持文件，比"
"如：Broadcom，Mellanox，等等，也有用来做模拟软交换机的实现，比如vs和p4。\n"
"- SONiC用来构建所有容器镜像的Dockerfile（`dockers`目录）\n"
"- 各种各样通用的配置文件和脚本（`files`目录）\n"
"- 用来做构建的编译容器的dockerfile（`sonic-slave-*`目录）\n"
"- 等等……"
msgstr ""
"- All the feature implementation repositories, they are added to this "
"repository as submodule (`src` directory)\n"
"- Support files for all device vendors (`device` directory), such as "
"configuration files for each model of switch, support scripts for accessing "
"hardware, etc. etc. For example: my switch is an Arista 7050 QX-32S, so I "
"can find its support files in the `device/arista/x86_64-arista_7050_qx32s ` "
"directory to find its support files.\n"
"- Support files provided by all ASIC chip vendors (`platform` directory), "
"such as drivers for each platform, BSP, underlying support scripts, etc. "
"Here we can see support files from almost all major chip vendors, such as: "
"Broadcom, Mellanox, etc. There are also implementations used to make "
"emulated soft switches, such as vs and p4.\n"
"- The Dockerfile (`dockers` directory) that SONiC uses to build all "
"container images\n"
"- Various generic configuration files and scripts (`files` directory)\n"
"- Dockerfile for compiled containers used to do builds (`sonic-slave-*` "
"directory)\n"
"- etc. ......"

#: src/3-1-code-repos.md:29
msgid ""
"正因为这个仓库里面将所有相关的资源全都放在了一起，所以我们学习SONiC的代码时，"
"基本只需要下载这一个源码仓库就可以了，不管是搜索还是跳转都非常方便！"
msgstr ""
"Because this repository has all the relevant resources put together, we "
"basically only need to download this one source code repository when "
"learning SONiC's code, no matter it is very convenient to search or jump!"

#: src/3-1-code-repos.md:31
msgid "## 功能实现仓库"
msgstr "## Function Implementation Warehouse"

#: src/3-1-code-repos.md:33
msgid ""
"除了核心仓库，SONiC下还有很多功能实现仓库，里面都是各个容器和子服务的实现，这"
"些仓库都被以submodule的形式放在了sonic-buildimage的`src`目录下，如果我们想对"
"SONiC进行修改和贡献，我们也需要了解一下。"
msgstr ""
"In addition to the core repository, there are also many feature "
"implementation repositories under SONiC, which are implementations of "
"various containers and subservices. These repositories are placed under the "
"`src` directory of sonic-buildimage in the form of submodule, which we also "
"need to know if we want to make changes and contributions to SONiC."

#: src/3-1-code-repos.md:35
msgid "### SWSS（Switch State Service）相关仓库"
msgstr "### SWSS (Switch State Service) related repository"

#: src/3-1-code-repos.md:37
msgid ""
"在上一篇中我们介绍过，SWSS容器是SONiC的大脑，在SONiC下，它由两个repo组成："
"[sonic-swss-common](https://github.com/sonic-net/sonic-swss-common)和[sonic-"
"swss](https://github.com/sonic-net/sonic-swss)。"
msgstr ""
"As we introduced in the previous article, the SWSS container is the brain of "
"SONiC. Under SONiC, it consists of two repo's: [sonic-swss-common](https://"
"github.com/sonic-net/sonic-swss-common) and [sonic-swss]( https://github.com/"
"sonic-net/sonic-swss)."

#: src/3-1-code-repos.md:39
msgid "#### SWSS公共库：sonic-swss-common"
msgstr "#### SWSS public library: sonic-swss-common"

#: src/3-1-code-repos.md:41
msgid ""
"首先是公共库：sonic-swss-common（<https://github.com/sonic-net/sonic-swss-"
"common>）。"
msgstr ""
"First is the public library: sonic-swss-common (<https://github.com/sonic-"
"net/sonic-swss-common>)."

#: src/3-1-code-repos.md:43
msgid ""
"这个仓库里面包含了所有`*mgrd`和`*syncd`服务所需要的公共功能，比如，logger，"
"json，netlink的封装，Redis操作和基于Redis的各种服务间通讯机制的封装等等。虽然"
"能看出来这个仓库一开始的目标是专门给swss服务使用的，但是也正因为功能多，很多"
"其他的仓库都有它的引用，比如`swss-sairedis`和`swss-restapi`。"
msgstr ""
"This repository contains all the public functions required by the `*mgrd` "
"and `*syncd` services, such as the encapsulation of logger, json, netlink, "
"Redis operations and various Redis-based inter-service communication "
"mechanisms. Although it can be seen that this repository was initially "
"targeted specifically for use by the swss service, it is also referenced by "
"many other repositories, such as `swss-sairedis` and `swss-restapi`, because "
"of its many features."

#: src/3-1-code-repos.md:45
msgid "#### SWSS主仓库：sonic-swss"
msgstr "#### SWSS main repository: sonic-swss"

#: src/3-1-code-repos.md:47
msgid ""
"然后就是SWSS的主仓库sonic-swss了：<https://github.com/sonic-net/sonic-swss>。"
msgstr ""
"Then there is the main SWSS repository, sonic-swss: <https://github.com/"
"sonic-net/sonic-swss>."

#: src/3-1-code-repos.md:49
msgid "我们可以在这个仓库中找到："
msgstr "We can find in this repository:"

#: src/3-1-code-repos.md:51
msgid ""
"- 绝大部分的`*mgrd`和`*syncd`服务：`orchagent`, `portsyncd/portmgrd/"
"intfmgrd`，`neighsyncd/nbrmgrd`，`natsyncd/natmgrd`，`buffermgrd`，"
"`coppmgrd`，`macsecmgrd`，`sflowmgrd`，`tunnelmgrd`，`vlanmgrd`，`vrfmgrd`，"
"`vxlanmgrd`，等等。\n"
"- `swssconfig`：在`swssconfig`目录下，用于在快速重启时（fast reboot）恢复FDB"
"和ARP表。\n"
"- `swssplayer`：也在`swssconfig`目录下，用来记录所有通过SWSS进行的配置下发操"
"作，这样我们就可以利用它来做replay，从而对问题进行重现和调试。\n"
"- 甚至一些不在SWSS容器中的服务，比如`fpmsyncd`（bgp容器）和`teamsyncd/"
"teammgrd`（teamd容器）。"
msgstr ""
"- Most of the `*mgrd` and `*syncd` services: `orchagent`, `portsyncd/"
"portmgrd/intfmgrd`, `neighsyncd/nbrmgrd`, `natsyncd/natmgrd`, `buffermgrd`, "
"`coppmgrd` , `macsecmgrd`, `sflowmgrd`, `tunnelmgrd`, `vlanmgrd`, `vrfmgrd`, "
"`vxlanmgrd`, etc.\n"
"- `swssconfig`: in the `swssconfig` directory, used to restore the FDB and "
"ARP tables during fast reboot (fast reboot).\n"
"- `swssplayer`: also in the `swssconfig` directory, used to record all "
"configuration downlink operations performed via SWSS, so we can use it to do "
"replay and thus reproduce and debug the problem.\n"
"- Even some services that are not in the SWSS container, such as `fpmsyncd` "
"(bgp container) and `teamsyncd/teammgrd` (teamd container)."

#: src/3-1-code-repos.md:56
msgid "### SAI/平台相关仓库"
msgstr "### SAI/platform related warehouses"

#: src/3-1-code-repos.md:58
msgid ""
"接下来就是作为交换机抽象接口的SAI了，[虽然SAI是微软提出来并在2015年3月份发布"
"了0.1版本](https://www.opencompute.org/documents/switch-abstraction-"
"interface-ocp-specification-v0-2-pdf)，但是[在2015年9月份，SONiC都还没有发布"
"第一个版本的时候，就已经被OCP接收并作为一个公共的标准了](https://azure."
"microsoft.com/en-us/blog/switch-abstraction-interface-sai-officially-"
"accepted-by-the-open-compute-project-ocp/)，这也是SONiC能够在这么短的时间内就"
"得到了这么多厂商的支持的原因之一。而也因为如此，SAI的代码仓库也被分成了两部"
"分："
msgstr ""
"Next up is SAI as a switch abstraction interface, [although SAI was proposed "
"by Microsoft and released in March 2015 as version 0.1](https://www."
"opencompute.org/documents/switch-abstraction-interface-ocp- specification-"
"v0-2-pdf), [it was accepted by OCP and made a public standard in September "
"2015, before SONiC even released the first version](https://azure.microsoft."
"com/en-us/blog/switch- abstraction-interface-sai-officially-accepted-by-the-"
"open-compute-project-ocp/), which is one of the reasons why SONiC has been "
"able to get support from so many vendors in such a short time. And because "
"of this, SAI's code repository has been divided into two parts:"

#: src/3-1-code-repos.md:60
msgid ""
"- OCP下的OpenComputeProject/SAI：<https://github.com/opencomputeproject/"
"SAI>。里面包含了有关SAI标准的所有代码，包括SAI的头文件，behavior model，测试"
"用例，文档等等。\n"
"- SONiC下的sonic-sairedis：<https://github.com/sonic-net/sonic-sairedis>。里"
"面包含了SONiC中用来和SAI交互的所有代码，比如syncd服务，和各种调试统计，比如用"
"来做replay的`saiplayer`和用来导出asic状态的`saidump`。"
msgstr ""
"- OpenComputeProject/SAI under OCP: <https://github.com/opencomputeproject/"
"SAI>. It contains all the code about the SAI standard, including SAI header "
"files, behavior model, test cases, documentation, etc.\n"
"- SONiC under sonic-sairedis: <https://github.com/sonic-net/sonic-sairedis>. "
"It contains all the code used in SONiC to interact with SAI, such as syncd "
"service, and various debugging statistics, such as `saiplayer` used to do "
"replay and `saidump` used to export asic state."

#: src/3-1-code-repos.md:63
msgid ""
"除了这两个仓库之外，还有一个平台相关的仓库，比如：[sonic-platform-vpp]"
"(https://github.com/sonic-net/sonic-platform-vpp)，它的作用是通过SAI的接口，"
"利用vpp来实现数据平面的功能，相当于一个高性能的软交换机，个人感觉未来可能会被"
"合并到buildimage仓库中，作为platform目录下的一部分。"
msgstr ""
"In addition to these two repositories, there is also a platform-related "
"repository, for example: [sonic-platform-vpp](https://github.com/sonic-net/"
"sonic-platform-vpp), which serves to implement data plane functions using "
"vpp through SAI's interface, equivalent to a High-performance soft switch. I "
"personally feel that it may be merged into the buildimage repository in the "
"future, as part of the platform directory."

#: src/3-1-code-repos.md:65
msgid "### 管理服务（mgmt）相关仓库"
msgstr "### Managed services (mgmt) related warehouses"

#: src/3-1-code-repos.md:67
msgid "然后是SONiC中所有和[管理服务][SONiCMgmtFramework]相关的仓库："
msgstr ""
"Then all the repositories in SONiC related to the [managed services]"
"[SONiCMgmtFramework]:"

#: src/3-1-code-repos.md:69
msgid ""
"| 名称 | 说明 |\n"
"| --- | --- |\n"
"| [sonic-mgmt-common](https://github.com/sonic-net/sonic-mgmt-common) | 管理"
"服务的基础库，里面包含着`translib`，yang model相关的代码 |\n"
"| [sonic-mgmt-framework](https://github.com/sonic-net/sonic-mgmt-framework) "
"| 使用Go来实现的REST Server，是下方架构图中的REST Gateway（进程名："
"`rest_server`） |\n"
"| [sonic-gnmi](https://github.com/sonic-net/sonic-gnmi) | 和sonic-mgmt-"
"framework类似，是下方架构图中，基于gRPC的gNMI（gRPC Network Management "
"Interface）Server |\n"
"| [sonic-restapi](https://github.com/sonic-net/sonic-restapi) | 这是SONiC使用"
"go来实现的另一个配置管理的REST Server，和mgmt-framework不同，这个server在收到"
"消息后会直接对CONFIG_DB进行操作，而不是走translib（下图中没有，进程名：`go-"
"server-server`） |\n"
"| [sonic-mgmt](https://github.com/sonic-net/sonic-mgmt) | 各种自动化脚本"
"（`ansible`目录），测试（`tests`目录），用来搭建test bed和测试上报"
"（`test_reporting`目录）之类的， |"
msgstr ""
"| Name | Description |\n"
"| --- | --- |\n"
"| [sonic-mgmt-common](https://github.com/sonic-net/sonic-mgmt-common) | The "
"base library for managing services, which contains `translib`, yang model "
"related code |\n"
"| [sonic-mgmt-framework](https://github.com/sonic-net/sonic-mgmt-framework) "
"| The REST Server, implemented using Go, is the REST Gateway in the "
"architecture diagram below (process name: `rest_server `)\n"
"| [sonic-gnmi](https://github.com/sonic-net/sonic-gnmi) | Similar to sonic-"
"mgmt-framework, this is the gRPC-based gNMI (gRPC Network Management "
"Interface) in the following diagram Server\n"
"| [sonic-restapi](https://github.com/sonic-net/sonic-restapi) | This is "
"another REST Server for configuration management implemented by SONiC using "
"go, unlike the mgmt-framework, this server will directly operate on "
"CONFIG_DB after receiving messages. This server will operate on CONFIG_DB "
"directly after receiving the message, instead of going translib (not in the "
"following figure, process name: `go-server-server`) |\n"
"| [sonic-mgmt](https://github.com/sonic-net/sonic-mgmt) | various automation "
"scripts (`ansible` directory), tests (`tests` directory), used to build test "
"beds and test reporting (`test_reporting` directory) and so on. |"

#: src/3-1-code-repos.md:77
msgid ""
"这里还是附上SONiC管理服务的架构图，方便大家配合食用 [\\[4\\]]"
"[SONiCMgmtFramework]："
msgstr ""
"Here is still attached the architecture diagram of SONiC management service "
"for your convenience with consumption [\\[4\\]][SONiCMgmtFramework]:"

#: src/3-1-code-repos.md:81
msgid "### 平台监控相关仓库：sonic-platform-common和sonic-platform-daemons"
msgstr ""
"### Platform monitoring related repositories: sonic-platform-common and "
"sonic-platform-daemons"

#: src/3-1-code-repos.md:83
msgid "以下两个仓库都和平台监控和控制相关，比如LED，风扇，电源，温控等等："
msgstr ""
"The following two warehouses are related to platform monitoring and control, "
"such as LEDs, fans, power supplies, temperature control, etc.:"

#: src/3-1-code-repos.md:85
msgid ""
"| 名称 | 说明 |\n"
"| --- | --- |\n"
"| [sonic-platform-common](https://github.com/sonic-net/sonic-platform-"
"common) | 这是给厂商们提供的基础包，用来定义访问风扇，LED，电源管理，温控等等"
"模块的接口定义，这些接口都是用python来实现的 |\n"
"| [sonic-platform-daemons](https://github.com/sonic-net/sonic-platform-"
"daemons) | 这里包含了SONiC中pmon容器中运行的各种监控服务：`chassisd`，"
"`ledd`，`pcied`，`psud`，`syseepromd`，`thermalctld`，`xcvrd`，`ycabled`，它"
"们都使用python实现，通过和中心数据库Redis进行连接，和加载并调用各个厂商提供的"
"接口实现来对各个模块进行监控和控制 |"
msgstr ""
"| Name | Description |\n"
"| --- | --- |\n"
"| [sonic-platform-common](https://github.com/sonic-net/sonic-platform-"
"common) | This is a base package for vendors to define interface definitions "
"for accessing modules such as fans, LEDs, power management, temperature "
"control, etc. These interfaces are all implemented using These interfaces "
"are implemented in python |\n"
"| [sonic-platform-daemons](https://github.com/sonic-net/sonic-platform-"
"daemons) | This contains the various monitoring services running in the pmon "
"container in SONiC: `chassisd`, `ledd`, ` pcied`, `psud`, `syseepromd`, "
"`thermalctld`, `xcvrd`, `ycabled`, all of which are implemented in python to "
"monitor and control each module by connecting to the central database Redis "
"and loading and calling the interfaces provided by each vendor."

#: src/3-1-code-repos.md:90
msgid "### 其他功能实现仓库"
msgstr "### Other function implementation warehouse"

#: src/3-1-code-repos.md:92
msgid ""
"除了上面这些仓库以外，SONiC还有很多实现其方方面面功能的仓库，有些是一个或多个"
"进程，有些是一些库，它们的作用如下表所示："
msgstr ""
"In addition to these repositories above, SONiC has a number of repositories "
"that implement various aspects of its functionality, some of which are one "
"or more processes, and some of which are libraries that serve the following "
"purposes:"

#: src/3-1-code-repos.md:94
msgid ""
"| 仓库 | 介绍 |\n"
"| --- | --- |\n"
"| [sonic-snmpagent](https://github.com/sonic-net/sonic-snmpagent) | [AgentX]"
"(https://www.ietf.org/rfc/rfc2741.txt) SNMP subagent的实现"
"（`sonic_ax_impl`），用于连接Redis数据库，给snmpd提供所需要的各种信息，可以把"
"它理解成snmpd的控制面，而snmpd是数据面，用于响应外部SNMP的请求 |\n"
"| [sonic-frr](https://github.com/sonic-net/sonic-frr) | FRRouting，各种路由协"
"议的实现，所以这个仓库中我们可以找到如`bgpd`，`zebra`这类的路由相关的进程实"
"现 |\n"
"| [sonic-linkmgrd](https://github.com/sonic-net/sonic-linkmgrd) | Dual ToR "
"support，检查Link的状态，并且控制ToR的连接 |\n"
"| [sonic-dhcp-relay](https://github.com/sonic-net/sonic-dhcp-relay) | DHCP "
"relay agent |\n"
"| [sonic-dhcpmon](https://github.com/sonic-net/sonic-dhcpmon) | 监控DHCP的状"
"态，并报告给中心数据库Redis |\n"
"| [sonic-dbsyncd](https://github.com/sonic-net/sonic-dbsyncd) | `lldp_syncd`"
"服务，但是repo的名字没取好，叫做dbsyncd |\n"
"| [sonic-pins](https://github.com/sonic-net/sonic-pins) | Google开发的基于P4"
"的网络栈支持（P4 Integrated Network Stack，PINS），更多信息可以参看[PINS的官"
"网][SONiCPINS]。 |\n"
"| [sonic-stp](https://github.com/sonic-net/sonic-stp) | STP（Spanning Tree "
"Protocol）的支持 |\n"
"| [sonic-ztp](https://github.com/sonic-net/sonic-ztp) | [Zero Touch "
"Provisioning][SONiCZTP] |\n"
"| [DASH](https://github.com/sonic-net/DASH) | [Disaggregated API for SONiC "
"Hosts][SONiCDASH] |\n"
"| [sonic-host-services](https://github.com/sonic-net/sonic-host-services) | "
"运行在host上通过dbus用来为容器中的服务提供支持的服务，比如保存和重新加载配"
"置，保存dump之类的非常有限的功能，类似一个host broker |\n"
"| [sonic-fips](https://github.com/sonic-net/sonic-fips) | FIPS（Federal "
"Information Processing Standards）的支持，里面有很多为了支持FIPS标准而加入的"
"各种补丁文件 |\n"
"| [sonic-wpa-supplicant](https://github.com/sonic-net/sonic-wpa-supplicant) "
"| 各种无线网络协议的支持 |"
msgstr ""
"| Warehouse | Introduction |\n"
"| --- | --- |\n"
"| [sonic-snmpagent](https://github.com/sonic-net/sonic-snmpagent) | [AgentX]"
"(https://www.ietf.org/rfc/rfc2741.txt) The implementation of the SNMP "
"subagent (` sonic_ax_impl`), which is used to connect to the Redis database "
"and give snmpd the various information it needs, can be interpreted as the "
"control plane of snmpd, which is the data plane and is used to respond to "
"external SNMP requests |\n"
"| [sonic-frr](https://github.com/sonic-net/sonic-frr) | FRRouting, the "
"implementation of various routing protocols, so this repository we can find "
"such routing-related process implementations as `bgpd`, `zebra`, etc. |\n"
"| [sonic-linkmgrd](https://github.com/sonic-net/sonic-linkmgrd) | Dual ToR "
"support, check the status of Link and control the ToR connection |\n"
"| [sonic-dhcp-relay](https://github.com/sonic-net/sonic-dhcp-relay) | DHCP "
"relay agent |\n"
"| [sonic-dhcpmon](https://github.com/sonic-net/sonic-dhcpmon) | Monitor DHCP "
"status and report to the central database Redis |\n"
"| [sonic-dbsyncd](https://github.com/sonic-net/sonic-dbsyncd) | The "
"`lldp_syncd` service, but the repo is not named properly, it is called "
"dbsyncd |\n"
"| [sonic-pins](https://github.com/sonic-net/sonic-pins) | Google's P4-based "
"network stack support (P4 Integrated Network Stack, PINS), for more "
"information, see [PINS's official website][. SONiCPINS] for more "
"information. |SONiCPINS\n"
"| [sonic-stp](https://github.com/sonic-net/sonic-stp) | STP (Spanning Tree "
"Protocol) support |\n"
"| [sonic-ztp](https://github.com/sonic-net/sonic-ztp) | [Zero Touch "
"Provisioning][SONiCZTP] |\n"
"| [DASH](https://github.com/sonic-net/DASH) | [Disaggregated API for SONiC "
"Hosts][SONiCDASH] |\n"
"| [sonic-host-services](https://github.com/sonic-net/sonic-host-services) | "
"The services running on the host via dbus are used to provide support for "
"services in the container, such as saving and reloading configurations, "
"saving dumps, and other very limited This is similar to a host broker.\n"
"| [sonic-fips](https://github.com/sonic-net/sonic-fips) | FIPS (Federal "
"Information Processing Standards) support, which contains many of the "
"various patch files added to support the FIPS standard |\n"
"| [sonic-wpa-supplicant](https://github.com/sonic-net/sonic-wpa-supplicant) "
"| Support for various wireless network protocols |"

#: src/3-1-code-repos.md:110
msgid "## 工具仓库：sonic-utilities"
msgstr "## Tools repository: sonic-utilities"

#: src/3-1-code-repos.md:112
msgid "<https://github.com/sonic-net/sonic-utilities>"
msgstr "<https://github.com/sonic-net/sonic-utilities>"

#: src/3-1-code-repos.md:114
msgid "这个仓库存放着SONiC所有的命令行下的工具："
msgstr "This repository holds all of SONiC's tools under the command line:"

#: src/3-1-code-repos.md:116
msgid ""
"- `config`，`show`，`clear`目录：这是三个SONiC CLI的主命令的实现。需要注意的"
"是，具体的命令实现并不一定在这几个目录里面，大量的命令是通过调用其他命令来实"
"现的，这几个命令只是提供了一个入口。\n"
"- `scripts`，`sfputil`，`psuutil`，`pcieutil`，`fwutil`，`ssdutil`，"
"`acl_loader`目录：这些目录下提供了大量的工具命令，但是它们大多并不是直接给用"
"户使用的，而是被`config`，`show`和`clear`目录下的命令调用的，比如：`show "
"platform fan`命令，就是通过调用`scripts`目录下的`fanshow`命令来实现的。\n"
"- `utilities_common`，`flow_counter_util`，`syslog_util`目录：这些目录和上面"
"类似，但是提供的是基础类，可以直接在python中import调用。\n"
"- 另外还有很多其他的命令：`fdbutil`，`pddf_fanutil`，`pddf_ledutil`，"
"`pddf_psuutil`，`pddf_thermalutil`，等等，用于查看和控制各个模块的状态。\n"
"- `connect`和`consutil`目录：这两个目录下的命令是用来连接到其他SONiC设备并对"
"其进行管理的。\n"
"- `crm`目录：用来配置和查看SONiC中的[CRM（Critical Resource Monitoring）]"
"[SONiCCRM]。这个命令并没有被包含在`config`和`show`命令中，所以用户可以直接使"
"用。\n"
"- `pfc`目录：用来配置和查看SONiC中的[PFC（Priority-based Flow Control）]"
"[SONiCPFC]。\n"
"- `pfcwd`目录：用来配置和查看SONiC中的[PFC Watch Dog][SONiCPFCWD]，比如启动，"
"停止，修改polling interval之类的操作。"
msgstr ""
"- The `config`, `show`, and `clear` directories: these are the three main "
"command implementations of the SONiC CLI. Note that the specific command "
"implementations are not necessarily in these directories; a large number of "
"commands are implemented by calling other commands, and these commands just "
"provide an entry point.\n"
"- `scripts`, `sfputil`, `psuutil`, `pcieutil`, `fwutil`, `ssdutil`, "
"`acl_loader` directories: These directories provide a large number of "
"utility commands, but most of them are not directly available to the user, "
"but are called by the `config`, `show` and ` clear` directories. For "
"example, the `show platform fan` command is implemented by calling the "
"`fanshow` command in the `scripts` directory.\n"
"- `utilities_common`, `flow_counter_util`, `syslog_util` directories: these "
"directories are similar to the above, but provide basic classes that can be "
"directly imported in python.\n"
"- There are also many other commands: `fdbutil`, `pddf_fanutil`, "
"`pddf_ledutil`, `pddf_psuutil`, `pddf_thermalutil`, and so on, for viewing "
"and controlling the status of each module.\n"
"- `connect` and `consutil` directories: the commands in these two "
"directories are used to connect to other SONiC devices and manage them.\n"
"- `crm` directory: This is used to configure and view [CRM (Critical "
"Resource Monitoring)][SONiCCRM] in SONiC. This command is not included in "
"the `config` and `show` commands, so users can use it directly.\n"
"- `pfc` directory: used to configure and view [PFC (Priority-based Flow "
"Control)][SONiCPFC] in SONiC.\n"
"- `pfcwd` directory: used to configure and view the [PFC Watch Dog]"
"[SONiCPFCWD] in SONiC, such as start, stop, modify the polling interval and "
"other operations."

#: src/3-1-code-repos.md:125
msgid "## 内核补丁：sonic-linux-kernel"
msgstr "## Kernel patch: sonic-linux-kernel"

#: src/3-1-code-repos.md:127
msgid "<https://github.com/sonic-net/sonic-linux-kernel>"
msgstr "<https://github.com/sonic-net/sonic-linux-kernel>"

#: src/3-1-code-repos.md:129
msgid ""
"虽然SONiC是基于debian的，但是默认的debian内核却不一定能运行SONiC，比如某个模"
"块默认没有启动，或者某些老版本的驱动有问题，所以SONiC需要或多或少有一些修改的"
"Linux内核。而这个仓库就是用来存放所有的内核补丁的。"
msgstr ""
"Although SONiC is based on debian, the default debian kernel is not always "
"able to run SONiC, for example, a module is not started by default, or some "
"old version of the driver has problems, so SONiC needs a more or less "
"modified Linux kernel. And this repository is used to store all the kernel "
"patches."

#: src/3-1-code-repos.md:133
msgid ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [SONiC Source Repositories][SONiCRepo]\n"
"3. [SONiC Management Framework][SONiCMgmtFramework]\n"
"4. [SAI API][SAIAPI]\n"
"5. [SONiC Critical Resource Monitoring][SONiCCRM]\n"
"6. [SONiC Zero Touch Provisioning][SONiCZTP]\n"
"7. [SONiC Critical Resource Monitoring][SONiCCRM]\n"
"8. [SONiC P4 Integrated Network Stack][SONiCPINS]\n"
"9. [SONiC Disaggregated API for Switch Hosts][SONiCDash]\n"
"10. [SAI spec for OCP][SAISpec]"
msgstr ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [SONiC Source Repositories][SONiCRepo]\n"
"3. [SONiC Management Framework][SONiCMgmtFramework]\n"
"4. [SAI API][SAIAPI]\n"
"5. [SONiC Critical Resource Monitoring][SONiCCRM]\n"
"6. [SONiC Zero Touch Provisioning][SONiCZTP]\n"
"7. [SONiC Critical Resource Monitoring][SONiCCRM]\n"
"8. [SONiC P4 Integrated Network Stack][SONiCPINS]\n"
"9. [SONiC Disaggregated API for Switch Hosts][SONiCDash]\n"
"10. [SAI spec for OCP][SAISpec]"

#: src/3-2-compile.md:1
msgid "# 编译"
msgstr "# Compilation"

#: src/3-2-compile.md:3
msgid "## 编译环境"
msgstr "## Compiler Environment"

#: src/3-2-compile.md:5
msgid ""
"由于SONiC是基于debian开发的，为了保证我们无论在什么平台下都可以成功的编译"
"SONiC，并且编译出来的程序能在对应的平台上运行，SONiC使用了容器化的编译环境 "
"—— 它将所有的工具和依赖都安装在对应debian版本的docker容器中，然后将我们的代码"
"挂载进容器，最后在容器内部进行编译工作，这样我们就可以很轻松的在任何平台上编"
"译SONiC，而不用担心依赖不匹配的问题，比如有一些包在debian里的版本比ubuntu更"
"高，这样就可能导致最后的程序在debian上运行的时候出现一些意外的错误。"
msgstr ""
"Since SONiC is based on debian, in order to ensure that we can successfully "
"compile SONiC no matter what platform we are on, and that the compiled "
"program can run on the corresponding platform, SONiC uses a containerized "
"compilation environment -- it installs all the tools and dependencies in the "
"corresponding This allows us to easily compile SONiC on any platform without "
"worrying about dependency mismatches, such as packages that are higher in "
"debian than in ubuntu, which may lead to some problems when the final "
"program runs on This may lead to some unexpected errors when the final "
"program is run on debian."

#: src/3-2-compile.md:7
msgid "## 初始化编译环境"
msgstr "## Initialize the compilation environment"

#: src/3-2-compile.md:9
msgid "### 安装Docker"
msgstr "### Install Docker"

#: src/3-2-compile.md:11
msgid ""
"为了支持容器化的编译环境，第一步，我们需要保证我们的机器上安装了docker。"
msgstr ""
"In order to support a containerized build environment, as a first step, we "
"need to make sure that docker is installed on our machine."

#: src/3-2-compile.md:13
msgid ""
"Docker的安装方法可以参考[官方文档][DockerInstall]，这里我们以Ubuntu为例，简单"
"介绍一下安装方法。"
msgstr ""
"The installation method of Docker can be found in the [official "
"documentation][DockerInstall], here we take Ubuntu as an example and briefly "
"introduce the installation method."

#: src/3-2-compile.md:15
msgid "首先，我们需要把docker的源和证书加入到apt的源列表中："
msgstr ""
"First, we need to add the docker sources and certificates to the apt source "
"list: the"

#: src/3-2-compile.md:17
msgid ""
"```bash\n"
"sudo apt-get update\n"
"sudo apt-get install ca-certificates curl gnupg\n"
"\n"
"sudo install -m 0755 -d /etc/apt/keyrings\n"
"curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor "
"-o /etc/apt/keyrings/docker.gpg\n"
"sudo chmod a+r /etc/apt/keyrings/docker.gpg\n"
"\n"
"echo \\\n"
"  \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/"
"docker.gpg] https://download.docker.com/linux/ubuntu \\\n"
"  \"$(. /etc/os-release && echo \"$VERSION_CODENAME\")\" stable\" | \\\n"
"  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n"
"```"
msgstr ""
"```bash\n"
"sudo apt-get update\n"
"sudo apt-get install ca-certificates curl gnupg\n"
"\n"
"sudo install -m 0755 -d /etc/apt/keyrings\n"
"curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor "
"-o /etc/apt/keyrings/docker.gpg\n"
"sudo chmod a+r /etc/apt/keyrings/docker.gpg\n"
"\n"
"echo \\\n"
"  \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/"
"docker.gpg] https://download.docker.com/linux/ubuntu \\\n"
"  \"$(. /etc/os-release && echo \"$VERSION_CODENAME\")\" stable\" | \\\n"
"  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n"
"```"

#: src/3-2-compile.md:31
msgid "然后，我们就可以通过apt来快速安装啦："
msgstr "Then, we can quickly install it via apt:"

#: src/3-2-compile.md:33
msgid ""
"```bash\n"
"sudo apt-get update\n"
"sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-"
"plugin docker-compose-plugin\n"
"```"
msgstr ""
"```bash\n"
"sudo apt-get update\n"
"sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-"
"plugin docker-compose-plugin\n"
"```"

#: src/3-2-compile.md:38
msgid ""
"安装完docker的程序之后，我们还需要把当前的账户添加到docker的用户组中，然后**"
"退出并重新登录当前用户**，这样我们就可以不用sudo来运行docker命令了！**这一点"
"非常重要**，因为后续SONiC的build是不允许使用sudo的。"
msgstr ""
"After installing docker's program, we also need to add our current account "
"to docker's user group, then **quit and log back in as the current user** so "
"we can run docker commands without sudo! **This is very important** because "
"subsequent builds of SONiC do not allow sudo."

#: src/3-2-compile.md:40
msgid ""
"```bash\n"
"sudo gpasswd -a ${USER} docker\n"
"```"
msgstr ""
"```bash\n"
"sudo gpasswd -a ${USER} docker\n"
"```"

#: src/3-2-compile.md:44
msgid ""
"安装完成之后，别忘了通过以下命令来验证一下是否安装成功（注意，此处不需要"
"sudo！）："
msgstr ""
"Once the installation is complete, don't forget to verify that it was "
"successful by using the following command (note that sudo is not required "
"here!):"

#: src/3-2-compile.md:46
msgid ""
"```bash\n"
"docker run hello-world\n"
"```"
msgstr ""
"```bash\n"
"docker run hello-world\n"
"```"

#: src/3-2-compile.md:50
msgid "### 安装其他依赖"
msgstr "### Install additional dependencies"

#: src/3-2-compile.md:52
msgid ""
"```bash\n"
"sudo apt install -y python3-pip\n"
"pip3 install --user j2cli\n"
"```"
msgstr ""
"```bash\n"
"sudo apt install -y python3-pip\n"
"pip3 install --user j2cli\n"
"```"

#: src/3-2-compile.md:57
msgid "### 拉取代码"
msgstr "### Pull code"

#: src/3-2-compile.md:59
msgid ""
"在[3.1 代码仓库](./3-1-code-repos)一章中，我们提到了SONiC的主仓库是[sonic-"
"buildimage][SonicBuildimageRepo]。它也是我们目前为止唯一需要安装关注的repo。"
msgstr ""
"In the [3.1 Code repository](. /3-1-code-repos) chapter, we mentioned that "
"the main SONiC repository is [sonic-buildimage][SonicBuildimageRepo]. It is "
"also the only repo that we need to install and follow so far."

#: src/3-2-compile.md:61
msgid ""
"因为这个仓库通过submodule的形式将其他所有和编译相关的仓库包含在内，我们通过"
"git命令拉取代码时需要注意加上`--recuse-submodules`的选项："
msgstr ""
"Since this repository includes all other build-related repositories in the "
"form of submodules, we need to be careful to add the `-recuse-submodules` "
"option when pulling code via the git command:"

#: src/3-2-compile.md:63
msgid ""
"```bash\n"
"git clone --recurse-submodules https://github.com/sonic-net/sonic-buildimage."
"git\n"
"```"
msgstr ""
"```bash\n"
"git clone --recurse-submodules https://github.com/sonic-net/sonic-buildimage."
"git\n"
"```"

#: src/3-2-compile.md:67
msgid "如果在拉取代码的时候忘记拉取submodule，可以通过以下命令来补上："
msgstr ""
"If you forget to pull the submodule when pulling the code, you can fill it "
"in with the following command:"

#: src/3-2-compile.md:69
msgid ""
"```bash\n"
"git submodule update --init --recursive\n"
"```"
msgstr ""
"```bash\n"
"git submodule update --init --recursive\n"
"```"

#: src/3-2-compile.md:73
msgid ""
"当代码下载完毕之后，或者对于已有的repo，我们就可以通过以下命令来初始化编译环"
"境了。这个命令更新当前所有的submodule到需要的版本，以帮助我们成功编译："
msgstr ""
"Once the code has been downloaded, or for existing repo's, we can initialize "
"the compilation environment with the following command. This command updates "
"all current submodules to the required version to help us compile "
"successfully:"

#: src/3-2-compile.md:75
msgid ""
"```bash\n"
"sudo modprobe overlay\n"
"make init\n"
"```"
msgstr ""
"```bash\n"
"sudo modprobe overlay\n"
"make init\n"
"```"

#: src/3-2-compile.md:80
msgid "## 了解并设置你的目标平台"
msgstr "## Understand and set up your target platform"

#: src/3-2-compile.md:82
msgid ""
"[SONiC虽然支持非常多种不同的交换机][SONiCDevices]，但是由于不同型号的交换机使"
"用的ASIC不同，所使用的驱动和SDK也会不同。SONiC通过SAI来封装这些变化，为上层提"
"供统一的配置接口，但是在编译的时候，我们需要正确的设置好，这样才能保证我们编"
"译出来的SONiC可以在我们的目标平台上运行。"
msgstr ""
"[Although SONiC supports a very wide variety of different switches]"
"[SONiCDevices], the drivers and SDKs used will be different due to the "
"different ASICs used by different models of switches. SONiC encapsulates "
"these variations through SAI to provide a unified configuration interface "
"for the upper layers, but when compiling, we need to set it up correctly so "
"that the SONiC we compile will work on our target platform."

#: src/3-2-compile.md:84
msgid "现在，SONiC主要支持如下几个平台："
msgstr "Nowadays, SONiC mainly supports the following platforms:"

#: src/3-2-compile.md:86
msgid ""
"- barefoot\n"
"- broadcom\n"
"- marvell\n"
"- mellanox\n"
"- cavium\n"
"- centec\n"
"- nephos\n"
"- innovium\n"
"- vs"
msgstr ""
"- barefoot\n"
"- broadcom\n"
"- marvell\n"
"- mellanox\n"
"- cavium\n"
"- centec\n"
"- nephos\n"
"- innovium\n"
"- vs"

#: src/3-2-compile.md:96
msgid "在确认好平台之后，我们就可以运行如下命令来配置我们的编译环境了："
msgstr ""
"After confirming the platform, we can run the following command to configure "
"our compilation environment:"

#: src/3-2-compile.md:98
msgid ""
"```bash\n"
"make PLATFORM=<platform> configure\n"
"# e.g.: make PLATFORM=mellanox configure\n"
"```"
msgstr ""
"```bash\n"
"make PLATFORM=<platform> configure\n"
"# e.g.: make PLATFORM=mellanox configure\n"
"```"

#: src/3-2-compile.md:103
msgid ""
"```admonish note\n"
"<b>所有的make命令</b>（除了`make init`）一开始都会检查并创建所有debian版本的"
"docker builder：bullseye，stretch，jessie，buster。每个builder都需要几十分钟"
"的时间才能创建完成，这对于我们平时开发而言实在完全没有必要，一般来说，我们只"
"需要创建最新的版本即可（当前为bullseye，bookwarm暂时还没有支持），具体命令如"
"下：\n"
"\n"
"    NOJESSIE=1 NOSTRETCH=1 NOBUSTER=1 make PLATFORM=<platform> configure\n"
"\n"
"当然，为了以后开发更加方便，避免重复输入，我们可以将这个命令写入到`~/.bashrc`"
"中，这样每次打开终端的时候，就会设置好这些环境变量了。\n"
"\n"
"    export NOJESSIE=1\n"
"    export NOSTRETCH=1\n"
"    export NOBUSTER=1\n"
"```"
msgstr ""
"```admonish note\n"
"<b>所有的make命令</b>（除了`make init`）一开始都会检查并创建所有debian版本的"
"docker builder：bullseye，stretch，jessie，buster。每个builder都需要几十分钟"
"的时间才能创建完成，这对于我们平时开发而言实在完全没有必要，一般来说，我们只"
"需要创建最新的版本即可（当前为bullseye，bookwarm暂时还没有支持），具体命令如"
"下：\n"
"\n"
"    NOJESSIE=1 NOSTRETCH=1 NOBUSTER=1 make PLATFORM=<platform> configure\n"
"\n"
"当然，为了以后开发更加方便，避免重复输入，我们可以将这个命令写入到`~/.bashrc`"
"中，这样每次打开终端的时候，就会设置好这些环境变量了。\n"
"\n"
"    export NOJESSIE=1\n"
"    export NOSTRETCH=1\n"
"    export NOBUSTER=1\n"
"```"

#: src/3-2-compile.md:115
msgid "## 编译代码"
msgstr "## Compile the code"

#: src/3-2-compile.md:117
msgid "### 编译全部代码"
msgstr "### Compile the entire code"

#: src/3-2-compile.md:119
msgid "设置好平台之后，我们就可以开始编译代码了："
msgstr "After setting up the platform, we can start compiling the code::"

#: src/3-2-compile.md:121
msgid ""
"```bash\n"
"# The number of jobs can be the number of cores on your machine.\n"
"# Say, if you have 16 cores, then feel free to set it to 16 to speed up the "
"build.\n"
"make SONIC_BUILD_JOBS=4 all\n"
"```"
msgstr ""
"```bash\n"
"# The number of jobs can be the number of cores on your machine.\n"
"# Say, if you have 16 cores, then feel free to set it to 16 to speed up the "
"build.\n"
"make SONIC_BUILD_JOBS=4 all\n"
"```"

#: src/3-2-compile.md:127
msgid ""
"```admonish note\n"
"当然，对于开发而言，我们可以把SONIC_BUILD_JOBS和上面其他变量一起也加入`~/."
"bashrc`中，减少我们的输入。\n"
"\n"
"    export SONIC_BUILD_JOBS=<number of cores>\n"
"```"
msgstr ""
"```admonish note\n"
"当然，对于开发而言，我们可以把SONIC_BUILD_JOBS和上面其他变量一起也加入`~/."
"bashrc`中，减少我们的输入。\n"
"\n"
"    export SONIC_BUILD_JOBS=<number of cores>\n"
"```"

#: src/3-2-compile.md:133
msgid "### 编译子项目代码"
msgstr "### Compile subproject code"

#: src/3-2-compile.md:135
msgid ""
"我们从SONiC的Build Pipeline中就会发现，编译整个项目是非常耗时的，而绝大部分时"
"候，我们的代码改动只会影响很小部分的代码，所以有没有办法减少我们编译的工作量"
"呢？答案是肯定的，我们可以通过指定make target来仅编译我们需要的子项目。"
msgstr ""
"As we can see from SONiC's Build Pipeline, compiling the entire project is "
"very time consuming, and most of the time, our code changes will only affect "
"a small part of the code, so is there any way to reduce our compilation "
"effort? The answer is yes, we can specify make target to compile only the "
"subprojects we need."

#: src/3-2-compile.md:137
msgid "SONiC中每个子项目生成的文件都可以在`target`目录中找到，比如："
msgstr ""
"The files generated by each subproject in SONiC can be found in the `target` "
"directory, e.g:"

#: src/3-2-compile.md:139
msgid ""
"- Docker containers: target/<docker-image>.gz，比如：`target/docker-"
"orchagent.gz`\n"
"- Deb packages: target/debs/<debian-version>/<package>.deb，比如：`target/"
"debs/bullseye/libswsscommon_1.0.0_amd64.deb`\n"
"- Python wheels: target/python-wheels/<debian-version>/<package>.whl，比如："
"`target/python-wheels/bullseye/sonic_utilities-1.2-py3-none-any.whl`"
msgstr ""
"- Docker containers: target/<docker-image>.gz，比如：`target/docker-"
"orchagent.gz`\n"
"- Deb packages: target/debs/<debian-version>/<package>.deb，比如：`target/"
"debs/bullseye/libswsscommon_1.0.0_amd64.deb`\n"
"- Python wheels: target/python-wheels/<debian-version>/<package>.whl，比如："
"`target/python-wheels/bullseye/sonic_utilities-1.2-py3-none-any.whl`"

#: src/3-2-compile.md:143
msgid ""
"当我们找到了我们需要的子项目之后，我们便可以将其生成的文件删除，然后重新调用"
"make命令，这里我们用`libswsscommon`来举例子，如下："
msgstr ""
"Once we have found the subproject we need, we can delete its generated files "
"and then re-invoke the make command, here we use `libswsscommon` as an "
"example, as follows:"

#: src/3-2-compile.md:145
msgid ""
"```bash\n"
"# Remove the deb package for bullseye\n"
"rm target/debs/bullseye/libswsscommon_1.0.0_amd64.deb\n"
"\n"
"# Build the deb package for bullseye\n"
"NOJESSIE=1 NOSTRETCH=1 NOBUSTER=1 make target/debs/bullseye/"
"libswsscommon_1.0.0_amd64.deb\n"
"```"
msgstr ""
"```bash\n"
"# Remove the deb package for bullseye\n"
"rm target/debs/bullseye/libswsscommon_1.0.0_amd64.deb\n"
"\n"
"# Build the deb package for bullseye\n"
"NOJESSIE=1 NOSTRETCH=1 NOBUSTER=1 make target/debs/bullseye/"
"libswsscommon_1.0.0_amd64.deb\n"
"```"

#: src/3-2-compile.md:153
msgid "### 检查和处理编译错误"
msgstr "### Check and handle compilation errors"

#: src/3-2-compile.md:155
msgid ""
"如果不巧在编译的时候发生了错误，我们可以通过检查失败项目的日志文件来查看具体"
"的原因。在SONiC中，每一个子编译项目都会生成其相关的日志文件，我们可以很容易的"
"在`target`目录中找到，如下："
msgstr ""
"If by chance an error occurs while compiling, we can check the exact cause "
"by examining the log file of the failed project. In SONiC, each subcompiled "
"project generates its associated log file, which we can easily find in the "
"`target` directory, as follows:"

#: src/3-2-compile.md:157
msgid ""
"```bash\n"
"$ ls -l\n"
"...\n"
"-rw-r--r--  1 r12f r12f 103M Jun  8 22:35 docker-database.gz\n"
"-rw-r--r--  1 r12f r12f  26K Jun  8 22:35 docker-database.gz.log      // Log "
"file for docker-database.gz\n"
"-rw-r--r--  1 r12f r12f 106M Jun  8 22:44 docker-dhcp-relay.gz\n"
"-rw-r--r--  1 r12f r12f 106K Jun  8 22:44 docker-dhcp-relay.gz.log    // Log "
"file for docker-dhcp-relay.gz\n"
"```"
msgstr ""
"```bash\n"
"$ ls -l\n"
"...\n"
"-rw-r--r--  1 r12f r12f 103M Jun  8 22:35 docker-database.gz\n"
"-rw-r--r--  1 r12f r12f  26K Jun  8 22:35 docker-database.gz.log      // Log "
"file for docker-database.gz\n"
"-rw-r--r--  1 r12f r12f 106M Jun  8 22:44 docker-dhcp-relay.gz\n"
"-rw-r--r--  1 r12f r12f 106K Jun  8 22:44 docker-dhcp-relay.gz.log    // Log "
"file for docker-dhcp-relay.gz\n"
"```"

#: src/3-2-compile.md:166
msgid ""
"如果我们不想每次在更新代码之后都去代码的根目录下重新编译，然后查看日志文件，"
"SONiC还提供了一个更加方便的方法，能让我们在编译完成之后停在docker builder中，"
"这样我们就可以直接去对应的目录运行`make`命令来重新编译了："
msgstr ""
"If we don't want to go to the root of the code and recompile it every time "
"we update it and then check the log files, SONiC also provides a more "
"convenient way to stop the build in the docker builder after it's done, so "
"we can go directly to the corresponding directory and run the `make` command "
"to recompile it:"

#: src/3-2-compile.md:168
msgid ""
"```bash\n"
"# KEEP_SLAVE_ON=yes make <target>\n"
"KEEP_SLAVE_ON=yes make target/debs/bullseye/libswsscommon_1.0.0_amd64.deb\n"
"KEEP_SLAVE_ON=yes make all\n"
"```"
msgstr ""
"```bash\n"
"# KEEP_SLAVE_ON=yes make <target>\n"
"KEEP_SLAVE_ON=yes make target/debs/bullseye/libswsscommon_1.0.0_amd64.deb\n"
"KEEP_SLAVE_ON=yes make all\n"
"```"

#: src/3-2-compile.md:174
msgid ""
"```admonish note\n"
"有些仓库中的部分代码在全量编译的时候是不会编译的，比如，`sonic-swss-common`中"
"的gtest，所以使用这种方法重编译的时候，请一定注意查看原仓库的编译指南，以避免"
"出错，如：<https://github.com/sonic-net/sonic-swss-common#build-from-"
"source>。\n"
"```"
msgstr ""
"```admonish note\n"
"有些仓库中的部分代码在全量编译的时候是不会编译的，比如，`sonic-swss-common`中"
"的gtest，所以使用这种方法重编译的时候，请一定注意查看原仓库的编译指南，以避免"
"出错，如：<https://github.com/sonic-net/sonic-swss-common#build-from-"
"source>。\n"
"```"

#: src/3-2-compile.md:178
msgid "## 获取正确的镜像文件"
msgstr "## Get the correct image file"

#: src/3-2-compile.md:180
msgid ""
"编译完成之后，我们就可以在`target`目录中找到我们需要的镜像文件了，但是这里有"
"一个问题：我们到底要用哪一种镜像来把SONiC安装到我们的交换机上呢？这里主要取决"
"于交换机使用什么样的BootLoader或者安装程序，其映射关系如下："
msgstr ""
"Once compiled, we can find the image file we need in the `target` directory, "
"but here's a question: which image do we use to install SONiC on our switch? "
"Here it depends on what BootLoader or installer the switch is using, and the "
"mapping is as follows:"

#: src/3-2-compile.md:182
msgid ""
"| Bootloader | 后缀 |\n"
"| --- | --- |\n"
"| Aboot | .swi |\n"
"| ONIE | .bin |\n"
"| Grub | .img.gz |"
msgstr ""
"| Bootloader | 后缀 |\n"
"| --- | --- |\n"
"| Aboot | .swi |\n"
"| ONIE | .bin\n"
"| Grub | .img.gz |."

#: src/3-2-compile.md:188
msgid "## 部分升级"
msgstr "## Partial upgrade"

#: src/3-2-compile.md:190
msgid ""
"显然，在开发的时候，每次都编译安装镜像然后进行全量安装的效率是相当低下的，所"
"以我们可以选择不安装镜像而使用直接升级deb包的方式来进行部分升级，从而提高我们"
"的开发效率。"
msgstr ""
"Obviously, when developing, it is quite inefficient to compile and install "
"the image each time and then do a full install, so we can choose not to "
"install the image and use the direct upgrade deb package to do a partial "
"upgrade, thus improving our development efficiency."

#: src/3-2-compile.md:192
msgid ""
"我们可以将deb包上传到交换机的`/etc/sonic`目录下，这个目录下的文件会被map到所"
"有容器的`/etc/sonic`目录下，接着我们可以进入到容器中，然后使用`dpkg`命令来安"
"装deb包，如下："
msgstr ""
"We can upload the deb package to the `/etc/sonic` directory of the switch, "
"the files in this directory will be mapped to the `/etc/sonic` directory of "
"all containers, then we can enter the container and use the `dpkg` command "
"to install the deb package as follows:"

#: src/3-2-compile.md:194
msgid ""
"```bash\n"
"# Enter the docker container\n"
"docker exec -it <container> bash\n"
"\n"
"# Install deb package\n"
"dpkg -i <deb-package>\n"
"```"
msgstr ""
"```bash\n"
"# Enter the docker container\n"
"docker exec -it <container> bash\n"
"\n"
"# Install deb package\n"
"dpkg -i <deb-package>\n"
"```"

#: src/3-2-compile.md:204
msgid ""
"1. [SONiC Build Guide][SONiCBuild]\n"
"2. [Install Docker Engine][DockerInstall]\n"
"3. [Github repo: sonic-buildimage][SonicBuildimageRepo]\n"
"4. [SONiC Supported Devices and Platforms][SONiCDevices]\n"
"5. [Wrapper for starting make inside sonic-slave container]"
"[SONiCBuildImageMakeFile]"
msgstr ""
"1. [SONiC Build Guide][SONiCBuild]\n"
"2. [Install Docker Engine][DockerInstall]\n"
"3. [Github repo: sonic-buildimage][SonicBuildimageRepo]\n"
"4. [SONiC Supported Devices and Platforms][SONiCDevices]\n"
"5. [Wrapper for starting make inside sonic-slave container]"
"[SONiCBuildImageMakeFile]"

#: src/3-3-testing.md:1
msgid "# 测试"
msgstr "# Testing"

#: src/3-4-debugging.md:1
msgid "# 调试"
msgstr "# Debugging"

#: src/3-4-sai-debugging.md:1
msgid "# SAI调试"
msgstr "# SAI debugging"

#: src/4-communications.md:1
msgid "# 通信机制"
msgstr "# Communication mechanisms"

#: src/4-communications.md:3
msgid ""
"SONiC中主要的通信机制有三种：与内核的通信，基于Redis和基于ZMQ的服务间的通信。"
msgstr ""
"There are three main communication mechanisms in SONiC: communication with "
"the kernel, Redis-based and ZMQ-based inter-service communication."

#: src/4-communications.md:5
msgid ""
"- 与内核通信主要有两种方法：命令行调用和Netlink消息。\n"
"- 基于Redis的服务间通信主要有四种方法：SubscriberStateTable，"
"NotificationProducer/Consumer，Producer/ConsumerTable，Producer/"
"ConsumerStateTable。虽然它们都是基于Redis的，但是它们解决的问题和方法却非常不"
"同。\n"
"- 基于ZMQ的服务间通信：现在只在`orchagent`和`syncd`的通信中使用了这种通信机"
"制。"
msgstr ""
"- There are two main methods for communicating with the kernel: command line "
"calls and Netlink messages.\n"
"- There are four main methods of Redis-based inter-service communication: "
"SubscriberStateTable, NotificationProducer/Consumer, Producer/ConsumerTable, "
"and Producer/ConsumerStateTable. Although they are both Redis-based, they "
"solve very different problems and approaches.\n"
"- ZMQ-based inter-service communication: This communication mechanism is now "
"used only for `orchagent` and `syncd` communication."

#: src/4-communications.md:9
msgid ""
"```admonish note\n"
"虽然大部分的通信机制都支持多消费者的PubSub的模式，但是请特别注意：在SONiC中，"
"所有的通信都是点对点的，即一个生产者对应一个消费者，绝对不会出现一个生产者对"
"应多个消费者的情况！\n"
"\n"
"一旦多消费者出现，那么一个消息的处理逻辑将可能发生在多个进程中，这将导致很大"
"的问题，因为对于任何一种特定的消息，SONiC中只有一个地方来处理，所以这会导致部"
"分消息不可避免的出错或者丢失。\n"
"```"
msgstr ""
"```admonish note\n"
"虽然大部分的通信机制都支持多消费者的PubSub的模式，但是请特别注意：在SONiC中，"
"所有的通信都是点对点的，即一个生产者对应一个消费者，绝对不会出现一个生产者对"
"应多个消费者的情况！\n"
"\n"
"一旦多消费者出现，那么一个消息的处理逻辑将可能发生在多个进程中，这将导致很大"
"的问题，因为对于任何一种特定的消息，SONiC中只有一个地方来处理，所以这会导致部"
"分消息不可避免的出错或者丢失。\n"
"```"

#: src/4-communications.md:15
msgid ""
"所有这些基础的通信机制的实现都在[sonic-swss-common][SONiCSWSSCommon]这个repo"
"中的`common`目录下。另外在其之上，为了方便各个服务使用，SONiC还在[sonic-swss]"
"[SONiCSWSS]中封装了一层Orch，将常用的表放在其中。"
msgstr ""
"The implementation of all these basic communication mechanisms is in the "
"`common` directory in the repo [sonic-swss-common][SONiCSWSSCommon]. Also on "
"top of it, for the convenience of each service, SONiC has wrapped a layer of "
"Orch in [sonic-swss][SONiCSWSS], where the commonly used tables are placed."

#: src/4-communications.md:17
msgid "这一章，我们就主要来看看这些通信机制的实现吧！"
msgstr ""
"In this chapter, let's focus on the implementation of these communication "
"mechanisms!"

#: src/4-communications.md:21 src/4-2-1-redis-wrappers.md:35
#: src/4-4-orch-layer.md:36 src/4-5-event-polling-and-error-handling.md:121
msgid ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [Github repo: sonic-swss][SONiCSWSS]\n"
"3. [Github repo: sonic-swss-common][SONiCSWSSCommon]"
msgstr ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [Github repo: sonic-swss][SONiCSWSS]\n"
"3. [Github repo: sonic-swss-common][SONiCSWSSCommon]"

#: src/4-1-1-exec.md:1
msgid "# 命令行调用"
msgstr "# Command line calls"

#: src/4-1-1-exec.md:3
msgid ""
"SONiC中的与内核通信最简单的方式就是命令行调用了，其实现放在[common/exec.h]"
"(https://github.com/sonic-net/sonic-swss-common/blob/master/common/exec.h)文"
"件下，且十分简单，接口如下："
msgstr ""
"The easiest way to communicate with the kernel in SONiC is to make a command "
"line call, which is placed under the [common/exec.h](https://github.com/"
"sonic-net/sonic-swss-common/blob/master/common/exec.h) file and is very "
"simple to implement The interface is as follows:"

#: src/4-1-1-exec.md:5
msgid ""
"```cpp\n"
"// File: common/exec.h\n"
"// Namespace: swss\n"
"int exec(const std::string &cmd, std::string &stdout);\n"
"```"
msgstr ""
"```cpp\n"
"// File: common/exec.h\n"
"// Namespace: swss\n"
"int exec(const std::string &cmd, std::string &stdout);\n"
"```"

#: src/4-1-1-exec.md:11
msgid ""
"其中，`cmd`是要执行的命令，`stdout`是命令执行的输出。这里的`exec`函数是一个同"
"步调用，调用者会一直阻塞，直到命令执行完毕。其内部通过调用`popen`函数来创建子"
"进程，并且通过`fgets`函数来获取输出。不过，**虽然这个函数返回了输出，但是基本"
"上并没有人使用**，而只是通过返回值来判断是否成功，甚至连错误log中都不会写入输"
"出的结果。"
msgstr ""
"Where `cmd` is the command to be executed and `stdout` is the output of the "
"command execution. The `exec` function here is a synchronous call, and the "
"caller blocks until the command is executed. Internally, it creates a child "
"process by calling the `popen` function and gets the output by using the "
"`fgets` function. However, **although this function returns output, "
"basically no one uses it**, but only by the return value to determine "
"whether it succeeded or not, and even the output is not written in the error "
"log."

#: src/4-1-1-exec.md:13
msgid ""
"这个函数虽然粗暴，但是使用广泛，特别是在各个`*mgrd`服务中，比如`portmgrd`中就"
"用它来设置每一个Port的状态等等。"
msgstr ""
"This function is crude but widely used, especially in the various `*mgrd` "
"services, such as `portmgrd` where it is used to set the status of each "
"port, etc."

#: src/4-1-1-exec.md:15
msgid ""
"```cpp\n"
"// File: sonic-swss - cfgmgr/portmgr.cpp\n"
"bool PortMgr::setPortAdminStatus(const string &alias, const bool up)\n"
"{\n"
"    stringstream cmd;\n"
"    string res, cmd_str;\n"
"\n"
"    // ip link set dev <port_name> [up|down]\n"
"    cmd << IP_CMD << \" link set dev \" << shellquote(alias) << (up ? \" "
"up\" : \" down\");\n"
"    cmd_str = cmd.str();\n"
"    int ret = swss::exec(cmd_str, res);\n"
"\n"
"    // ...\n"
"```"
msgstr ""
"```cpp\n"
"// File: sonic-swss - cfgmgr/portmgr.cpp\n"
"bool PortMgr::setPortAdminStatus(const string &alias, const bool up)\n"
"{\n"
"    stringstream cmd;\n"
"    string res, cmd_str;\n"
"\n"
"    // ip link set dev <port_name> [up|down]\n"
"    cmd << IP_CMD << \" link set dev \" << shellquote(alias) << (up ? \" "
"up\" : \" down\");\n"
"    cmd_str = cmd.str();\n"
"    int ret = swss::exec(cmd_str, res);\n"
"\n"
"    // ...\n"
"```"

#: src/4-1-1-exec.md:30
msgid ""
"```admonish note\n"
"**为什么说命令行调用是一种通信机制呢**？\n"
"\n"
"原因是当`*mgrd`服务调用`exec`函数对系统进行的修改，会触发下面马上会提到的"
"netlink事件，从而通知其他服务进行相应的修改，比如`*syncd`，这样就间接的构成了"
"一种通信。所以这里我们把命令行调用看作一种通信机制能帮助我们以后更好的理解"
"SONiC的各种工作流。\n"
"```"
msgstr ""
"```admonish note\n"
"**为什么说命令行调用是一种通信机制呢**？\n"
"\n"
"原因是当`*mgrd`服务调用`exec`函数对系统进行的修改，会触发下面马上会提到的"
"netlink事件，从而通知其他服务进行相应的修改，比如`*syncd`，这样就间接的构成了"
"一种通信。所以这里我们把命令行调用看作一种通信机制能帮助我们以后更好的理解"
"SONiC的各种工作流。\n"
"```"

#: src/4-1-1-exec.md:38 src/4-1-2-netlink.md:72
msgid "1. [Github repo: sonic-swss-common][SONiCSWSSCommon]"
msgstr "1. [Github repo: sonic-swss-common][SONiCSWSSCommon]"

#: src/4-1-2-netlink.md:1
msgid "# Netlink"
msgstr "# Netlink"

#: src/4-1-2-netlink.md:3
msgid ""
"Netlink是Linux内核中用于内核与用户空间进程之间的一种基于消息的通信机制。它通"
"过套接字接口和自定义的协议族来实现，可以用来传递各种类型的内核消息，包括网络"
"设备状态、路由表更新、防火墙规则变化、系统资源使用情况等等。而SONiC的`*sync`"
"服务就大量使用了Netlink的机制来监听系统中网络设备的变化，并将最新的状态同步到"
"Redis中，并通知其他服务进行相应的修改。"
msgstr ""
"Netlink is a message-based communication mechanism used in the Linux kernel "
"between the kernel and user-space processes. It is implemented through a "
"socket interface and a custom protocol family, and can be used to deliver "
"various types of kernel messages, including network device status, routing "
"table updates, firewall rule changes, system resource usage, and so on. "
"SONiC's `*sync` service makes extensive use of Netlink's mechanism to listen "
"for changes to network devices in the system, synchronize the latest state "
"to Redis, and notify other services of the corresponding changes."

#: src/4-1-2-netlink.md:5
msgid ""
"Netlink的实现主要在这几个文件中：[common/netmsg.*](https://github.com/sonic-"
"net/sonic-swss-common/blob/master/common/netmsg.h)、[common/netlink.*]"
"(https://github.com/sonic-net/sonic-swss-common/blob/master/common/netlink."
"h) 和 [common/netdispatcher.*](https://github.com/sonic-net/sonic-swss-"
"common/blob/master/common/netdispatcher.h)，具体类图如下："
msgstr ""
"The Netlink implementation is mainly in these files: [common/netmsg.*]"
"(https://github.com/sonic-net/sonic-swss-common/blob/master/common/netmsg."
"h), [common/netlink. *](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/netlink.h) and [common/netdispatcher.*](https://github.com/"
"sonic-) net/sonic-swss-common/blob/master/common/netdispatcher.h), with the "
"following class diagram:"

#: src/4-1-2-netlink.md:9 src/4-2-1-redis-wrappers.md:9
msgid "其中："
msgstr "Among them:"

#: src/4-1-2-netlink.md:11
msgid ""
"- **Netlink**：封装了Netlink的套接字接口，提供了Netlink消息的接口和接收消息的"
"回调。\n"
"- **NetDispatcher**：它是一个单例，提供了Handler注册的接口。当Netlink类接收到"
"原始的消息后，就会调用NetDispatcher将其解析成nl_onject，并根据消息的类型调用"
"相应的Handler。\n"
"- **NetMsg**：Netlink消息Handler的基类，仅提供了onMsg的接口，其中没有实现。"
msgstr ""
"- **Netlink**: It encapsulates the socket interface of Netlink and provides "
"the interface of Netlink messages and callbacks for receiving messages.\n"
"- **NetDispatcher**: It is a single instance that provides the interface for "
"Handler registration. When the Netlink class receives a raw message, it "
"calls NetDispatcher to parse it into nl_onject and calls the corresponding "
"Handler according to the type of the message.\n"
"- **NetMsg**: The base class of Netlink message Handler, which only provides "
"the interface of onMsg, of which there is no implementation."

#: src/4-1-2-netlink.md:15
msgid ""
"举一个例子，当`portsyncd`启动的时候，它会创建一个Netlink对象，用来监听Link相"
"关的状态变化，并且会实现NetMsg的接口，对Link相关的消息进行处理。具体的实现如"
"下："
msgstr ""
"As an example, when `portsyncd` starts, it will create a Netlink object to "
"listen for Link-related state changes and will implement the NetMsg "
"interface to handle Link-related messages. The concrete implementation is as "
"follows:"

#: src/4-1-2-netlink.md:17
msgid ""
"```cpp\n"
"// File: sonic-swss - portsyncd/portsyncd.cpp\n"
"int main(int argc, char **argv)\n"
"{\n"
"    // ...\n"
"\n"
"    // Create Netlink object to listen to link messages\n"
"    NetLink netlink;\n"
"    netlink.registerGroup(RTNLGRP_LINK);\n"
"\n"
"    // Here SONiC request a fulldump of current state, so that it can get "
"the current state of all links\n"
"    netlink.dumpRequest(RTM_GETLINK);      \n"
"    cout << \"Listen to link messages...\" << endl;\n"
"    // ...\n"
"\n"
"    // Register handler for link messages\n"
"    LinkSync sync(&appl_db, &state_db);\n"
"    NetDispatcher::getInstance().registerMessageHandler(RTM_NEWLINK, "
"&sync);\n"
"    NetDispatcher::getInstance().registerMessageHandler(RTM_DELLINK, "
"&sync);\n"
"\n"
"    // ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: sonic-swss - portsyncd/portsyncd.cpp\n"
"int main(int argc, char **argv)\n"
"{\n"
"    // ...\n"
"\n"
"    // Create Netlink object to listen to link messages\n"
"    NetLink netlink;\n"
"    netlink.registerGroup(RTNLGRP_LINK);\n"
"\n"
"    // Here SONiC request a fulldump of current state, so that it can get "
"the current state of all links\n"
"    netlink.dumpRequest(RTM_GETLINK);      \n"
"    cout << \"Listen to link messages...\" << endl;\n"
"    // ...\n"
"\n"
"    // Register handler for link messages\n"
"    LinkSync sync(&appl_db, &state_db);\n"
"    NetDispatcher::getInstance().registerMessageHandler(RTM_NEWLINK, "
"&sync);\n"
"    NetDispatcher::getInstance().registerMessageHandler(RTM_DELLINK, "
"&sync);\n"
"\n"
"    // ...\n"
"}\n"
"```"

#: src/4-1-2-netlink.md:41
msgid ""
"上面的LinkSync，就是一个NetMsg的实现，它实现了onMsg接口，用来处理Link相关的消"
"息："
msgstr ""
"The above LinkSync, which is an implementation of NetMsg, implements the "
"onMsg interface to handle Link-related messages::"

#: src/4-1-2-netlink.md:43
msgid ""
"```cpp\n"
"// File: sonic-swss - portsyncd/linksync.h\n"
"class LinkSync : public NetMsg\n"
"{\n"
"public:\n"
"    LinkSync(DBConnector *appl_db, DBConnector *state_db);\n"
"\n"
"    // NetMsg interface\n"
"    virtual void onMsg(int nlmsg_type, struct nl_object *obj);\n"
"\n"
"    // ...\n"
"};\n"
"\n"
"// File: sonic-swss - portsyncd/linksync.cpp\n"
"void LinkSync::onMsg(int nlmsg_type, struct nl_object *obj)\n"
"{\n"
"    // ...\n"
"\n"
"    // Write link state to Redis DB\n"
"    FieldValueTuple fv(\"oper_status\", oper ? \"up\" : \"down\");\n"
"    vector<FieldValueTuple> fvs;\n"
"    fvs.push_back(fv);\n"
"    m_stateMgmtPortTable.set(key, fvs);\n"
"    // ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: sonic-swss - portsyncd/linksync.h\n"
"class LinkSync : public NetMsg\n"
"{\n"
"public:\n"
"    LinkSync(DBConnector *appl_db, DBConnector *state_db);\n"
"\n"
"    // NetMsg interface\n"
"    virtual void onMsg(int nlmsg_type, struct nl_object *obj);\n"
"\n"
"    // ...\n"
"};\n"
"\n"
"// File: sonic-swss - portsyncd/linksync.cpp\n"
"void LinkSync::onMsg(int nlmsg_type, struct nl_object *obj)\n"
"{\n"
"    // ...\n"
"\n"
"    // Write link state to Redis DB\n"
"    FieldValueTuple fv(\"oper_status\", oper ? \"up\" : \"down\");\n"
"    vector<FieldValueTuple> fvs;\n"
"    fvs.push_back(fv);\n"
"    m_stateMgmtPortTable.set(key, fvs);\n"
"    // ...\n"
"}\n"
"```"

#: src/4-2-1-redis-wrappers.md:1
msgid "# Redis封装"
msgstr "# Redis Wrapper"

#: src/4-2-1-redis-wrappers.md:3
msgid "## Redis数据库操作层"
msgstr "## Redis Database Operations Layer"

#: src/4-2-1-redis-wrappers.md:5
msgid ""
"第一层，也是最底层，是Redis的数据库操作层，封装了各种基本命令，比如，DB的连"
"接，命令的执行，事件通知的回调接口等等。具体的类图如下："
msgstr ""
"The first and lowest layer is the database operations layer of Redis, which "
"encapsulates various basic commands, such as DB connection, command "
"execution, callback interface for event notification, etc. The specific "
"class diagram is as follows:"

#: src/4-2-1-redis-wrappers.md:11
msgid ""
"- **[RedisContext](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/dbconnector.h)**：封装并保持着与Redis的连接，当其销毁时会将其连"
"接关闭。\n"
"- **[DBConnector](https://github.com/sonic-net/sonic-swss-common/blob/master/"
"common/dbconnector.h)**：封装了所有的底层使用到的Redis的命令，比如`SET`、"
"`GET`、`DEL`等等。\n"
"- **[RedisTransactioner](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/redistran.h)**：封装了Redis的事务操作，用于在一个事务中执行多个"
"命令，比如`MULTI`、`EXEC`等等。\n"
"- **[RedisPipeline](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/redispipeline.h)**：封装了hiredis的redisAppendFormattedCommand "
"API，提供了一个类似队列的异步的执行Redis命令的接口（虽然大部分使用方法依然是"
"同步的）。它也是少有的对`SCRIPT LOAD`命令进行了封装的类，用于在Redis中加载Lua"
"脚本实现存储过程。SONiC中绝大部分需要执行Lua脚本的类，都会使用这个类来进行加"
"载和调用。\n"
"- **[RedisSelect](https://github.com/sonic-net/sonic-swss-common/blob/master/"
"common/redisselect.h)**：它实现了Selectable的接口，用来支持基于epoll的事件通"
"知机制（Event Polling）。主要是在我们收到了Redis的回复，用来触发epoll进行回调"
"（我们最后会更详细的介绍）。\n"
"- **[SonicDBConfig](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/dbconnector.h)**：这个类是一个“静态类”，它主要实现了SONiC DB的"
"配置文件的读取和解析。其他的数据库操作类，如果需要任何的配置信息，都会通过这"
"个类来获取。"
msgstr ""
"- **[RedisContext](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/dbconnector.h)**: encapsulates and maintains the connection to "
"Redis, and will close it when it is destroyed.\n"
"- **[DBConnector](https://github.com/sonic-net/sonic-swss-common/blob/master/"
"common/dbconnector.h)**: encapsulates all the underlying Redis commands that "
"are used, such as `SET`, ` GET`, `DEL`, and so on.\n"
"- **[RedisTransactioner](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/redistran.h)**: encapsulates the Redis transaction operations "
"used to execute multiple commands, such as `MULTI`, `EXEC`, and so on.\n"
"- **[RedisPipeline](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/redispipeline.h)**: encapsulates the hiredis "
"redisAppendFormattedCommand API, providing a queue-like interface for "
"executing Redis commands asynchronously (although most of the usage is still "
"synchronous). It is also one of the few classes that wraps the `SCRIPT LOAD` "
"command for loading Lua scripts to implement stored procedures in Redis.\n"
"- **[RedisSelect](https://github.com/sonic-net/sonic-swss-common/blob/master/"
"common/redisselect.h)**: It implements the Selectable interface, which is "
"used to support the epoll-based Event Polling. It is mainly used to trigger "
"epoll for callbacks when we receive a reply from Redis (we will cover this "
"in more detail at the end).\n"
"- **[SonicDBConfig](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/dbconnector.h)**: This class is a \"static class \", it mainly "
"implements the reading and parsing of the configuration file of SONiC DB. "
"Other database operation classes, if they need any configuration "
"information, will get it through this class."

#: src/4-2-1-redis-wrappers.md:19
msgid "## 表（Table）抽象层"
msgstr "## Table abstraction layer"

#: src/4-2-1-redis-wrappers.md:21
msgid ""
"在Redis数据库操作层之上，便是SONiC自己利用Redis中间的Key建立的表（Table）的抽"
"象了，因为每一个Redis的Key的格式都是`<table-name><separator><key-name>`，所以"
"SONiC在访问数据库时需要对其进行一次转换（没有印象的小伙伴可以移步[我之前的博"
"客了解更多的信息](/posts/sonic-2-key-components/#数据库)）。"
msgstr ""
"On top of the Redis database operation layer is the abstraction of the Table "
"that SONiC itself builds using the Redis intermediate Key, because the "
"format of each Redis Key is `<table-name><separator><key-name>`, so SONiC "
"needs to perform a conversion (for those who don't remember, you can move to "
"[my previous blog for more information](/posts/sonic-2-key-components/"
"#database))."

#: src/4-2-1-redis-wrappers.md:23
msgid "相关类的主要类图如下："
msgstr "The main class diagram of the related classes is as follows:"

#: src/4-2-1-redis-wrappers.md:27
msgid "其中关键的类有三个："
msgstr "Three of the key classes are:"

#: src/4-2-1-redis-wrappers.md:29
msgid ""
"- **[TableBase](https://github.com/sonic-net/sonic-swss-common/blob/master/"
"common/table.h)**：这个类是所有表的基类，它主要封装了表的基本信息，如表的名"
"字，Redis Key的打包，每个表发生修改时用于通信的Channel的名字，等等。\n"
"- **[Table](https://github.com/sonic-net/sonic-swss-common/blob/master/"
"common/table.h)**：这个类就是对于每个表增删改查的封装了，里面包含了表的名称和"
"分隔符，这样就可以在调用时构造最终的key了。\n"
"- **[ConsumerTableBase](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/consumertablebase.h)**：这个类是各种SubscriptionTable的基类，里"
"面主要是封装了一个简单的队列和其pop操作（对，只有pop，没有push），用来给上层"
"调用。"
msgstr ""
"- **[TableBase](https://github.com/sonic-net/sonic-swss-common/blob/master/"
"common/table.h)**: This class is the base class for all tables, it mainly "
"encapsulates the basic information about the table, such as the name of the "
"table, the Redis Key It encapsulates basic information about the table, such "
"as the name of the table, the packing of the Redis Key, the name of the "
"Channel used to communicate with each table when a modification occurs, and "
"so on.\n"
"- **[Table](https://github.com/sonic-net/sonic-swss-common/blob/master/"
"common/table.h)**: This class is the encapsulation for each table add, "
"delete, and modify, and contains the table name and separator so that the "
"final key can be constructed when it is called. constructs the final key.\n"
"- **[ConsumerTableBase](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/consumertablebase.h)**: This class is the base class for all "
"kinds of SubscriptionTable base class, which mainly encapsulates a simple "
"queue and its pop operation (yes, only pop, not push), used for upper-level "
"calls."

#: src/4-2-2-redis-messaging-layer.md:1
msgid "# 通信层"
msgstr "# Communication层"

#: src/4-2-2-redis-messaging-layer.md:3
msgid ""
"在Redis的封装和表抽象之上，便是SONiC的通信层了，由于需求的不同，这一层中提供"
"了四种不同的PubSub的封装，用于服务间的通信。"
msgstr ""
"On top of the Redis encapsulation and table abstraction is the SONiC "
"communication layer, which provides four different PubSub encapsulations for "
"inter-service communication, depending on the requirements."

#: src/4-2-2-redis-messaging-layer.md:5
msgid "## SubscribeStateTable"
msgstr "## SubscribeStateTable"

#: src/4-2-2-redis-messaging-layer.md:7
msgid ""
"最直接的就是[SubscriberStateTable](https://github.com/sonic-net/sonic-swss-"
"common/blob/master/common/subscriberstatetable.h)了。"
msgstr ""
"最直接的就是[SubscriberStateTable](https://github.com/sonic-net/sonic-swss-"
"common/blob/master/common/subscriberstatetable.h)了。"

#: src/4-2-2-redis-messaging-layer.md:9
msgid ""
"它的原理是利用Redis数据库中自带的keyspace消息通知机制 [\\[4\\]]"
"[RedisKeyspace] —— 当数据库中的任何一个key对应的值发生了变化，就会触发Redis发"
"送两个keyspace的事件通知，一个是`__keyspace@<db-id>__:<key>`下的`<op>`事件，"
"一个是`__keyspace@<db-id>__:<op>`下的`<key>>`事件，比如，在数据库0中删除了一"
"个key，那么就会触发两个事件通知："
msgstr ""
"It works by using the keyspace message notification mechanism that comes "
"with the Redis database [\\[4\\]][RedisKeyspace] -- when the value "
"corresponding to any key in the database changes, it triggers Redis to send "
"two keyspace event notifications , one is the `<op>` event under "
"`__keyspace@<db-id>__:<key>`, and one is the `<key>>` event under "
"`__keyspace@<db-id>__:<op>`, for example, if a key is deleted in database 0, "
"then two event notifications are triggered:"

#: src/4-2-2-redis-messaging-layer.md:11
msgid ""
"```redis\n"
"PUBLISH __keyspace@0__:foo del\n"
"PUBLISH __keyevent@0__:del foo\n"
"```"
msgstr ""
"```redis\n"
"PUBLISH __keyspace@0__:foo del\n"
"PUBLISH __keyevent@0__:del foo\n"
"```"

#: src/4-2-2-redis-messaging-layer.md:16
msgid ""
"而SubscriberStateTable就是监听了第一个事件通知，然后调用相应的回调函数。和其"
"直接相关的主要的类的类图如下，这里可以看到它继承了ConsumerTableBase，因为它是"
"Redis的消息的Consumer："
msgstr ""
"The SubscriberStateTable listens for the first event notification and then "
"calls the corresponding callback function. The class diagram of the main "
"class directly related to it is as follows, where you can see that it "
"inherits from ConsumerTableBase, since it is the Consumer of Redis messages:"

#: src/4-2-2-redis-messaging-layer.md:20
msgid "在初始化时，我们可以看到它是如何订阅Redis的事件通知的："
msgstr ""
"At initialization time, we can see how it subscribes to Redis event "
"notifications: the"

#: src/4-2-2-redis-messaging-layer.md:22
msgid ""
"```cpp\n"
"// File: sonic-swss-common - common/subscriberstatetable.cpp\n"
"SubscriberStateTable::SubscriberStateTable(DBConnector *db, const string "
"&tableName, int popBatchSize, int pri)\n"
"    : ConsumerTableBase(db, tableName, popBatchSize, pri), m_table(db, "
"tableName)\n"
"{\n"
"    m_keyspace = \"__keyspace@\";\n"
"    m_keyspace += to_string(db->getDbId()) + \"__:\" + tableName + m_table."
"getTableNameSeparator() + \"*\";\n"
"    psubscribe(m_db, m_keyspace);\n"
"    // ...\n"
"```"
msgstr ""
"```cpp\n"
"// File: sonic-swss-common - common/subscriberstatetable.cpp\n"
"SubscriberStateTable::SubscriberStateTable(DBConnector *db, const string "
"&tableName, int popBatchSize, int pri)\n"
"    : ConsumerTableBase(db, tableName, popBatchSize, pri), m_table(db, "
"tableName)\n"
"{\n"
"    m_keyspace = \"__keyspace@\";\n"
"    m_keyspace += to_string(db->getDbId()) + \"__:\" + tableName + m_table."
"getTableNameSeparator() + \"*\";\n"
"    psubscribe(m_db, m_keyspace);\n"
"    // ...\n"
"```"

#: src/4-2-2-redis-messaging-layer.md:33
msgid "其事件接收和分发主要由两个函数负责："
msgstr ""
"Its event reception and distribution are mainly handled by two functions:"

#: src/4-2-2-redis-messaging-layer.md:35
msgid ""
"- `readData()`负责将redis中待读取的事件读取出来，并放入ConsumerTableBase中的"
"队列中\n"
"- `pops()`：负责将队列中的原始事件取出来，并且进行解析，然后通过函数参数传递"
"给调用方"
msgstr ""
"- `readData()` is responsible for reading out the events to be read from "
"redis and putting them into the queue in ConsumerTableBase\n"
"- `pops()`: responsible for taking out the original events from the queue, "
"parsing them, and passing them to the caller via function parameters"

#: src/4-2-2-redis-messaging-layer.md:38
msgid ""
"```cpp\n"
"// File: sonic-swss-common - common/subscriberstatetable.cpp\n"
"uint64_t SubscriberStateTable::readData()\n"
"{\n"
"    // ...\n"
"    reply = nullptr;\n"
"    int status;\n"
"    do {\n"
"        status = redisGetReplyFromReader(m_subscribe->getContext(), "
"reinterpret_cast<void**>(&reply));\n"
"        if(reply != nullptr && status == REDIS_OK) {\n"
"            m_keyspace_event_buffer."
"emplace_back(make_shared<RedisReply>(reply));\n"
"        }\n"
"    } while(reply != nullptr && status == REDIS_OK);\n"
"    // ...\n"
"    return 0;\n"
"}\n"
"\n"
"void SubscriberStateTable::pops(deque<KeyOpFieldsValuesTuple> &vkco, const "
"string& /*prefix*/)\n"
"{\n"
"    vkco.clear();\n"
"    // ...\n"
"\n"
"    // Pop from m_keyspace_event_buffer, which is filled by readData()\n"
"    while (auto event = popEventBuffer()) {\n"
"        KeyOpFieldsValuesTuple kco;\n"
"        // Parsing here ...\n"
"        vkco.push_back(kco);\n"
"    }\n"
"\n"
"    m_keyspace_event_buffer.clear();\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: sonic-swss-common - common/subscriberstatetable.cpp\n"
"uint64_t SubscriberStateTable::readData()\n"
"{\n"
"    // ...\n"
"    reply = nullptr;\n"
"    int status;\n"
"    do {\n"
"        status = redisGetReplyFromReader(m_subscribe->getContext(), "
"reinterpret_cast<void**>(&reply));\n"
"        if(reply != nullptr && status == REDIS_OK) {\n"
"            m_keyspace_event_buffer."
"emplace_back(make_shared<RedisReply>(reply));\n"
"        }\n"
"    } while(reply != nullptr && status == REDIS_OK);\n"
"    // ...\n"
"    return 0;\n"
"}\n"
"\n"
"void SubscriberStateTable::pops(deque<KeyOpFieldsValuesTuple> &vkco, const "
"string& /*prefix*/)\n"
"{\n"
"    vkco.clear();\n"
"    // ...\n"
"\n"
"    // Pop from m_keyspace_event_buffer, which is filled by readData()\n"
"    while (auto event = popEventBuffer()) {\n"
"        KeyOpFieldsValuesTuple kco;\n"
"        // Parsing here ...\n"
"        vkco.push_back(kco);\n"
"    }\n"
"\n"
"    m_keyspace_event_buffer.clear();\n"
"}\n"
"```"

#: src/4-2-2-redis-messaging-layer.md:71
msgid "## NotificationProducer / NotificationConsumer"
msgstr "## NotificationProducer / NotificationConsumer"

#: src/4-2-2-redis-messaging-layer.md:73
msgid ""
"说到消息通信，我们很容易就会联想到消息队列，这就是我们的第二种通信方式 —— "
"[NotificationProducer](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/notificationproducer.h)和[NotificationConsumer](https://github."
"com/sonic-net/sonic-swss-common/blob/master/common/notificationconsumer.h)。"
msgstr ""
"When it comes to message communication, it's easy to associate it with "
"message queues, which is our second form of communication -- "
"[NotificationProducer](https://github.com/sonic-net/sonic-swss-common /blob/"
"master/common/notificationproducer.h) and [NotificationConsumer](https://"
"github.com/sonic-net/sonic-swss-common/blob/master/ common/"
"notificationconsumer.h)."

#: src/4-2-2-redis-messaging-layer.md:75
msgid ""
"这种通信方式通过Redis的自带的PubSub来实现，主要是对`PUBLISH`和`SUBSCRIBE`命令"
"的包装，很有限的应用在最简单的通知型的场景中，比如orchagent中的timeout "
"check, restart check之类，非传递用户配置和数据的场景："
msgstr ""
"This communication method is implemented through Redis' own PubSub, which is "
"mainly a wrapper around the `PUBLISH` and `SUBSCRIBE` commands, and is very "
"limited in the simplest notification scenarios, such as timeout check, "
"restart check, etc. in orchagent, not for passing user configuration and "
"data. Scenarios:"

#: src/4-2-2-redis-messaging-layer.md:79
msgid ""
"这种通信模式下，消息的发送方Producer，主要会做两件事情：一是将消息打包成JSON"
"格式，二是调用Redis的`PUBLISH`命令将消息发送出去。而且由于`PUBLISH`命令只能携"
"带一个消息，所以请求中的`op`和`data`字段会被放在`values`的最前面，然后再调用"
"`buildJson`函数将其打包成一个JSON数组的格式："
msgstr ""
"In this communication mode, the Producer, the sender of the message, does "
"two main things: first, it packages the message into JSON format, and "
"second, it calls Redis' `PUBLISH` command to send the message out. And since "
"the `PUBLISH` command can only carry one message, the `op` and `data` fields "
"in the request are placed at the top of the `values`, and then the "
"`buildJson` function is called to package it into a JSON array format:"

#: src/4-2-2-redis-messaging-layer.md:81
msgid ""
"```cpp\n"
"int64_t swss::NotificationProducer::send(const std::string &op, const std::"
"string &data, std::vector<FieldValueTuple> &values)\n"
"{\n"
"    // Pack the op and data into values array, then pack everything into a "
"JSON string as the message\n"
"    FieldValueTuple opdata(op, data);\n"
"    values.insert(values.begin(), opdata);\n"
"    std::string msg = JSon::buildJson(values);\n"
"    values.erase(values.begin());\n"
"\n"
"    // Publish message to Redis channel\n"
"    RedisCommand command;\n"
"    command.format(\"PUBLISH %s %s\", m_channel.c_str(), msg.c_str());\n"
"    // ...\n"
"    RedisReply reply = m_pipe->push(command);\n"
"    reply.checkReplyType(REDIS_REPLY_INTEGER);\n"
"    return reply.getReply<long long int>();\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"int64_t swss::NotificationProducer::send(const std::string &op, const std::"
"string &data, std::vector<FieldValueTuple> &values)\n"
"{\n"
"    // Pack the op and data into values array, then pack everything into a "
"JSON string as the message\n"
"    FieldValueTuple opdata(op, data);\n"
"    values.insert(values.begin(), opdata);\n"
"    std::string msg = JSon::buildJson(values);\n"
"    values.erase(values.begin());\n"
"\n"
"    // Publish message to Redis channel\n"
"    RedisCommand command;\n"
"    command.format(\"PUBLISH %s %s\", m_channel.c_str(), msg.c_str());\n"
"    // ...\n"
"    RedisReply reply = m_pipe->push(command);\n"
"    reply.checkReplyType(REDIS_REPLY_INTEGER);\n"
"    return reply.getReply<long long int>();\n"
"}\n"
"```"

#: src/4-2-2-redis-messaging-layer.md:100
msgid "接收方则是利用`SUBSCRIBE`命令来接收所有的通知："
msgstr "The receiver receives all notifications using the `SUBSCRIBE` command:"

#: src/4-2-2-redis-messaging-layer.md:102
msgid ""
"```cpp\n"
"void swss::NotificationConsumer::subscribe()\n"
"{\n"
"    // ...\n"
"    m_subscribe = new DBConnector(m_db->getDbId(),\n"
"                                    m_db->getContext()->unix_sock.path,\n"
"                                    NOTIFICATION_SUBSCRIBE_TIMEOUT);\n"
"    // ...\n"
"\n"
"    // Subscribe to Redis channel\n"
"    std::string s = \"SUBSCRIBE \" + m_channel;\n"
"    RedisReply r(m_subscribe, s, REDIS_REPLY_ARRAY);\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"void swss::NotificationConsumer::subscribe()\n"
"{\n"
"    // ...\n"
"    m_subscribe = new DBConnector(m_db->getDbId(),\n"
"                                    m_db->getContext()->unix_sock.path,\n"
"                                    NOTIFICATION_SUBSCRIBE_TIMEOUT);\n"
"    // ...\n"
"\n"
"    // Subscribe to Redis channel\n"
"    std::string s = \"SUBSCRIBE \" + m_channel;\n"
"    RedisReply r(m_subscribe, s, REDIS_REPLY_ARRAY);\n"
"}\n"
"```"

#: src/4-2-2-redis-messaging-layer.md:117
msgid "## ProducerTable / ConsumerTable"
msgstr "## ProducerTable / ConsumerTable"

#: src/4-2-2-redis-messaging-layer.md:119
msgid ""
"我们可以看到NotificationProducer/Consumer实现简单粗暴，但是由于API的限制 "
"[\\[8\\]][RedisClientHandling]，它并不适合用来传递数据，所以，SONiC中提供了一"
"种和它非常接近的另外一种基于消息队列的通信机制 —— [ProducerTable](https://"
"github.com/sonic-net/sonic-swss-common/blob/master/common/producertable.h)和"
"[ConsumerTable](https://github.com/sonic-net/sonic-swss-common/blob/master/"
"common/consumertable.h)。"
msgstr ""
"We can see that the NotificationProducer/Consumer implementation is simple "
"and brutal, but due to the limitations of the API [\\[8\\]]"
"[RedisClientHandling], it is not suitable for passing data, so an "
"alternative message queue-based communication mechanism is provided in SONiC "
"that is very close to it -- [ProducerTable](https://github.com/sonic-net/"
"sonic-swss-common/blob/master/common/producertable.h) and [ ConsumerTable]"
"(https://github.com/sonic-net/sonic-swss-common/blob/master/common/"
"consumertable.h)."

#: src/4-2-2-redis-messaging-layer.md:121
msgid ""
"这种通信方式通过Redis的List来实现，和Notification不同的地方在于，发布给"
"Channel中的消息非常的简单（单字符\"G\"），所有的数据都存储在List中，从而解决"
"了Notification中消息大小限制的问题。在SONiC中，它主要用在FlexCounter，`syncd`"
"服务和`ASIC_DB`中："
msgstr ""
"The difference between this communication method and Notification is that "
"the message published to the Channel is very simple (single character \"G\") "
"and all the data is stored in the List, thus solving the problem of message "
"size limitation in Notification. In SONiC, it is mainly used in the "
"FlexCounter, `syncd` service and `ASIC_DB`:"

#: src/4-2-2-redis-messaging-layer.md:123
msgid ""
"1. **消息格式**：每条消息都是一个（Key, FieldValuePairs, Op）的三元组，如果用"
"JSON来表达这个消息，那么它的格式如下：（这里的Key是Table中数据的Key，被操作的"
"数据是[Hash][RedisHash]，所以Field就是Hash中的Field，Value就是Hash中的Value"
"了，也就是说一个消息可以对很多个Field进行操作）\n"
"\n"
"   ```json\n"
"   [ \"Key\", \"[\\\"Field1\\\", \\\"Value1\\\", \\\"Field2\", \\\"Value2\\"
"\", ...]\", \"Op\" ]\n"
"   ```\n"
"\n"
"2. **Enqueue**：ProducerTable通过Lua脚本将消息三元组原子的写入消息队列中"
"（Key = `<table-name>_KEY_VALUE_OP_QUEUE`，并且发布更新通知到特定的Channel"
"（Key = `<table-name>_CHANNEL`）中。\n"
"3. **Pop**：ConsumerTable也通过Lua脚本从消息队列中原子的读取消息三元组，并**"
"在读取过程中**将其中请求的改动真正的写入到数据库中。"
msgstr ""
"1. **Message format**: Each message is a triple of (Key, FieldValuePairs, "
"Op), if the message is expressed in JSON, then it has the following format: "
"(Here the Key is the Key of the data in the Table, the data being operated "
"on is [Hash][RedisHash], so the Field is the The Field is the Field in the "
"Hash, and the Value is the Value in the Hash, which means that a message can "
"operate on many Fields)\n"
"\n"
"   ```json\n"
"   [ \"Key\", \"[\\\"Field1\\\", \\\"Value1\\\", \\\"Field2\\\", \\\"Value2\\"
"\", ...]\" , \"Op\" ]\n"
"   ```\n"
"\n"
"2. **Enqueue**: ProducerTable writes the message triplet atomically to the "
"message queue (Key = `<table-name>_KEY_VALUE_OP_QUEUE`) via Lua script and "
"issues update notifications to a specific Channel (Key = `<table-name>_ "
"CHANNEL`).\n"
"3. **Pop**: ConsumerTable also reads the message triplet atomically from the "
"message queue via Lua script and **during the read** actually writes the "
"requested changes therein to the database."

#: src/4-2-2-redis-messaging-layer.md:132
msgid ""
"```admonish note\n"
"**注意**：Redis中Lua脚本和MULTI/EXEC的原子性和通常说的数据库ACID中的原子性"
"（Atomicity）不同，Redis中的原子性其实更接近于ACID中的隔离性（Isolation），他"
"保证Lua脚本中所有的命令在执行的时候不会有其他的命令执行，但是并不保证Lua脚本"
"中的所有命令都会执行成功，比如，如果Lua脚本中的第二个命令执行失败了，那么第一"
"个命令依然会被提交，只是后面的命令就不会继续执行了。更多的细节可以参考Redis官"
"方文档 [\\[5\\]][RedisTx] [\\[6\\]][RedisLuaAtomicity]。\n"
"```"
msgstr ""
"```admonish note\n"
"**注意**：Redis中Lua脚本和MULTI/EXEC的原子性和通常说的数据库ACID中的原子性"
"（Atomicity）不同，Redis中的原子性其实更接近于ACID中的隔离性（Isolation），他"
"保证Lua脚本中所有的命令在执行的时候不会有其他的命令执行，但是并不保证Lua脚本"
"中的所有命令都会执行成功，比如，如果Lua脚本中的第二个命令执行失败了，那么第一"
"个命令依然会被提交，只是后面的命令就不会继续执行了。更多的细节可以参考Redis官"
"方文档 [\\[5\\]][RedisTx] [\\[6\\]][RedisLuaAtomicity]。\n"
"```"

#: src/4-2-2-redis-messaging-layer.md:136
msgid ""
"其主要类图如下，这里我们可以看到在ProducerTable中的`m_shaEnqueue`和"
"ConsumerTable中的`m_shaPop`，它们就是上面我们提到的这两个Lua脚本在加载时获得"
"的SHA了，而之后我们就可以使用Redis的`EVALSHA`命令对他们进行原子的调用了："
msgstr ""
"The main class diagram is as follows. Here we can see `m_shaEnqueue` in the "
"ProducerTable and `m_shaPop` in the ConsumerTable, which are the SHAs "
"obtained by the two Lua scripts we mentioned above at load time, and we can "
"then use Redis's `EVALSHA` command to make atomic calls to them: the"

#: src/4-2-2-redis-messaging-layer.md:140
msgid ""
"ProducerTable的核心逻辑如下，我们可以看到对Values的JSON打包，和使用`EVALSHA`"
"来进行Lua脚本的调用："
msgstr ""
"The core logic of the ProducerTable is as follows, we can see the JSON "
"packaging of Values and the use of `EVALSHA` to make Lua script calls:"

#: src/4-2-2-redis-messaging-layer.md:142
msgid ""
"```cpp\n"
"// File: sonic-swss-common - common/producertable.cpp\n"
"ProducerTable::ProducerTable(RedisPipeline *pipeline, const string "
"&tableName, bool buffered)\n"
"    // ...\n"
"{\n"
"    string luaEnque =\n"
"        \"redis.call('LPUSH', KEYS[1], ARGV[1], ARGV[2], ARGV[3]);\"\n"
"        \"redis.call('PUBLISH', KEYS[2], ARGV[4]);\";\n"
"\n"
"    m_shaEnque = m_pipe->loadRedisScript(luaEnque);\n"
"}\n"
"\n"
"void ProducerTable::set(const string &key, const vector<FieldValueTuple> "
"&values, const string &op, const string &prefix)\n"
"{\n"
"    enqueueDbChange(key, JSon::buildJson(values), \"S\" + op, prefix);\n"
"}\n"
"\n"
"void ProducerTable::del(const string &key, const string &op, const string "
"&prefix)\n"
"{\n"
"    enqueueDbChange(key, \"{}\", \"D\" + op, prefix);\n"
"}\n"
"\n"
"void ProducerTable::enqueueDbChange(const string &key, const string &value, "
"const string &op, const string& /* prefix */)\n"
"{\n"
"    RedisCommand command;\n"
"\n"
"    command.format(\n"
"        \"EVALSHA %s 2 %s %s %s %s %s %s\",\n"
"        m_shaEnque.c_str(),\n"
"        getKeyValueOpQueueTableName().c_str(),\n"
"        getChannelName(m_pipe->getDbId()).c_str(),\n"
"        key.c_str(),\n"
"        value.c_str(),\n"
"        op.c_str(),\n"
"        \"G\");\n"
"\n"
"    m_pipe->push(command, REDIS_REPLY_NIL);\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: sonic-swss-common - common/producertable.cpp\n"
"ProducerTable::ProducerTable(RedisPipeline *pipeline, const string "
"&tableName, bool buffered)\n"
"    // ...\n"
"{\n"
"    string luaEnque =\n"
"        \"redis.call('LPUSH', KEYS[1], ARGV[1], ARGV[2], ARGV[3]);\"\n"
"        \"redis.call('PUBLISH', KEYS[2], ARGV[4]);\";\n"
"\n"
"    m_shaEnque = m_pipe->loadRedisScript(luaEnque);\n"
"}\n"
"\n"
"void ProducerTable::set(const string &key, const vector<FieldValueTuple> "
"&values, const string &op, const string &prefix)\n"
"{\n"
"    enqueueDbChange(key, JSon::buildJson(values), \"S\" + op, prefix);\n"
"}\n"
"\n"
"void ProducerTable::del(const string &key, const string &op, const string "
"&prefix)\n"
"{\n"
"    enqueueDbChange(key, \"{}\", \"D\" + op, prefix);\n"
"}\n"
"\n"
"void ProducerTable::enqueueDbChange(const string &key, const string &value, "
"const string &op, const string& /* prefix */)\n"
"{\n"
"    RedisCommand command;\n"
"\n"
"    command.format(\n"
"        \"EVALSHA %s 2 %s %s %s %s %s %s\",\n"
"        m_shaEnque.c_str(),\n"
"        getKeyValueOpQueueTableName().c_str(),\n"
"        getChannelName(m_pipe->getDbId()).c_str(),\n"
"        key.c_str(),\n"
"        value.c_str(),\n"
"        op.c_str(),\n"
"        \"G\");\n"
"\n"
"    m_pipe->push(command, REDIS_REPLY_NIL);\n"
"}\n"
"```"

#: src/4-2-2-redis-messaging-layer.md:182
msgid ""
"而另一侧的ConsumerTable就稍稍复杂一点，因为其支持的op类型很多，所以逻辑都写在"
"了一个单独的文件中（`common/consumer_table_pops.lua`），我们这里就不贴代码"
"了，有兴趣的同学可以自己去看看。"
msgstr ""
"The other side of the ConsumerTable is a little more complicated, because it "
"supports many op types, so the logic is written in a separate file (`common/"
"consumer_table_pops.lua`), we won't post the code here, interested students "
"can see for themselves."

#: src/4-2-2-redis-messaging-layer.md:184
msgid ""
"```cpp\n"
"// File: sonic-swss-common - common/consumertable.cpp\n"
"ConsumerTable::ConsumerTable(DBConnector *db, const string &tableName, int "
"popBatchSize, int pri)\n"
"    : ConsumerTableBase(db, tableName, popBatchSize, pri)\n"
"    , TableName_KeyValueOpQueues(tableName)\n"
"    , m_modifyRedis(true)\n"
"{\n"
"    std::string luaScript = loadLuaScript(\"consumer_table_pops.lua\");\n"
"    m_shaPop = loadRedisScript(db, luaScript);\n"
"    // ...\n"
"}\n"
"\n"
"void ConsumerTable::pops(deque<KeyOpFieldsValuesTuple> &vkco, const string "
"&prefix)\n"
"{\n"
"    // Note that here we are processing the messages in bulk with "
"POP_BATCH_SIZE!\n"
"    RedisCommand command;\n"
"    command.format(\n"
"        \"EVALSHA %s 2 %s %s %d %d\",\n"
"        m_shaPop.c_str(),\n"
"        getKeyValueOpQueueTableName().c_str(),\n"
"        (prefix+getTableName()).c_str(),\n"
"        POP_BATCH_SIZE,\n"
"\n"
"    RedisReply r(m_db, command, REDIS_REPLY_ARRAY);\n"
"    vkco.clear();\n"
"\n"
"    // Parse and pack the messages in bulk\n"
"    // ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: sonic-swss-common - common/consumertable.cpp\n"
"ConsumerTable::ConsumerTable(DBConnector *db, const string &tableName, int "
"popBatchSize, int pri)\n"
"    : ConsumerTableBase(db, tableName, popBatchSize, pri)\n"
"    , TableName_KeyValueOpQueues(tableName)\n"
"    , m_modifyRedis(true)\n"
"{\n"
"    std::string luaScript = loadLuaScript(\"consumer_table_pops.lua\");\n"
"    m_shaPop = loadRedisScript(db, luaScript);\n"
"    // ...\n"
"}\n"
"\n"
"void ConsumerTable::pops(deque<KeyOpFieldsValuesTuple> &vkco, const string "
"&prefix)\n"
"{\n"
"    // Note that here we are processing the messages in bulk with "
"POP_BATCH_SIZE!\n"
"    RedisCommand command;\n"
"    command.format(\n"
"        \"EVALSHA %s 2 %s %s %d %d\",\n"
"        m_shaPop.c_str(),\n"
"        getKeyValueOpQueueTableName().c_str(),\n"
"        (prefix+getTableName()).c_str(),\n"
"        POP_BATCH_SIZE,\n"
"\n"
"    RedisReply r(m_db, command, REDIS_REPLY_ARRAY);\n"
"    vkco.clear();\n"
"\n"
"    // Parse and pack the messages in bulk\n"
"    // ...\n"
"}\n"
"```"

#: src/4-2-2-redis-messaging-layer.md:215
msgid "## ProducerStateTable / ConsumerStateTable"
msgstr "## ProducerStateTable / ConsumerStateTable"

#: src/4-2-2-redis-messaging-layer.md:217
msgid ""
"Producer/ConsumerTable虽然直观，而且保序，但是它一个消息只能处理一个Key，并且"
"还需要JSON的序列化，然而很多时候我们并用不到保序的功能，反而更需要更大的吞吐"
"量，所以为了优化性能，SONiC就引入了第四种通信方式，也是最常用的通信方式："
"[ProducerStateTable](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/producerstatetable.h)和[ConsumerStateTable](https://github.com/"
"sonic-net/sonic-swss-common/blob/master/common/consumertatetable.h)。"
msgstr ""
"Although Producer/ConsumerTable is intuitive and order-preserving, it can "
"only handle one Key for one message and also requires JSON serialization, "
"however, many times we do not use the order-preserving function, but rather "
"need more throughput, so in order to optimize performance, SONiC introduces "
"the fourth communication method, which is also the most commonly used "
"communication method: the [ProducerStateTable](https://github.com/sonic-net/"
"sonic-swss-common/blob/master/common/producerstatetable.h) and "
"[ConsumerStateTable]( https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/consumertatetable.h)."

#: src/4-2-2-redis-messaging-layer.md:219
msgid ""
"与ProducerTable不同，ProducerStateTable使用Hash的方式来存储消息，而不是List。"
"这样虽然不能保证消息的顺序，但是却可以很好的提升性能！首先，我们省下了JSON的"
"序列化的开销，其次，对于同一个Key下的相同的Field如果被变更多次，那么只需要保"
"留最后一次的变更，这样就将关于这个Key的所有变更消息就合并成了一条，减少了很多"
"不必要的消息处理。"
msgstr ""
"Unlike ProducerTable, ProducerStateTable uses Hash to store messages instead "
"of List, which doesn't guarantee the order of messages, but is a great "
"performance boost! First, we save the overhead of JSON serialization, and "
"second, for the same Field under the same Key if it is changed several "
"times, then only the last change needs to be kept, so that all the change "
"messages about the Key are combined into one, reducing a lot of unnecessary "
"message processing."

#: src/4-2-2-redis-messaging-layer.md:221
msgid ""
"Producer/ConsumerStateTable的底层实现相比于Producer/ConsumerTable也更加复杂一"
"些。其相关联的类的主要类图如下，这里我们依然可以看到它的实现是通过`EVALSHA`调"
"用Lua脚本来实现的，`m_shaSet`和`m_shaDel`就是用来存放修改和发送消息的，而另一"
"边`m_shaPop`就是用来获取消息的："
msgstr ""
"The underlying implementation of Producer/ConsumerStateTable is also a bit "
"more complex than Producer/ConsumerTable. The main class diagram of its "
"associated classes is as follows. Here we can still see that it is "
"implemented by calling Lua scripts through `EVALSHA`, `m_shaSet` and "
"`m_shaDel` are used to store modified and sent messages, while `m_shaPop` is "
"used to get messages on the other side:"

#: src/4-2-2-redis-messaging-layer.md:225
msgid "在传递消息时："
msgstr "When delivering messages:"

#: src/4-2-2-redis-messaging-layer.md:227
msgid ""
"- 首先，每个消息会被存放成两个部分：一个是KEY_SET，用来保存当前有哪些Key发生"
"了修改，它以Set的形式存放在`<table-name_KEY_SET>`的key下，另一个是所有被修改"
"的Key的内容，它以Hash的形式存放在`_<redis-key-name>`的key下。\n"
"- 然后，消息存放之后Producer如果发现是新的Key，那么就是调用`PUBLISH`命令，来"
"通知`<table-name>_CHANNEL@<db-id>`Channel，有新的Key出现了。\n"
"\n"
"  ```cpp\n"
"  // File: sonic-swss-common - common/producerstatetable.cpp\n"
"  ProducerStateTable::ProducerStateTable(RedisPipeline *pipeline, const "
"string &tableName, bool buffered)\n"
"      : TableBase(tableName, SonicDBConfig::getSeparator(pipeline-"
">getDBConnector()))\n"
"      , TableName_KeySet(tableName)\n"
"      // ...\n"
"  {\n"
"      string luaSet =\n"
"          \"local added = redis.call('SADD', KEYS[2], ARGV[2])\\n\"\n"
"          \"for i = 0, #KEYS - 3 do\\n\"\n"
"          \"    redis.call('HSET', KEYS[3 + i], ARGV[3 + i * 2], ARGV[4 + i "
"* 2])\\n\"\n"
"          \"end\\n\"\n"
"          \" if added > 0 then \\n\"\n"
"          \"    redis.call('PUBLISH', KEYS[1], ARGV[1])\\n\"\n"
"          \"end\\n\";\n"
"\n"
"      m_shaSet = m_pipe->loadRedisScript(luaSet);\n"
"  ```\n"
"\n"
"- 最后，Consumer会通过`SUBSCRIBE`命令来订阅`<table-name>_CHANNEL@<db-"
"id>`Channel，一旦有新的消息到来，就会使用Lua脚本调用`HGETALL`命令来获取所有的"
"Key，并将其中的值读取出来并真正的写入到数据库中去。\n"
"\n"
"  ```cpp\n"
"  ConsumerStateTable::ConsumerStateTable(DBConnector *db, const std::string "
"&tableName, int popBatchSize, int pri)\n"
"      : ConsumerTableBase(db, tableName, popBatchSize, pri)\n"
"      , TableName_KeySet(tableName)\n"
"  {\n"
"      std::string luaScript = loadLuaScript(\"consumer_state_table_pops."
"lua\");\n"
"      m_shaPop = loadRedisScript(db, luaScript);\n"
"      // ...\n"
"  \n"
"      subscribe(m_db, getChannelName(m_db->getDbId()));\n"
"      // ...\n"
"  ```"
msgstr ""
"- First, each message is stored into two parts: one is KEY_SET, which is "
"used to store which Keys are currently modified, and it is stored as a Set "
"under the key of `<table-name_KEY_SET>`, and the other is the content of all "
"modified Keys, and it is stored as a Hash under the key of `_<redis-key- "
"name>` under the key.\n"
"- Then, after the message is stored the Producer, if it finds that it is a "
"new Key, then it is calling the `PUBLISH` command to notify the `<table-"
"name>_CHANNEL@<db-id>`Channel that a new Key is available.\n"
"\n"
"  ```cpp\n"
"  // File: sonic-swss-common - common/producerstatetable.cpp\n"
"  ProducerStateTable::ProducerStateTable(RedisPipeline *pipeline, const "
"string &tableName, bool buffered)\n"
"      : TableBase(tableName, SonicDBConfig::getSeparator(pipeline -> "
"getDBConnector()))\n"
"      , TableName_KeySet(tableName)\n"
"      // ...\n"
"  {\n"
"      string luaSet =\n"
"          \"local added = redis.call('SADD', KEYS[2], ARGV[2])\\n\"\n"
"          \"for i = 0, #KEYS - 3 do\\n\"\n"
"          \" redis.call('HSET', KEYS[3 + i], ARGV[3 + i * 2], ARGV[4 + i * "
"2])\\n\"\n"
"          \"end\\n\"\n"
"          \" if added > 0 then \\n\"\n"
"          \" redis.call('PUBLISH', KEYS[1], ARGV[1])\\n\"\n"
"          \"end\\n\".\n"
"\n"
"      m_shaSet = m_pipe->loadRedisScript(luaSet).\n"
"  ```\n"
"\n"
"- Finally, the Consumer will subscribe to the `<table-name>_CHANNEL@<db-"
"id>`Channel with the `SUBSCRIBE` command, and once a new message arrives, it "
"will use the LuaScript to call the `HGETALL` command to get all the Keys and "
"read the values from them and actually write them to the the database.\n"
"\n"
"  ```cpp\n"
"  ConsumerStateTable::ConsumerStateTable(DBConnector *db, const std::string "
"&tableName, int popBatchSize, int pri)\n"
"      : ConsumerTableBase(db, tableName, popBatchSize, pri)\n"
"      , TableName_KeySet(tableName)\n"
"  {\n"
"      std::string luaScript = loadLuaScript(\"consumer_state_table_pops."
"lua\").\n"
"      m_shaPop = loadRedisScript(db, luaScript).\n"
"      // ...\n"
"\n"
"      subscribe(m_db, getChannelName(m_db->getDbId())).\n"
"      // ...\n"
"  ```"

#: src/4-2-2-redis-messaging-layer.md:264
msgid "为了方便理解，我们这里举一个例子：启用Port Ethernet0："
msgstr ""
"For ease of understanding, let's take an example here: Enabling Port "
"Ethernet0:"

#: src/4-2-2-redis-messaging-layer.md:266
msgid ""
"- 首先，我们在命令行下调用`config interface startup Ethernet0`来启用"
"Ethernet0，这会导致`portmgrd`通过ProducerStateTable向APP_DB发送状态更新消息，"
"如下：\n"
"\n"
"  ```redis\n"
"  EVALSHA \"<hash-of-set-lua>\" \"6\" \"PORT_TABLE_CHANNEL@0\" "
"\"PORT_TABLE_KEY_SET\" \n"
"      \"_PORT_TABLE:Ethernet0\" \"_PORT_TABLE:Ethernet0\" \"_PORT_TABLE:"
"Ethernet0\" \"_PORT_TABLE:Ethernet0\" \"G\"\n"
"      \"Ethernet0\" \"alias\" \"Ethernet5/1\" \"index\" \"5\" \"lanes\" "
"\"9,10,11,12\" \"speed\" \"40000\"\n"
"  ```\n"
"\n"
"  这个命令会在其中调用如下的命令来创建和发布消息：\n"
"\n"
"  ```redis\n"
"  SADD \"PORT_TABLE_KEY_SET\" \"_PORT_TABLE:Ethernet0\"\n"
"  HSET \"_PORT_TABLE:Ethernet0\" \"alias\" \"Ethernet5/1\"\n"
"  HSET \"_PORT_TABLE:Ethernet0\" \"index\" \"5\"\n"
"  HSET \"_PORT_TABLE:Ethernet0\" \"lanes\" \"9,10,11,12\"\n"
"  HSET \"_PORT_TABLE:Ethernet0\" \"speed\" \"40000\"\n"
"  PUBLISH \"PORT_TABLE_CHANNEL@0\" \"_PORT_TABLE:Ethernet0\"\n"
"  ```\n"
"\n"
"  所以最终这个消息会在APPL_DB中被存放成如下的形式：\n"
"\n"
"  ```redis\n"
"  PORT_TABLE_KEY_SET:\n"
"    _PORT_TABLE:Ethernet0\n"
"\n"
"  _PORT_TABLE:Ethernet0:\n"
"    alias: Ethernet5/1\n"
"    index: 5\n"
"    lanes: 9,10,11,12\n"
"    speed: 40000\n"
"  ```\n"
"\n"
"- 当ConsumerStateTable收到消息后，也会调用`EVALSHA`命令来执行Lua脚本，如"
"下：\n"
"\n"
"  ```redis\n"
"  EVALSHA \"<hash-of-pop-lua>\" \"3\" \"PORT_TABLE_KEY_SET\" \"PORT_TABLE:\" "
"\"PORT_TABLE_DEL_SET\" \"8192\" \"_\"\n"
"  ```\n"
"\n"
"  和Producer类似，这个脚本会执行如下命令，将`PORT_TABLE_KEY_SET`中的key，也就"
"是`_PORT_TABLE:Ethernet0`读取出来，然后再将其对应的Hash读取出来，并更新到"
"`PORT_TABLE:Ethernet0`去，同时将`_PORT_TABLE:Ethernet0`从数据库和"
"`PORT_TABLE_KEY_SET`中删除。\n"
"\n"
"  ```redis\n"
"  SPOP \"PORT_TABLE_KEY_SET\" \"_PORT_TABLE:Ethernet0\"\n"
"  HGETALL \"_PORT_TABLE:Ethernet0\"\n"
"  HSET \"PORT_TABLE:Ethernet0\" \"alias\" \"Ethernet5/1\"\n"
"  HSET \"PORT_TABLE:Ethernet0\" \"index\" \"5\"\n"
"  HSET \"PORT_TABLE:Ethernet0\" \"lanes\" \"9,10,11,12\"\n"
"  HSET \"PORT_TABLE:Ethernet0\" \"speed\" \"40000\"\n"
"  DEL \"_PORT_TABLE:Ethernet0\"\n"
"  ```\n"
"\n"
"  到这里，数据的更新才算是完成了。"
msgstr ""
"- First, we enable Ethernet0 by calling `config interface startup Ethernet0` "
"at the command line, which causes `portmgrd` to send a state update message "
"to APP_DB via the ProducerStateTable as follows:\n"
"\n"
"  ``redis\n"
"  EVALSHA \"<hash-of-set-lua>\" \"6\" \"PORT_TABLE_CHANNEL@0\" "
"\"PORT_TABLE_KEY_SET\"\n"
"      \"_PORT_TABLE:Ethernet0\" \"_PORT_TABLE:Ethernet0\" \"_PORT_TABLE:"
"Ethernet0\" \"_PORT_TABLE:Ethernet0\" \"_PORT_TABLE:Ethernet0\" \"G\"\n"
"      \"Ethernet0\" \"alias\" \"Ethernet5/1\" \"index\" \"5\" \"lanes\" "
"\"9,10,11,12\" \"speed\" \"40000\"\n"
"  ```\n"
"\n"
"  This command will create and publish messages by calling the following "
"commands in it:\n"
"\n"
"  ```redis\n"
"  SADD \"PORT_TABLE_KEY_SET\" \"_PORT_TABLE:Ethernet0\"\n"
"  HSET \"_PORT_TABLE:Ethernet0\" \"alias\" \"Ethernet5/1\"\n"
"  HSET \"_PORT_TABLE:Ethernet0\" \"index\" \"5\"\n"
"  HSET \"_PORT_TABLE:Ethernet0\" \"lanes\" \"9,10,11,12\"\n"
"  HSET \"_PORT_TABLE:Ethernet0\" \"speed\" \"40000\"\n"
"  PUBLISH \"PORT_TABLE_CHANNEL@0\" \"_PORT_TABLE:Ethernet0\"\n"
"  ```\n"
"\n"
"  So eventually this message will be stored in APPL_DB in the following "
"form:\n"
"\n"
"  ```redis\n"
"  PORT_TABLE_KEY_SET.\n"
"    _PORT_TABLE:Ethernet0\n"
"\n"
"  _PORT_TABLE:Ethernet0.\n"
"    alias: Ethernet5/1\n"
"    index: 5\n"
"    lanes: 9,10,11,12\n"
"    speed: 40000\n"
"  ```\n"
"\n"
"- When the ConsumerStateTable receives the message, it also calls the "
"`EVALSHA` command to execute the Lua script, as follows:\n"
"\n"
"  ```redis\n"
"  EVALSHA \"<hash-of-pop-lua>\" \"3\" \"PORT_TABLE_KEY_SET\" \"PORT_TABLE:\" "
"\"PORT_TABLE_DEL_SET\" \"8192\" \"_\"\n"
"  ```\n"
"\n"
"  Similar to Producer, this script will execute the following command to "
"read out the key in `PORT_TABLE_KEY_SET`, which is `_PORT_TABLE:Ethernet0`, "
"and then read out its corresponding hash and update it to `PORT_TABLE:"
"Ethernet0`, and at the same time, read out the `_PORT_TABLE:Ethernet0` is "
"removed from the database and `PORT_TABLE_KEY_SET`.\n"
"\n"
"  ``redis\n"
"  SPOP \"PORT_TABLE_KEY_SET\" \"_PORT_TABLE:Ethernet0\"\n"
"  HGETALL \"_PORT_TABLE:Ethernet0\"\n"
"  HSET \"PORT_TABLE:Ethernet0\" \"alias\" \"Ethernet5/1\"\n"
"  HSET \"PORT_TABLE:Ethernet0\" \"index\" \"5\"\n"
"  HSET \"PORT_TABLE:Ethernet0\" \"lanes\" \"9,10,11,12\"\n"
"  HSET \"PORT_TABLE:Ethernet0\" \"speed\" \"40000\"\n"
"  DEL \"_PORT_TABLE:Ethernet0\"\n"
"  ```\n"
"\n"
"  Here, the data update is considered complete."

#: src/4-2-2-redis-messaging-layer.md:320
msgid ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [Github repo: sonic-swss][SONiCSWSS]\n"
"3. [Github repo: sonic-swss-common][SONiCSWSSCommon]\n"
"4. [Redis keyspace notifications][RedisKeyspace]\n"
"5. [Redis Transactions][RedisTx]\n"
"6. [Redis Atomicity with Lua][RedisLuaAtomicity]\n"
"7. [Redis hashes][RedisHash]\n"
"8. [Redis client handling][RedisClientHandling]"
msgstr ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [Github repo: sonic-swss][SONiCSWSS]\n"
"3. [Github repo: sonic-swss-common][SONiCSWSSCommon]\n"
"4. [Redis keyspace notifications][RedisKeyspace]\n"
"5. [Redis Transactions][RedisTx]\n"
"6. [Redis Atomicity with Lua][RedisLuaAtomicity]\n"
"7. [Redis hashes][RedisHash]\n"
"8. [Redis client handling][RedisClientHandling]"

#: src/4-3-zmq-messaging.md:1
msgid "# 基于ZMQ的通信"
msgstr "# ZMQ-based communication"

#: src/4-4-orch-layer.md:1
msgid "# 服务层 - Orch"
msgstr "# Service Layer - Orch"

#: src/4-4-orch-layer.md:3
msgid ""
"最后，为了方便各个服务使用，SONiC还在通信层上进行了更进一步的封装，为各个服务"
"提供了一个基类：[Orch](https://github.com/sonic-net/sonic-swss/blob/master/"
"src/orchagent/orch.hcommon/consumertatetable.h)。"
msgstr ""
"Finally, to facilitate the use of the individual services, SONiC has further "
"encapsulated the communication layer by providing a base class for each "
"service: [Orch](https://github.com/sonic-net/sonic-swss/blob/master/src/"
"orchagent/orch. hcommon/consumertatetable.h)."

#: src/4-4-orch-layer.md:5
msgid ""
"由于有了上面这些封装，Orch中关于消息通信的封装就相对简单了，主要的类图如下："
msgstr ""
"Thanks to these above encapsulations, the encapsulation of message "
"communication in Orch is relatively simple, and the main class diagram is as "
"follows:"

#: src/4-4-orch-layer.md:9
msgid ""
"```admonish note\n"
"注意：由于这一层是服务层，所以其代码是在`sonic-swss`的仓库中，而不是`sonic-"
"swss`。这个类中除了消息通信的封装以外，还提供了很多和服务实现相关的公共函数，"
"比如，日志文件等等。\n"
"```"
msgstr ""
"```admonish note\n"
"注意：由于这一层是服务层，所以其代码是在`sonic-swss`的仓库中，而不是`sonic-"
"swss`。这个类中除了消息通信的封装以外，还提供了很多和服务实现相关的公共函数，"
"比如，日志文件等等。\n"
"```"

#: src/4-4-orch-layer.md:13
msgid ""
"可以看到，Orch主要是封装了`SubscriberStateTable`和`ConsumerStateTable`来简化"
"和统一消息的订阅，核心代码非常简单，就是根据不同的数据库类型来创建不同的"
"Consumer，如下："
msgstr ""
"As you can see, Orch mainly encapsulates `SubscriberStateTable` and "
"`ConsumerStateTable` to simplify and unify the subscription of messages. The "
"core code is very simple, which is to create different Consumers according "
"to different database types, as follows:"

#: src/4-4-orch-layer.md:15
msgid ""
"```cpp\n"
"void Orch::addConsumer(DBConnector *db, string tableName, int pri)\n"
"{\n"
"    if (db->getDbId() == CONFIG_DB || db->getDbId() == STATE_DB || db-"
">getDbId() == CHASSIS_APP_DB) {\n"
"        addExecutor(\n"
"            new Consumer(\n"
"                new SubscriberStateTable(db, tableName, TableConsumable::"
"DEFAULT_POP_BATCH_SIZE, pri),\n"
"                this,\n"
"                tableName));\n"
"    } else {\n"
"        addExecutor(\n"
"            new Consumer(\n"
"                new ConsumerStateTable(db, tableName, gBatchSize, pri),\n"
"                this,\n"
"                tableName));\n"
"    }\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"void Orch::addConsumer(DBConnector *db, string tableName, int pri)\n"
"{\n"
"    if (db->getDbId() == CONFIG_DB || db->getDbId() == STATE_DB || db-"
">getDbId() == CHASSIS_APP_DB) {\n"
"        addExecutor(\n"
"            new Consumer(\n"
"                new SubscriberStateTable(db, tableName, TableConsumable::"
"DEFAULT_POP_BATCH_SIZE, pri),\n"
"                this,\n"
"                tableName));\n"
"    } else {\n"
"        addExecutor(\n"
"            new Consumer(\n"
"                new ConsumerStateTable(db, tableName, gBatchSize, pri),\n"
"                this,\n"
"                tableName));\n"
"    }\n"
"}\n"
"```"

#: src/4-5-event-polling-and-error-handling.md:1
msgid "# 事件分发和错误处理"
msgstr "# Event distribution and error handling"

#: src/4-5-event-polling-and-error-handling.md:3
msgid "## 基于epoll的事件分发机制"
msgstr "## epoll-based event distribution mechanism"

#: src/4-5-event-polling-and-error-handling.md:5
msgid "和很多的Linux服务一样，SONiC底层使用了epoll作为事件分发机制："
msgstr ""
"As with many Linux services, SONiC uses epoll as the event distribution "
"mechanism at the bottom:"

#: src/4-5-event-polling-and-error-handling.md:7
msgid ""
"- 所有需要支持事件分发的类都需要继承`Selectable`类，并实现两个最核心的函数："
"`int getFd();`（用于返回epoll能用来监听事件的fd）和`uint64_t readData()`（用"
"于在监听到事件到来之后进行读取）。而对于一般服务而言，这个fd就是redis通信使用"
"的fd，所以`getFd()`函数的调用，都会被最终转发到Redis的库中。\n"
"- 所有需要参与事件分发的对象，都需要注册到`Select`类中，这个类会将所有的"
"`Selectable`对象的fd注册到epoll中，并在事件到来时调用`Selectable`的"
"`readData()`函数。"
msgstr ""
"- All classes that need to support event distribution need to inherit the "
"`Selectable` class and implement the two core functions: `int getFd();` "
"(used to return the fd that epoll can use to listen for events) and "
"`uint64_t readData()` (used to read events as they come in). For general "
"services, this fd is the fd used for redis communication, so calls to the "
"`getFd()` function are eventually forwarded to the Redis library.\n"
"- All objects that need to participate in event distribution need to be "
"registered to the `Select` class, which registers the fd of all `Selectable` "
"objects to epoll and calls the `readData()` function of `Selectable` when "
"the event arrives."

#: src/4-5-event-polling-and-error-handling.md:10
msgid "其类图如下："
msgstr "The class diagram is as follows:"

#: src/4-5-event-polling-and-error-handling.md:14
msgid "在Select类中，我们可以很容易的找到其最核心的代码，实现也非常的简单："
msgstr ""
"In the Select class, we can easily find its most core code, and the "
"implementation is very simple:"

#: src/4-5-event-polling-and-error-handling.md:16
msgid ""
"```cpp\n"
"int Select::poll_descriptors(Selectable **c, unsigned int timeout, bool "
"interrupt_on_signal = false)\n"
"{\n"
"    int sz_selectables = static_cast<int>(m_objects.size());\n"
"    std::vector<struct epoll_event> events(sz_selectables);\n"
"    int ret;\n"
"\n"
"    while(true) {\n"
"        ret = ::epoll_wait(m_epoll_fd, events.data(), sz_selectables, "
"timeout);\n"
"        // ...\n"
"    }\n"
"    // ...\n"
"\n"
"    for (int i = 0; i < ret; ++i)\n"
"    {\n"
"        int fd = events[i].data.fd;\n"
"        Selectable* sel = m_objects[fd];\n"
"\n"
"        sel->readData();\n"
"        // error handling here ...\n"
"\n"
"        m_ready.insert(sel);\n"
"    }\n"
"\n"
"    while (!m_ready.empty())\n"
"    {\n"
"        auto sel = *m_ready.begin();\n"
"        m_ready.erase(sel);\n"
"        \n"
"        // After update callback ...\n"
"        return Select::OBJECT;\n"
"    }\n"
"\n"
"    return Select::TIMEOUT;\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"int Select::poll_descriptors(Selectable **c, unsigned int timeout, bool "
"interrupt_on_signal = false)\n"
"{\n"
"    int sz_selectables = static_cast<int>(m_objects.size());\n"
"    std::vector<struct epoll_event> events(sz_selectables);\n"
"    int ret;\n"
"\n"
"    while(true) {\n"
"        ret = ::epoll_wait(m_epoll_fd, events.data(), sz_selectables, "
"timeout);\n"
"        // ...\n"
"    }\n"
"    // ...\n"
"\n"
"    for (int i = 0; i < ret; ++i)\n"
"    {\n"
"        int fd = events[i].data.fd;\n"
"        Selectable* sel = m_objects[fd];\n"
"\n"
"        sel->readData();\n"
"        // error handling here ...\n"
"\n"
"        m_ready.insert(sel);\n"
"    }\n"
"\n"
"    while (!m_ready.empty())\n"
"    {\n"
"        auto sel = *m_ready.begin();\n"
"        m_ready.erase(sel);\n"
"        \n"
"        // After update callback ...\n"
"        return Select::OBJECT;\n"
"    }\n"
"\n"
"    return Select::TIMEOUT;\n"
"}\n"
"```"

#: src/4-5-event-polling-and-error-handling.md:53
msgid ""
"然而，问题来了…… 回调呢？我们上面提过，`readData()`只是把消息读出来放在一个待"
"处理队列中，并不会真正的处理消息，真正的消息处理需要调用`pops()`函数，将消息"
"拿出来处理，所以什么地方会调用每一个上层封装的消息处理呢？"
msgstr ""
"However, the question arises ...... What about callbacks? As we mentioned "
"above, `readData()` just reads the message out and puts it in a pending "
"queue, it doesn't really process the message, the real message processing "
"needs to call the `pops()` function to take the message out and process it, "
"so where does it call each of the upper level wrapped message processing?"

#: src/4-5-event-polling-and-error-handling.md:55
msgid ""
"这里我们还是找到我们的老朋友`portmgrd`的`main`函数，从下面简化的代码中，我们"
"可以看到和一般的Event Loop实现不同，SONiC中，最后的事件处理不是通过回调来实现"
"的，而是需要最外层的Event Loop来主动调用完成："
msgstr ""
"Here we still find the `main` function of our old friend `portmgrd`. From "
"the following simplified code, we can see that unlike the general Event Loop "
"implementation, the final event handling in SONiC is not achieved through "
"callbacks, but requires the outermost Event Loop to be actively called to "
"complete:"

#: src/4-5-event-polling-and-error-handling.md:57
msgid ""
"```cpp\n"
"int main(int argc, char **argv)\n"
"{\n"
"    // ...\n"
"\n"
"    // Create PortMgr, which implements Orch interface.\n"
"    PortMgr portmgr(&cfgDb, &appDb, &stateDb, cfg_port_tables);\n"
"    vector<Orch *> cfgOrchList = {&portmgr};\n"
"\n"
"    // Create Select object for event loop and add PortMgr to it.\n"
"    swss::Select s;\n"
"    for (Orch *o : cfgOrchList) {\n"
"        s.addSelectables(o->getSelectables());\n"
"    }\n"
"\n"
"    // Event loop\n"
"    while (true)\n"
"    {\n"
"        Selectable *sel;\n"
"        int ret;\n"
"\n"
"        // When anyone of the selectables gets signaled, select() will call\n"
"        // into readData() and fetch all events, then return.\n"
"        ret = s.select(&sel, SELECT_TIMEOUT);\n"
"        // ...\n"
"\n"
"        // Then, we call into execute() explicitly to process all events.\n"
"        auto *c = (Executor *)sel;\n"
"        c->execute();\n"
"    }\n"
"    return -1;\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"int main(int argc, char **argv)\n"
"{\n"
"    // ...\n"
"\n"
"    // Create PortMgr, which implements Orch interface.\n"
"    PortMgr portmgr(&cfgDb, &appDb, &stateDb, cfg_port_tables);\n"
"    vector<Orch *> cfgOrchList = {&portmgr};\n"
"\n"
"    // Create Select object for event loop and add PortMgr to it.\n"
"    swss::Select s;\n"
"    for (Orch *o : cfgOrchList) {\n"
"        s.addSelectables(o->getSelectables());\n"
"    }\n"
"\n"
"    // Event loop\n"
"    while (true)\n"
"    {\n"
"        Selectable *sel;\n"
"        int ret;\n"
"\n"
"        // When anyone of the selectables gets signaled, select() will call\n"
"        // into readData() and fetch all events, then return.\n"
"        ret = s.select(&sel, SELECT_TIMEOUT);\n"
"        // ...\n"
"\n"
"        // Then, we call into execute() explicitly to process all events.\n"
"        auto *c = (Executor *)sel;\n"
"        c->execute();\n"
"    }\n"
"    return -1;\n"
"}\n"
"```"

#: src/4-5-event-polling-and-error-handling.md:91
msgid "## 错误处理"
msgstr "## Error Handling"

#: src/4-5-event-polling-and-error-handling.md:93
msgid ""
"关于Event Loop我们还有一个问题，那就是错误处理，比如，如果Redis的命令执行出错"
"了，连接断开了，故障了等等的情况下，我们的服务会发生什么呢？"
msgstr ""
"Another issue we have with Event Loop is error handling. For example, what "
"happens to our service if a Redis command is executed incorrectly, a "
"connection is broken, a fault occurs, etc.?"

#: src/4-5-event-polling-and-error-handling.md:95
msgid ""
"从代码上来看，SONiC中的错误处理是非常简单的，就是直接抛出异常（比如，获取命令"
"执行结果的代码，如下），然后在Event Loop中捕获异常，打印日志，接着继续执行。"
msgstr ""
"From the code point of view, the error handling in SONiC is very simple, "
"that is, it just throws an exception (for example, the code to get the "
"result of command execution, as follows), then catches the exception in the "
"Event Loop, prints the log, and then continues the execution."

#: src/4-5-event-polling-and-error-handling.md:97
msgid ""
"```cpp\n"
"RedisReply::RedisReply(RedisContext *ctx, const RedisCommand& command)\n"
"{\n"
"    int rc = redisAppendFormattedCommand(ctx->getContext(), command.c_str(), "
"command.length());\n"
"    if (rc != REDIS_OK)\n"
"    {\n"
"        // The only reason of error is REDIS_ERR_OOM (Out of memory)\n"
"        // ref: https://github.com/redis/hiredis/blob/master/hiredis.c\n"
"        throw bad_alloc();\n"
"    }\n"
"\n"
"    rc = redisGetReply(ctx->getContext(), (void**)&m_reply);\n"
"    if (rc != REDIS_OK)\n"
"    {\n"
"        throw RedisError(\"Failed to redisGetReply with \" + string(command."
"c_str()), ctx->getContext());\n"
"    }\n"
"    guard([&]{checkReply();}, command.c_str());\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"RedisReply::RedisReply(RedisContext *ctx, const RedisCommand& command)\n"
"{\n"
"    int rc = redisAppendFormattedCommand(ctx->getContext(), command.c_str(), "
"command.length());\n"
"    if (rc != REDIS_OK)\n"
"    {\n"
"        // The only reason of error is REDIS_ERR_OOM (Out of memory)\n"
"        // ref: https://github.com/redis/hiredis/blob/master/hiredis.c\n"
"        throw bad_alloc();\n"
"    }\n"
"\n"
"    rc = redisGetReply(ctx->getContext(), (void**)&m_reply);\n"
"    if (rc != REDIS_OK)\n"
"    {\n"
"        throw RedisError(\"Failed to redisGetReply with \" + string(command."
"c_str()), ctx->getContext());\n"
"    }\n"
"    guard([&]{checkReply();}, command.c_str());\n"
"}\n"
"```"

#: src/4-5-event-polling-and-error-handling.md:117
msgid ""
"关于异常和错误的种类及其原因，在代码里面并没有看到用于统计和Telemetry的代码，"
"所以监控上说是比较薄弱的。另外还需要考虑数据出错的场景，比如数据库写到一半突"
"然断开导致的脏数据，不过简单的重启相关的`*syncd`和`*mgrd`服务可能可以解决此类"
"问题，因为启动时会进行全量同步。"
msgstr ""
"Regarding the types of exceptions and errors and their causes, there is no "
"code seen inside the code for statistics and Telemetry, so monitoring is "
"said to be weak. Also need to consider data error scenarios, such as dirty "
"data due to sudden disconnection halfway through writing the database, but a "
"simple restart of the related `*syncd` and `*mgrd` services may solve such "
"problems, as the full amount of synchronization will be performed at startup."

#: src/5-core-components.md:1
msgid "# 核心组件解析"
msgstr "Core Components"

#: src/5-core-components.md:3
msgid ""
"这一章，我们会从代码的层面上来深入的分析一下SONiC中一些比较有代表性的核心组件"
"和它们的工作流。"
msgstr ""
"In this chapter, we will take a deeper look at some of the more "
"representative workflows in SONiC from the code level."

#: src/5-core-components.md:5
msgid ""
"```admonish note\n"
"为了方便阅读和理解，所有的代码都只是列出了最核心的代码来展现流程，并不是完整"
"的代码，如果需要查看完整代码，请参考[仓库中的原始代码](./3-1-code-repos."
"html)。\n"
"\n"
"另外，每个代码块的开头都给出了相关文件的路径，其使用的是仓库均为SONiC的主仓"
"库：[sonic-buildimage](https://github.com/sonic-net/sonic-buildimage)。\n"
"```"
msgstr ""
"```admonish note\n"
"为了方便阅读和理解，所有的代码都只是列出了最核心的代码来展现流程，并不是完整"
"的代码，如果需要查看完整代码，请参考[仓库中的原始代码](./3-1-code-repos."
"html)。\n"
"\n"
"另外，每个代码块的开头都给出了相关文件的路径，其使用的是仓库均为SONiC的主仓"
"库：[sonic-buildimage](https://github.com/sonic-net/sonic-buildimage)。\n"
"```"

#: src/5-1-syncd-and-sai.md:1
msgid "# Syncd和SAI"
msgstr "# Syncd and SAI"

#: src/5-1-syncd-and-sai.md:3
msgid ""
"[Syncd容器](./2-3-key-containers.html#asic管理容器syncd)是SONiC中专门负责管理"
"ASIC的容器，其中核心进程`syncd`负责与Redis数据库沟通，加载SAI并与其交互，以完"
"成ASIC的初始化，配置和状态上报的处理等等。"
msgstr ""
"The [Syncd container](. /2-3-key-containers.html#asic management container "
"syncd) is a container in SONiC dedicated to managing ASICs, where the core "
"process `syncd` is responsible for communicating with the Redis database, "
"loading SAIs and interacting with them to complete ASIC initialization, "
"configuration and status reporting processing, and so on."

#: src/5-1-syncd-and-sai.md:5
msgid ""
"由于SONiC中大量的工作流最后都需要通过Syncd和SAI来和ASIC进行交互，所以这一部分"
"也就成为了这些工作流的公共部分，所以，在展开其他工作流之前，我们先来看一下"
"Syncd和SAI是如何工作的。"
msgstr ""
"Since a large number of workflows in SONiC end up needing to interact with "
"ASIC through Syncd and SAI, this part becomes a common part of these "
"workflows, so let's take a look at how Syncd and SAI work before we expand "
"on other workflows."

#: src/5-1-syncd-and-sai.md:7
msgid "## Syncd启动流程"
msgstr "## Syncd startup process"

#: src/5-1-syncd-and-sai.md:9
msgid ""
"`syncd`进程的入口在`syncd_main.cpp`中的`syncd_main`函数，其启动的整体流程大致"
"分为两部分。"
msgstr ""
"The entry point of the `syncd` process is in the `syncd_main.cpp` function, "
"and the overall process of its startup is roughly divided into two parts."

#: src/5-1-syncd-and-sai.md:11
msgid "第一部分是创建各个对象，并进行初始化："
msgstr ""
"The first part is the creation of individual objects and their "
"initialization:"

#: src/5-1-syncd-and-sai.md:13
msgid ""
"```mermaid\n"
"sequenceDiagram\n"
"    autonumber\n"
"    participant SDM as syncd_main\n"
"    participant SD as Syncd\n"
"    participant SAI as VendorSai\n"
"\n"
"    SDM->>+SD: 调用构造函数\n"
"    SD->>SD: 加载和解析命令行参数和配置文件\n"
"    SD->>SD: 创建数据库相关对象，如：<br/>ASIC_DB Connector和"
"FlexCounterManager\n"
"    SD->>SD: 创建MDIO IPC服务器\n"
"    SD->>SD: 创建SAI上报处理逻辑\n"
"    SD->>SD: 创建RedisSelectableChannel用于接收Redis通知\n"
"    SD->>-SAI: 初始化SAI\n"
"```"
msgstr ""
"```mermaid\n"
"sequenceDiagram\n"
"    autonumber\n"
"    participant SDM as syncd_main\n"
"    participant SD as Syncd\n"
"    participant SAI as VendorSai\n"
"\n"
"    SDM->>+SD: 调用构造函数\n"
"    SD->>SD: 加载和解析命令行参数和配置文件\n"
"    SD->>SD: 创建数据库相关对象，如：<br/>ASIC_DB Connector和"
"FlexCounterManager\n"
"    SD->>SD: 创建MDIO IPC服务器\n"
"    SD->>SD: 创建SAI上报处理逻辑\n"
"    SD->>SD: 创建RedisSelectableChannel用于接收Redis通知\n"
"    SD->>-SAI: 初始化SAI\n"
"```"

#: src/5-1-syncd-and-sai.md:29
msgid "第二个部分是启动主循环，并且处理初始化事件："
msgstr ""
"The second part starts the main loop and handles the initialization events:"

#: src/5-1-syncd-and-sai.md:31
msgid ""
"```mermaid\n"
"sequenceDiagram\n"
"    autonumber\n"
"    box purple 主线程\n"
"    participant SDM as syncd_main\n"
"    participant SD as Syncd\n"
"    participant SAI as VendorSai\n"
"    end\n"
"    box darkblue 通知处理线程\n"
"    participant NP as NotificationProcessor\n"
"    end\n"
"    box darkgreen MDIO IPC服务器线程\n"
"    participant MIS as MdioIpcServer\n"
"    end\n"
"\n"
"    SDM->>+SD: 启动主线程循环\n"
"    SD->>NP: 启动SAI上报处理线程\n"
"    NP->>NP: 开始通知处理循环\n"
"    SD->>MIS: 启动MDIO IPC服务器线程\n"
"    MIS->>MIS: 开始MDIO IPC服务器事件循环\n"
"    SD->>SD: 初始化并启动事件分发机制，开始主循环\n"
"\n"
"    loop 处理事件\n"
"        alt 如果是创建Switch的事件或者是WarmBoot\n"
"            SD->>SAI: 创建Switch对象，设置通知回调\n"
"        else 如果是其他事件\n"
"            SD->>SD: 处理事件\n"
"        end\n"
"    end\n"
"\n"
"    SD->>-SDM: 退出主循环返回\n"
"```"
msgstr ""
"```mermaid\n"
"sequenceDiagram\n"
"    autonumber\n"
"    box purple 主线程\n"
"    participant SDM as syncd_main\n"
"    participant SD as Syncd\n"
"    participant SAI as VendorSai\n"
"    end\n"
"    box darkblue 通知处理线程\n"
"    participant NP as NotificationProcessor\n"
"    end\n"
"    box darkgreen MDIO IPC服务器线程\n"
"    participant MIS as MdioIpcServer\n"
"    end\n"
"\n"
"    SDM->>+SD: 启动主线程循环\n"
"    SD->>NP: 启动SAI上报处理线程\n"
"    NP->>NP: 开始通知处理循环\n"
"    SD->>MIS: 启动MDIO IPC服务器线程\n"
"    MIS->>MIS: 开始MDIO IPC服务器事件循环\n"
"    SD->>SD: 初始化并启动事件分发机制，开始主循环\n"
"\n"
"    loop 处理事件\n"
"        alt 如果是创建Switch的事件或者是WarmBoot\n"
"            SD->>SAI: 创建Switch对象，设置通知回调\n"
"        else 如果是其他事件\n"
"            SD->>SD: 处理事件\n"
"        end\n"
"    end\n"
"\n"
"    SD->>-SDM: 退出主循环返回\n"
"```"

#: src/5-1-syncd-and-sai.md:64
msgid "然后我们再从代码的角度来更加仔细的看一下这个流程。"
msgstr "Then let's take a closer look at the process from a code perspective."

#: src/5-1-syncd-and-sai.md:66
msgid "### syncd_main函数"
msgstr "### syncd_main function"

#: src/5-1-syncd-and-sai.md:68
msgid ""
"`syncd_main`函数本身非常简单，主要逻辑就是创建Syncd对象，然后调用其`run`方"
"法："
msgstr ""
"The `syncd_main` function itself is very simple, the main logic is to create "
"the Syncd object and then call its `run` method:"

#: src/5-1-syncd-and-sai.md:70
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/syncd_main.cpp\n"
"int syncd_main(int argc, char **argv)\n"
"{\n"
"    auto vendorSai = std::make_shared<VendorSai>();\n"
"    auto syncd = std::make_shared<Syncd>(vendorSai, commandLineOptions, "
"isWarmStart);\n"
"    syncd->run();\n"
"    return EXIT_SUCCESS;\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/syncd_main.cpp\n"
"int syncd_main(int argc, char **argv)\n"
"{\n"
"    auto vendorSai = std::make_shared<VendorSai>();\n"
"    auto syncd = std::make_shared<Syncd>(vendorSai, commandLineOptions, "
"isWarmStart);\n"
"    syncd->run();\n"
"    return EXIT_SUCCESS;\n"
"}\n"
"```"

#: src/5-1-syncd-and-sai.md:81
msgid ""
"其中，`Syncd`对象的构造函数负责初始化`Syncd`中的各个功能，而`run`方法则负责启"
"动Syncd的主循环。"
msgstr ""
"The constructor of the `Syncd` object is responsible for initializing the "
"various functions in `Syncd`, while the `run` method is responsible for "
"starting the main loop of Syncd."

#: src/5-1-syncd-and-sai.md:83
msgid "### Syncd构造函数"
msgstr "### Syncd constructor"

#: src/5-1-syncd-and-sai.md:85
msgid ""
"`Syncd`对象的构造函数负责创建或初始化`Syncd`中的各个功能，比如用于连接数据库"
"的对象，统计管理，和ASIC通知的处理逻辑等等，其主要代码如下："
msgstr ""
"The constructor of the `Syncd` object is responsible for creating or "
"initializing various functions in `Syncd`, such as objects for connecting to "
"the database, statistics management, and ASIC notification processing logic, "
"etc. The main code is as follows:"

#: src/5-1-syncd-and-sai.md:87
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"Syncd::Syncd(\n"
"        _In_ std::shared_ptr<sairedis::SaiInterface> vendorSai,\n"
"        _In_ std::shared_ptr<CommandLineOptions> cmd,\n"
"        _In_ bool isWarmStart):\n"
"    m_vendorSai(vendorSai),\n"
"    ...\n"
"{\n"
"    ...\n"
"\n"
"    // Load context config\n"
"    auto ccc = sairedis::ContextConfigContainer::"
"loadFromFile(m_commandLineOptions->m_contextConfig.c_str());\n"
"    m_contextConfig = ccc->get(m_commandLineOptions->m_globalContext);\n"
"    ...\n"
"\n"
"    // Create FlexCounter manager\n"
"    m_manager = std::make_shared<FlexCounterManager>(m_vendorSai, "
"m_contextConfig->m_dbCounters);\n"
"\n"
"    // Create DB related objects\n"
"    m_dbAsic = std::make_shared<swss::DBConnector>(m_contextConfig-"
">m_dbAsic, 0);\n"
"    m_mdioIpcServer = std::make_shared<MdioIpcServer>(m_vendorSai, "
"m_commandLineOptions->m_globalContext);\n"
"    m_selectableChannel = std::make_shared<sairedis::"
"RedisSelectableChannel>(m_dbAsic, ASIC_STATE_TABLE, REDIS_TABLE_GETRESPONSE, "
"TEMP_PREFIX, modifyRedis);\n"
"\n"
"    // Create notification processor and handler\n"
"    m_notifications = std::"
"make_shared<RedisNotificationProducer>(m_contextConfig->m_dbAsic);\n"
"    m_client = std::make_shared<RedisClient>(m_dbAsic);\n"
"    m_processor = std::make_shared<NotificationProcessor>(m_notifications, "
"m_client, std::bind(&Syncd::syncProcessNotification, this, _1));\n"
"\n"
"    m_handler = std::make_shared<NotificationHandler>(m_processor);\n"
"    m_sn.onFdbEvent = std::bind(&NotificationHandler::onFdbEvent, m_handler."
"get(), _1, _2);\n"
"    m_sn.onNatEvent = std::bind(&NotificationHandler::onNatEvent, m_handler."
"get(), _1, _2);\n"
"    // Init many other event handlers here\n"
"    m_handler->setSwitchNotifications(m_sn.getSwitchNotifications());\n"
"    ...\n"
"\n"
"    // Initialize SAI\n"
"    sai_status_t status = vendorSai->initialize(0, &m_test_services);\n"
"    ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"Syncd::Syncd(\n"
"        _In_ std::shared_ptr<sairedis::SaiInterface> vendorSai,\n"
"        _In_ std::shared_ptr<CommandLineOptions> cmd,\n"
"        _In_ bool isWarmStart):\n"
"    m_vendorSai(vendorSai),\n"
"    ...\n"
"{\n"
"    ...\n"
"\n"
"    // Load context config\n"
"    auto ccc = sairedis::ContextConfigContainer::"
"loadFromFile(m_commandLineOptions->m_contextConfig.c_str());\n"
"    m_contextConfig = ccc->get(m_commandLineOptions->m_globalContext);\n"
"    ...\n"
"\n"
"    // Create FlexCounter manager\n"
"    m_manager = std::make_shared<FlexCounterManager>(m_vendorSai, "
"m_contextConfig->m_dbCounters);\n"
"\n"
"    // Create DB related objects\n"
"    m_dbAsic = std::make_shared<swss::DBConnector>(m_contextConfig-"
">m_dbAsic, 0);\n"
"    m_mdioIpcServer = std::make_shared<MdioIpcServer>(m_vendorSai, "
"m_commandLineOptions->m_globalContext);\n"
"    m_selectableChannel = std::make_shared<sairedis::"
"RedisSelectableChannel>(m_dbAsic, ASIC_STATE_TABLE, REDIS_TABLE_GETRESPONSE, "
"TEMP_PREFIX, modifyRedis);\n"
"\n"
"    // Create notification processor and handler\n"
"    m_notifications = std::"
"make_shared<RedisNotificationProducer>(m_contextConfig->m_dbAsic);\n"
"    m_client = std::make_shared<RedisClient>(m_dbAsic);\n"
"    m_processor = std::make_shared<NotificationProcessor>(m_notifications, "
"m_client, std::bind(&Syncd::syncProcessNotification, this, _1));\n"
"\n"
"    m_handler = std::make_shared<NotificationHandler>(m_processor);\n"
"    m_sn.onFdbEvent = std::bind(&NotificationHandler::onFdbEvent, m_handler."
"get(), _1, _2);\n"
"    m_sn.onNatEvent = std::bind(&NotificationHandler::onNatEvent, m_handler."
"get(), _1, _2);\n"
"    // Init many other event handlers here\n"
"    m_handler->setSwitchNotifications(m_sn.getSwitchNotifications());\n"
"    ...\n"
"\n"
"    // Initialize SAI\n"
"    sai_status_t status = vendorSai->initialize(0, &m_test_services);\n"
"    ...\n"
"}\n"
"```"

#: src/5-1-syncd-and-sai.md:129
msgid "### SAI的初始化与VendorSai"
msgstr "### SAI initialization with VendorSai"

#: src/5-1-syncd-and-sai.md:131
msgid ""
"`Syncd`初始化的最后也是最重要的一步，就是对SAI进行初始化。[在核心组件的SAI介"
"绍中，我们简单的展示了SAI的初始化，实现，以及它是如何为SONiC提供不同平台的支"
"持](./2-4-sai-intro.html)，所以这里我们主要来看看`Syncd`是如何对SAI进行封装和"
"调用的。"
msgstr ""
"The last and most important step in the initialization of `Syncd` is the "
"initialization of the SAI. [In the SAI introduction for the core component, "
"we briefly showed the initialization of SAI, the implementation, and how it "
"provides support for different platforms for SONiC](. /2-4-sai-intro.html), "
"so here we will mainly look at how `Syncd` wraps and calls SAI."

#: src/5-1-syncd-and-sai.md:133
msgid ""
"`Syncd`使用`VendorSai`来对SAI的所有API进行封装，方便上层调用。其初始化过程也"
"非常直接，基本就是对上面两个函数的直接调用和错误处理，如下："
msgstr ""
"`Syncd` uses `VendorSai` to encapsulate all the APIs of SAI, making it easy "
"for the upper layers to call. Its initialization process is also very "
"straightforward, basically a direct call to the above two functions and "
"error handling, as follows:"

#: src/5-1-syncd-and-sai.md:135
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/VendorSai.cpp\n"
"sai_status_t VendorSai::initialize(\n"
"        _In_ uint64_t flags,\n"
"        _In_ const sai_service_method_table_t *service_method_table)\n"
"{\n"
"    ...\n"
"    \n"
"    // Initialize SAI\n"
"    memcpy(&m_service_method_table, service_method_table, "
"sizeof(m_service_method_table));\n"
"    auto status = sai_api_initialize(flags, service_method_table);\n"
"\n"
"    // If SAI is initialized successfully, query all SAI API methods.\n"
"    // sai_metadata_api_query will also update all extern global sai_*_api "
"variables, so we can also use\n"
"    // sai_metadata_get_object_type_info to get methods for a specific SAI "
"object type.\n"
"    if (status == SAI_STATUS_SUCCESS) {\n"
"        memset(&m_apis, 0, sizeof(m_apis));\n"
"        int failed = sai_metadata_apis_query(sai_api_query, &m_apis);\n"
"        ...\n"
"    }\n"
"    ...\n"
"\n"
"    return status;\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/VendorSai.cpp\n"
"sai_status_t VendorSai::initialize(\n"
"        _In_ uint64_t flags,\n"
"        _In_ const sai_service_method_table_t *service_method_table)\n"
"{\n"
"    ...\n"
"    \n"
"    // Initialize SAI\n"
"    memcpy(&m_service_method_table, service_method_table, "
"sizeof(m_service_method_table));\n"
"    auto status = sai_api_initialize(flags, service_method_table);\n"
"\n"
"    // If SAI is initialized successfully, query all SAI API methods.\n"
"    // sai_metadata_api_query will also update all extern global sai_*_api "
"variables, so we can also use\n"
"    // sai_metadata_get_object_type_info to get methods for a specific SAI "
"object type.\n"
"    if (status == SAI_STATUS_SUCCESS) {\n"
"        memset(&m_apis, 0, sizeof(m_apis));\n"
"        int failed = sai_metadata_apis_query(sai_api_query, &m_apis);\n"
"        ...\n"
"    }\n"
"    ...\n"
"\n"
"    return status;\n"
"}\n"
"```"

#: src/5-1-syncd-and-sai.md:161
msgid ""
"当获取好所有的SAI API之后，我们就可以通过`VendorSai`对象来调用SAI的API了。当"
"前调用SAI的API方式主要有两种。"
msgstr ""
"Once all the SAI APIs are obtained, we can call the SAI APIs through the "
"`VendorSai` object. Currently there are two main ways to call the SAI API."

#: src/5-1-syncd-and-sai.md:163
msgid ""
"第一种是通过`sai_object_type_into_t`来调用，它类似于为所有的SAI Object实现了"
"一个虚表，如下："
msgstr ""
"The first one is called by `sai_object_type_into_t`, which is similar to "
"implementing a dummy table for all SAI Objects, as follows:"

#: src/5-1-syncd-and-sai.md:165
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/VendorSai.cpp\n"
"sai_status_t VendorSai::set(\n"
"        _In_ sai_object_type_t objectType,\n"
"        _In_ sai_object_id_t objectId,\n"
"        _In_ const sai_attribute_t *attr)\n"
"{\n"
"    ...\n"
"\n"
"    auto info = sai_metadata_get_object_type_info(objectType);\n"
"    sai_object_meta_key_t mk = { .objecttype = objectType, .objectkey = { ."
"key = { .object_id = objectId } } };\n"
"    return info->set(&mk, attr);\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/VendorSai.cpp\n"
"sai_status_t VendorSai::set(\n"
"        _In_ sai_object_type_t objectType,\n"
"        _In_ sai_object_id_t objectId,\n"
"        _In_ const sai_attribute_t *attr)\n"
"{\n"
"    ...\n"
"\n"
"    auto info = sai_metadata_get_object_type_info(objectType);\n"
"    sai_object_meta_key_t mk = { .objecttype = objectType, .objectkey = { ."
"key = { .object_id = objectId } } };\n"
"    return info->set(&mk, attr);\n"
"}\n"
"```"

#: src/5-1-syncd-and-sai.md:180
msgid ""
"另外一种是通过保存在`VendorSai`对象中的`m_apis`来调用，这种方式更加直接，但是"
"调用前需要先根据SAI Object的类型来调用不同的API。"
msgstr ""
"The other way is to call through `m_apis` saved in the `VendorSai` object. "
"This way is more direct, but before calling it, you need to call different "
"APIs according to the type of SAI Object."

#: src/5-1-syncd-and-sai.md:182
msgid ""
"```cpp\n"
"sai_status_t VendorSai::getStatsExt(\n"
"        _In_ sai_object_type_t object_type,\n"
"        _In_ sai_object_id_t object_id,\n"
"        _In_ uint32_t number_of_counters,\n"
"        _In_ const sai_stat_id_t *counter_ids,\n"
"        _In_ sai_stats_mode_t mode,\n"
"        _Out_ uint64_t *counters)\n"
"{\n"
"    sai_status_t (*ptr)(\n"
"            _In_ sai_object_id_t port_id,\n"
"            _In_ uint32_t number_of_counters,\n"
"            _In_ const sai_stat_id_t *counter_ids,\n"
"            _In_ sai_stats_mode_t mode,\n"
"            _Out_ uint64_t *counters);\n"
"\n"
"    switch ((int)object_type)\n"
"    {\n"
"        case SAI_OBJECT_TYPE_PORT:\n"
"            ptr = m_apis.port_api->get_port_stats_ext;\n"
"            break;\n"
"        case SAI_OBJECT_TYPE_ROUTER_INTERFACE:\n"
"            ptr = m_apis.router_interface_api-"
">get_router_interface_stats_ext;\n"
"            break;\n"
"        case SAI_OBJECT_TYPE_POLICER:\n"
"            ptr = m_apis.policer_api->get_policer_stats_ext;\n"
"            break;\n"
"        ...\n"
"\n"
"        default:\n"
"            SWSS_LOG_ERROR(\"not implemented, FIXME\");\n"
"            return SAI_STATUS_FAILURE;\n"
"    }\n"
"\n"
"    return ptr(object_id, number_of_counters, counter_ids, mode, counters);\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"sai_status_t VendorSai::getStatsExt(\n"
"        _In_ sai_object_type_t object_type,\n"
"        _In_ sai_object_id_t object_id,\n"
"        _In_ uint32_t number_of_counters,\n"
"        _In_ const sai_stat_id_t *counter_ids,\n"
"        _In_ sai_stats_mode_t mode,\n"
"        _Out_ uint64_t *counters)\n"
"{\n"
"    sai_status_t (*ptr)(\n"
"            _In_ sai_object_id_t port_id,\n"
"            _In_ uint32_t number_of_counters,\n"
"            _In_ const sai_stat_id_t *counter_ids,\n"
"            _In_ sai_stats_mode_t mode,\n"
"            _Out_ uint64_t *counters);\n"
"\n"
"    switch ((int)object_type)\n"
"    {\n"
"        case SAI_OBJECT_TYPE_PORT:\n"
"            ptr = m_apis.port_api->get_port_stats_ext;\n"
"            break;\n"
"        case SAI_OBJECT_TYPE_ROUTER_INTERFACE:\n"
"            ptr = m_apis.router_interface_api-"
">get_router_interface_stats_ext;\n"
"            break;\n"
"        case SAI_OBJECT_TYPE_POLICER:\n"
"            ptr = m_apis.policer_api->get_policer_stats_ext;\n"
"            break;\n"
"        ...\n"
"\n"
"        default:\n"
"            SWSS_LOG_ERROR(\"not implemented, FIXME\");\n"
"            return SAI_STATUS_FAILURE;\n"
"    }\n"
"\n"
"    return ptr(object_id, number_of_counters, counter_ids, mode, counters);\n"
"}\n"
"```"

#: src/5-1-syncd-and-sai.md:220
msgid "可以明显看出，第一种调用方式代码要精炼和直观许多。"
msgstr ""
"As you can clearly see, the code of the first call is much more concise and "
"intuitive."

#: src/5-1-syncd-and-sai.md:222
msgid "### Syncd主循环"
msgstr "### Syncd main loop"

#: src/5-1-syncd-and-sai.md:224
msgid ""
"`Syncd`的主循环也是使用的SONiC中标准的[事件分发](./4-3-event-polling-and-"
"error-handling.html)机制：在启动时，`Syncd`会将所有用于事件处理的`Selectable`"
"对象注册到用于获取事件的`Select`对象中，然后在主循环中调用`Select`的`select`"
"方法，等待事件的发生。核心代码如下："
msgstr ""
"The main loop of `Syncd` is also using the standard [event distribution] in "
"SONiC (. /4-3-event-polling-and-error-handling.html) mechanism: at startup, "
"`Syncd` registers all `Selectable` objects used for event handling into the "
"`Select` object used to fetch events, and then calls `Select`'s `select ` "
"method in the main loop and wait for the event to occur. The core code is as "
"follows:"

#: src/5-1-syncd-and-sai.md:226
msgid ""
"```c\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"void Syncd::run()\n"
"{\n"
"    volatile bool runMainLoop = true;\n"
"    std::shared_ptr<swss::Select> s = std::make_shared<swss::Select>();\n"
"    onSyncdStart(m_commandLineOptions->m_startType == "
"SAI_START_TYPE_WARM_BOOT);\n"
"\n"
"    // Start notification processing thread\n"
"    m_processor->startNotificationsProcessingThread();\n"
"\n"
"    // Start MDIO threads\n"
"    for (auto& sw: m_switches) { m_mdioIpcServer->setSwitchId(sw.second-"
">getRid()); }\n"
"    m_mdioIpcServer->startMdioThread();\n"
"\n"
"    // Registering selectable for event polling\n"
"    s->addSelectable(m_selectableChannel.get());\n"
"    s->addSelectable(m_restartQuery.get());\n"
"    s->addSelectable(m_flexCounter.get());\n"
"    s->addSelectable(m_flexCounterGroup.get());\n"
"\n"
"    // Main event loop\n"
"    while (runMainLoop)\n"
"    {\n"
"        swss::Selectable *sel = NULL;\n"
"        int result = s->select(&sel);\n"
"\n"
"        ...\n"
"        if (sel == m_restartQuery.get()) {\n"
"            // Handling switch restart event and restart switch here.\n"
"        } else if (sel == m_flexCounter.get()) {\n"
"            processFlexCounterEvent(*(swss::ConsumerTable*)sel);\n"
"        } else if (sel == m_flexCounterGroup.get()) {\n"
"            processFlexCounterGroupEvent(*(swss::ConsumerTable*)sel);\n"
"        } else if (sel == m_selectableChannel.get()) {\n"
"            // Handle redis updates here.\n"
"            processEvent(*m_selectableChannel.get());\n"
"        } else {\n"
"            SWSS_LOG_ERROR(\"select failed: %d\", result);\n"
"        }\n"
"        ...\n"
"    }\n"
"    ...\n"
"}\n"
"```"
msgstr ""
"```c\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"void Syncd::run()\n"
"{\n"
"    volatile bool runMainLoop = true;\n"
"    std::shared_ptr<swss::Select> s = std::make_shared<swss::Select>();\n"
"    onSyncdStart(m_commandLineOptions->m_startType == "
"SAI_START_TYPE_WARM_BOOT);\n"
"\n"
"    // Start notification processing thread\n"
"    m_processor->startNotificationsProcessingThread();\n"
"\n"
"    // Start MDIO threads\n"
"    for (auto& sw: m_switches) { m_mdioIpcServer->setSwitchId(sw.second-"
">getRid()); }\n"
"    m_mdioIpcServer->startMdioThread();\n"
"\n"
"    // Registering selectable for event polling\n"
"    s->addSelectable(m_selectableChannel.get());\n"
"    s->addSelectable(m_restartQuery.get());\n"
"    s->addSelectable(m_flexCounter.get());\n"
"    s->addSelectable(m_flexCounterGroup.get());\n"
"\n"
"    // Main event loop\n"
"    while (runMainLoop)\n"
"    {\n"
"        swss::Selectable *sel = NULL;\n"
"        int result = s->select(&sel);\n"
"\n"
"        ...\n"
"        if (sel == m_restartQuery.get()) {\n"
"            // Handling switch restart event and restart switch here.\n"
"        } else if (sel == m_flexCounter.get()) {\n"
"            processFlexCounterEvent(*(swss::ConsumerTable*)sel);\n"
"        } else if (sel == m_flexCounterGroup.get()) {\n"
"            processFlexCounterGroupEvent(*(swss::ConsumerTable*)sel);\n"
"        } else if (sel == m_selectableChannel.get()) {\n"
"            // Handle redis updates here.\n"
"            processEvent(*m_selectableChannel.get());\n"
"        } else {\n"
"            SWSS_LOG_ERROR(\"select failed: %d\", result);\n"
"        }\n"
"        ...\n"
"    }\n"
"    ...\n"
"}\n"
"```"

#: src/5-1-syncd-and-sai.md:272
msgid ""
"其中，`m_selectableChannel`就是主要负责处理Redis数据库中的事件的对象。它使用"
"[ProducerTable / ConsumerTable](./4-2-2-redis-messaging-layer."
"md#producertable--consumertable)的方式与Redis数据库进行交互，所以，所有"
"`orchagent`发送过来的操作都会以三元组的形式保存在Redis中的list中，等待`Syncd`"
"的处理。其核心定义如下："
msgstr ""
"One of them, `m_selectableChannel`, is the object that is primarily "
"responsible for handling events in the Redis database. It uses the "
"[ProducerTable / ConsumerTable](. /4-2-2-redis-messaging-layer."
"md#producertable--consumertable) to interact with the Redis database, so all "
"operations sent by the `orchagent` are stored in a list in Redis in the form "
"of a triple, waiting for ` Syncd` for processing. The core definition is as "
"follows:"

#: src/5-1-syncd-and-sai.md:274
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/meta/RedisSelectableChannel.h\n"
"class RedisSelectableChannel: public SelectableChannel\n"
"{\n"
"    public:\n"
"        RedisSelectableChannel(\n"
"                _In_ std::shared_ptr<swss::DBConnector> dbAsic,\n"
"                _In_ const std::string& asicStateTable,\n"
"                _In_ const std::string& getResponseTable,\n"
"                _In_ const std::string& tempPrefix,\n"
"                _In_ bool modifyRedis);\n"
"\n"
"    public: // SelectableChannel overrides\n"
"        virtual bool empty() override;\n"
"        ...\n"
"\n"
"    public: // Selectable overrides\n"
"        virtual int getFd() override;\n"
"        virtual uint64_t readData() override;\n"
"        ...\n"
"\n"
"    private:\n"
"        std::shared_ptr<swss::DBConnector> m_dbAsic;\n"
"        std::shared_ptr<swss::ConsumerTable> m_asicState;\n"
"        std::shared_ptr<swss::ProducerTable> m_getResponse;\n"
"        ...\n"
"};\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/meta/RedisSelectableChannel.h\n"
"class RedisSelectableChannel: public SelectableChannel\n"
"{\n"
"    public:\n"
"        RedisSelectableChannel(\n"
"                _In_ std::shared_ptr<swss::DBConnector> dbAsic,\n"
"                _In_ const std::string& asicStateTable,\n"
"                _In_ const std::string& getResponseTable,\n"
"                _In_ const std::string& tempPrefix,\n"
"                _In_ bool modifyRedis);\n"
"\n"
"    public: // SelectableChannel overrides\n"
"        virtual bool empty() override;\n"
"        ...\n"
"\n"
"    public: // Selectable overrides\n"
"        virtual int getFd() override;\n"
"        virtual uint64_t readData() override;\n"
"        ...\n"
"\n"
"    private:\n"
"        std::shared_ptr<swss::DBConnector> m_dbAsic;\n"
"        std::shared_ptr<swss::ConsumerTable> m_asicState;\n"
"        std::shared_ptr<swss::ProducerTable> m_getResponse;\n"
"        ...\n"
"};\n"
"```"

#: src/5-1-syncd-and-sai.md:303
msgid "另外，在主循环启动时，`Syncd`还会额外启动两个线程："
msgstr ""
"In addition, when the main loop is started, `Syncd` starts two additional "
"threads:"

#: src/5-1-syncd-and-sai.md:305
msgid ""
"- 用于接收ASIC上报通知的通知处理线程：`m_processor-"
">startNotificationsProcessingThread();`\n"
"- 用于处理MDIO通信的MDIO IPC处理线程：`m_mdioIpcServer->startMdioThread();`"
msgstr ""
"- Notifications processing thread for receiving ASIC upload notifications: "
"`m_processor->startNotificationsProcessingThread();`\n"
"- MDIO IPC processing thread for handling MDIO communication: "
"`m_mdioIpcServer->startMdioThread();`"

#: src/5-1-syncd-and-sai.md:308
msgid ""
"它们的细节我们在初始化的部分不做过多展开，等后面介绍相关工作流时再来详细介"
"绍。"
msgstr ""
"We won't expand too much on their details in the initialization section, but "
"will come back to them later when we introduce the relevant workflows."

#: src/5-1-syncd-and-sai.md:310
msgid "### 创建Switch对象，初始化通知机制"
msgstr "### Create Switch object, initialize notification mechanism"

#: src/5-1-syncd-and-sai.md:312
msgid ""
"在主循环启动后，`Syncd`就会开始调用SAI的API来创建Switch对象，这里的入口有两"
"个，一个是ASIC_DB收到创建Switch的通知，另外一个是Warm Boot时，`Syncd`来主动调"
"用，但是创建Switch这一步的内部流程都类似。"
msgstr ""
"After the main loop starts, `Syncd` will start calling the SAI API to create "
"Switch objects. There are two entry points here, one is when ASIC_DB "
"receives a notification to create a Switch, and the other is when Warm Boot, "
"`Syncd` comes to initiate the call, but the internal flow of this step of "
"creating a Switch is similar."

#: src/5-1-syncd-and-sai.md:314
msgid ""
"在这一步中间，有一个很重要的步骤，就是初始化SAI内部实现中的通知回调，将我们之"
"前已经创建好的通知处理逻辑传递给SAI的实现，比如FDB的事件等等。这些回调函数会"
"被当做Switch的属性（Attributes）通过参数的形式传给SAI的`create_switch`方法，"
"SAI的实现会将其保存起来，这样就可以在事件发生时调用回调函数，来通知`Syncd`"
"了。这里的核心代码如下："
msgstr ""
"In the middle of this step, there is an important step to initialize the "
"notification callbacks in the SAI's internal implementation to pass the "
"notification handling logic we have created before to the SAI's "
"implementation, such as FDB's events and so on. These callbacks will be "
"passed as Attributes of the Switch to the SAI's `create_switch` method as "
"parameters, and the SAI implementation will save them so that the callbacks "
"can be called to notify `Syncd` when an event occurs. The core code here is "
"as follows:"

#: src/5-1-syncd-and-sai.md:316
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"sai_status_t Syncd::processQuadEvent(\n"
"        _In_ sai_common_api_t api,\n"
"        _In_ const swss::KeyOpFieldsValuesTuple &kco)\n"
"{\n"
"    // Parse event into SAI object\n"
"    sai_object_meta_key_t metaKey;\n"
"    ...\n"
"\n"
"    SaiAttributeList list(metaKey.objecttype, values, false);\n"
"    sai_attribute_t *attr_list = list.get_attr_list();\n"
"    uint32_t attr_count = list.get_attr_count();\n"
"\n"
"    // Update notifications pointers in attribute list\n"
"    if (metaKey.objecttype == SAI_OBJECT_TYPE_SWITCH && (api == "
"SAI_COMMON_API_CREATE || api == SAI_COMMON_API_SET))\n"
"    {\n"
"        m_handler->updateNotificationsPointers(attr_count, attr_list);\n"
"    }\n"
"\n"
"    if (isInitViewMode())\n"
"    {\n"
"        // ProcessQuadEventInInitViewMode will eventually call into "
"VendorSai, which calls create_swtich function in SAI.\n"
"        sai_status_t status = processQuadEventInInitViewMode(metaKey."
"objecttype, strObjectId, api, attr_count, attr_list);\n"
"        syncUpdateRedisQuadEvent(status, api, kco);\n"
"        return status;\n"
"    }\n"
"    ...\n"
"}\n"
"\n"
"// File: src/sonic-sairedis/syncd/NotificationHandler.cpp\n"
"void NotificationHandler::updateNotificationsPointers(_In_ uint32_t "
"attr_count, _In_ sai_attribute_t *attr_list) const\n"
"{\n"
"    for (uint32_t index = 0; index < attr_count; ++index) {\n"
"        ...\n"
"\n"
"        sai_attribute_t &attr = attr_list[index];\n"
"        switch (attr.id) {\n"
"            ...\n"
"\n"
"            case SAI_SWITCH_ATTR_SHUTDOWN_REQUEST_NOTIFY:\n"
"                attr.value.ptr = (void*)m_switchNotifications."
"on_switch_shutdown_request;\n"
"                break;\n"
"\n"
"            case SAI_SWITCH_ATTR_FDB_EVENT_NOTIFY:\n"
"                attr.value.ptr = (void*)m_switchNotifications.on_fdb_event;\n"
"                break;\n"
"            ...\n"
"        }\n"
"        ...\n"
"    }\n"
"}\n"
"\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"// Call stack: processQuadEvent\n"
"//          -> processQuadEventInInitViewMode\n"
"//          -> processQuadInInitViewModeCreate\n"
"//          -> onSwitchCreateInInitViewMode\n"
"void Syncd::onSwitchCreateInInitViewMode(_In_ sai_object_id_t switchVid, "
"_In_ uint32_t attr_count, _In_ const sai_attribute_t *attr_list)\n"
"{\n"
"    if (m_switches.find(switchVid) == m_switches.end()) {\n"
"        sai_object_id_t switchRid;\n"
"        sai_status_t status;\n"
"        status = m_vendorSai->create(SAI_OBJECT_TYPE_SWITCH, &switchRid, 0, "
"attr_count, attr_list);\n"
"        ...\n"
"\n"
"        m_switches[switchVid] = std::make_shared<SaiSwitch>(switchVid, "
"switchRid, m_client, m_translator, m_vendorSai);\n"
"        m_mdioIpcServer->setSwitchId(switchRid);\n"
"        ...\n"
"    }\n"
"    ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"sai_status_t Syncd::processQuadEvent(\n"
"        _In_ sai_common_api_t api,\n"
"        _In_ const swss::KeyOpFieldsValuesTuple &kco)\n"
"{\n"
"    // Parse event into SAI object\n"
"    sai_object_meta_key_t metaKey;\n"
"    ...\n"
"\n"
"    SaiAttributeList list(metaKey.objecttype, values, false);\n"
"    sai_attribute_t *attr_list = list.get_attr_list();\n"
"    uint32_t attr_count = list.get_attr_count();\n"
"\n"
"    // Update notifications pointers in attribute list\n"
"    if (metaKey.objecttype == SAI_OBJECT_TYPE_SWITCH && (api == "
"SAI_COMMON_API_CREATE || api == SAI_COMMON_API_SET))\n"
"    {\n"
"        m_handler->updateNotificationsPointers(attr_count, attr_list);\n"
"    }\n"
"\n"
"    if (isInitViewMode())\n"
"    {\n"
"        // ProcessQuadEventInInitViewMode will eventually call into "
"VendorSai, which calls create_swtich function in SAI.\n"
"        sai_status_t status = processQuadEventInInitViewMode(metaKey."
"objecttype, strObjectId, api, attr_count, attr_list);\n"
"        syncUpdateRedisQuadEvent(status, api, kco);\n"
"        return status;\n"
"    }\n"
"    ...\n"
"}\n"
"\n"
"// File: src/sonic-sairedis/syncd/NotificationHandler.cpp\n"
"void NotificationHandler::updateNotificationsPointers(_In_ uint32_t "
"attr_count, _In_ sai_attribute_t *attr_list) const\n"
"{\n"
"    for (uint32_t index = 0; index < attr_count; ++index) {\n"
"        ...\n"
"\n"
"        sai_attribute_t &attr = attr_list[index];\n"
"        switch (attr.id) {\n"
"            ...\n"
"\n"
"            case SAI_SWITCH_ATTR_SHUTDOWN_REQUEST_NOTIFY:\n"
"                attr.value.ptr = (void*)m_switchNotifications."
"on_switch_shutdown_request;\n"
"                break;\n"
"\n"
"            case SAI_SWITCH_ATTR_FDB_EVENT_NOTIFY:\n"
"                attr.value.ptr = (void*)m_switchNotifications.on_fdb_event;\n"
"                break;\n"
"            ...\n"
"        }\n"
"        ...\n"
"    }\n"
"}\n"
"\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"// Call stack: processQuadEvent\n"
"//          -> processQuadEventInInitViewMode\n"
"//          -> processQuadInInitViewModeCreate\n"
"//          -> onSwitchCreateInInitViewMode\n"
"void Syncd::onSwitchCreateInInitViewMode(_In_ sai_object_id_t switchVid, "
"_In_ uint32_t attr_count, _In_ const sai_attribute_t *attr_list)\n"
"{\n"
"    if (m_switches.find(switchVid) == m_switches.end()) {\n"
"        sai_object_id_t switchRid;\n"
"        sai_status_t status;\n"
"        status = m_vendorSai->create(SAI_OBJECT_TYPE_SWITCH, &switchRid, 0, "
"attr_count, attr_list);\n"
"        ...\n"
"\n"
"        m_switches[switchVid] = std::make_shared<SaiSwitch>(switchVid, "
"switchRid, m_client, m_translator, m_vendorSai);\n"
"        m_mdioIpcServer->setSwitchId(switchRid);\n"
"        ...\n"
"    }\n"
"    ...\n"
"}\n"
"```"

#: src/5-1-syncd-and-sai.md:390
msgid "从Mellanox的SAI实现，我们可以看到其具体的保存的方法："
msgstr ""
"From Mellanox's SAI implementation, we can see its specific approach to "
"preservation:"

#: src/5-1-syncd-and-sai.md:392
msgid ""
"```cpp\n"
"static sai_status_t mlnx_create_switch(_Out_ sai_object_id_t     * "
"switch_id,\n"
"                                       _In_ uint32_t               "
"attr_count,\n"
"                                       _In_ const sai_attribute_t "
"*attr_list)\n"
"{\n"
"    ...\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_SWITCH_STATE_CHANGE_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_switch_state_change = "
"(sai_switch_state_change_notification_fn)attr_val->ptr;\n"
"    }\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_SHUTDOWN_REQUEST_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_switch_shutdown_request =\n"
"            (sai_switch_shutdown_request_notification_fn)attr_val->ptr;\n"
"    }\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_FDB_EVENT_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_fdb_event = "
"(sai_fdb_event_notification_fn)attr_val->ptr;\n"
"    }\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_PORT_STATE_CHANGE_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_port_state_change = "
"(sai_port_state_change_notification_fn)attr_val->ptr;\n"
"    }\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_PACKET_EVENT_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_packet_event = "
"(sai_packet_event_notification_fn)attr_val->ptr;\n"
"    }\n"
"    ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"static sai_status_t mlnx_create_switch(_Out_ sai_object_id_t     * "
"switch_id,\n"
"                                       _In_ uint32_t               "
"attr_count,\n"
"                                       _In_ const sai_attribute_t "
"*attr_list)\n"
"{\n"
"    ...\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_SWITCH_STATE_CHANGE_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_switch_state_change = "
"(sai_switch_state_change_notification_fn)attr_val->ptr;\n"
"    }\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_SHUTDOWN_REQUEST_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_switch_shutdown_request =\n"
"            (sai_switch_shutdown_request_notification_fn)attr_val->ptr;\n"
"    }\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_FDB_EVENT_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_fdb_event = "
"(sai_fdb_event_notification_fn)attr_val->ptr;\n"
"    }\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_PORT_STATE_CHANGE_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_port_state_change = "
"(sai_port_state_change_notification_fn)attr_val->ptr;\n"
"    }\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_PACKET_EVENT_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_packet_event = "
"(sai_packet_event_notification_fn)attr_val->ptr;\n"
"    }\n"
"    ...\n"
"}\n"
"```"

#: src/5-1-syncd-and-sai.md:428
msgid "## ASIC状态更新"
msgstr "## ASIC Status Update"

#: src/5-1-syncd-and-sai.md:430
msgid ""
"ASIC状态更新是`Syncd`中最重要的工作流之一，当`orchagent`发现任何变化并开始修"
"改ASIC_DB时，就会触发该工作流，通过SAI来对ASIC进行更新。在了解了`Syncd`的主循"
"环之后，理解ASIC状态更新的工作流就很简单了。"
msgstr ""
"ASIC status update is one of the most important workflows in `Syncd`, which "
"is triggered when `orchagent` finds any change and starts modifying ASIC_DB "
"to update ASIC via SAI. After understanding the main loop of `Syncd`, it is "
"easy to understand the workflow of ASIC state update."

#: src/5-1-syncd-and-sai.md:432
msgid "所有的步骤都发生在主线程一个线程中，顺序执行，总结成时序图如下："
msgstr ""
"All steps occur in one thread in the main thread and are executed "
"sequentially, summarized in a timing diagram as follows:"

#: src/5-1-syncd-and-sai.md:434
msgid ""
"```mermaid\n"
"sequenceDiagram\n"
"    autonumber\n"
"    participant SD as Syncd\n"
"    participant RSC as RedisSelectableChannel\n"
"    participant SAI as VendorSai\n"
"    participant R as Redis\n"
"\n"
"    loop 主线程循环\n"
"        SD->>RSC: 收到epoll通知，通知获取所有到来的消息\n"
"        RSC->>R: 通过ConsumerTable获取所有到来的消息\n"
"\n"
"        critical 给Syncd加锁\n"
"            loop 所有收到的消息\n"
"                SD->>RSC: 获取一个消息\n"
"                SD->>SD: 解析消息，获取操作类型和操作对象\n"
"                SD->>SAI: 调用对应的SAI API，更新ASIC\n"
"                SD->>RSC: 发送调用结果给Redis\n"
"                RSC->>R: 将调用结果写入Redis\n"
"            end\n"
"        end\n"
"    end\n"
"```"
msgstr ""
"```mermaid\n"
"sequenceDiagram\n"
"    autonumber\n"
"    participant SD as Syncd\n"
"    participant RSC as RedisSelectableChannel\n"
"    participant SAI as VendorSai\n"
"    participant R as Redis\n"
"\n"
"    loop 主线程循环\n"
"        SD->>RSC: 收到epoll通知，通知获取所有到来的消息\n"
"        RSC->>R: 通过ConsumerTable获取所有到来的消息\n"
"\n"
"        critical 给Syncd加锁\n"
"            loop 所有收到的消息\n"
"                SD->>RSC: 获取一个消息\n"
"                SD->>SD: 解析消息，获取操作类型和操作对象\n"
"                SD->>SAI: 调用对应的SAI API，更新ASIC\n"
"                SD->>RSC: 发送调用结果给Redis\n"
"                RSC->>R: 将调用结果写入Redis\n"
"            end\n"
"        end\n"
"    end\n"
"```"

#: src/5-1-syncd-and-sai.md:458
msgid ""
"首先，`orchagent`通过Redis发送过来的操作会被`RedisSelectableChannel`对象接"
"收，然后在主循环中被处理。当`Syncd`处理到`m_selectableChannel`时，就会调用"
"`processEvent`方法来处理该操作。这几步的核心代码我们上面介绍主循环时已经介绍"
"过了，这里就不再赘述。"
msgstr ""
"First, the operation sent by `orchagent` through Redis is received by the "
"`RedisSelectableChannel` object and then processed in the main loop. When "
"`Syncd` processes to `m_selectableChannel`, it calls the `processEvent` "
"method to process the operation. The core code for these steps has been "
"described above when we introduced the main loop, so we won't go over it "
"here."

#: src/5-1-syncd-and-sai.md:460
msgid ""
"然后，`processEvent`会根据其中的操作类型，调用对应的SAI的API来对ASIC进行更"
"新。其逻辑是一个巨大的switch-case语句，如下："
msgstr ""
"Then, `processEvent` will call the corresponding SAI's API to update the "
"ASIC according to the type of operation in it. The logic is a giant switch-"
"case statement, as follows:"

#: src/5-1-syncd-and-sai.md:462
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"void Syncd::processEvent(_In_ sairedis::SelectableChannel& consumer)\n"
"{\n"
"    // Loop all operations in the queue\n"
"    std::lock_guard<std::mutex> lock(m_mutex);\n"
"    do {\n"
"        swss::KeyOpFieldsValuesTuple kco;\n"
"        consumer.pop(kco, isInitViewMode());\n"
"        processSingleEvent(kco);\n"
"    } while (!consumer.empty());\n"
"}\n"
"\n"
"sai_status_t Syncd::processSingleEvent(_In_ const swss::"
"KeyOpFieldsValuesTuple &kco)\n"
"{\n"
"    auto& op = kfvOp(kco);\n"
"    ...\n"
"\n"
"    if (op == REDIS_ASIC_STATE_COMMAND_CREATE)\n"
"        return processQuadEvent(SAI_COMMON_API_CREATE, kco);\n"
"\n"
"    if (op == REDIS_ASIC_STATE_COMMAND_REMOVE)\n"
"        return processQuadEvent(SAI_COMMON_API_REMOVE, kco);\n"
"    \n"
"    ...\n"
"}\n"
"\n"
"sai_status_t Syncd::processQuadEvent(\n"
"        _In_ sai_common_api_t api,\n"
"        _In_ const swss::KeyOpFieldsValuesTuple &kco)\n"
"{\n"
"    // Parse operation\n"
"    const std::string& key = kfvKey(kco);\n"
"    const std::string& strObjectId = key.substr(key.find(\":\") + 1);\n"
"\n"
"    sai_object_meta_key_t metaKey;\n"
"    sai_deserialize_object_meta_key(key, metaKey);\n"
"\n"
"    auto& values = kfvFieldsValues(kco);\n"
"    SaiAttributeList list(metaKey.objecttype, values, false);\n"
"    sai_attribute_t *attr_list = list.get_attr_list();\n"
"    uint32_t attr_count = list.get_attr_count();\n"
"    ...\n"
"\n"
"    auto info = sai_metadata_get_object_type_info(metaKey.objecttype);\n"
"\n"
"    // Process the operation\n"
"    sai_status_t status;\n"
"    if (info->isnonobjectid) {\n"
"        status = processEntry(metaKey, api, attr_count, attr_list);\n"
"    } else {\n"
"        status = processOid(metaKey.objecttype, strObjectId, api, "
"attr_count, attr_list);\n"
"    }\n"
"\n"
"    // Send response\n"
"    if (api == SAI_COMMON_API_GET) {\n"
"        sai_object_id_t switchVid = VidManager::switchIdQuery(metaKey."
"objectkey.key.object_id);\n"
"        sendGetResponse(metaKey.objecttype, strObjectId, switchVid, status, "
"attr_count, attr_list);\n"
"        ...\n"
"    } else {\n"
"        sendApiResponse(api, status);\n"
"    }\n"
"\n"
"    syncUpdateRedisQuadEvent(status, api, kco);\n"
"    return status;\n"
"}\n"
"\n"
"sai_status_t Syncd::processEntry(_In_ sai_object_meta_key_t metaKey, _In_ "
"sai_common_api_t api,\n"
"                                 _In_ uint32_t attr_count, _In_ "
"sai_attribute_t *attr_list)\n"
"{\n"
"    ...\n"
"\n"
"    switch (api)\n"
"    {\n"
"        case SAI_COMMON_API_CREATE:\n"
"            return m_vendorSai->create(metaKey, SAI_NULL_OBJECT_ID, "
"attr_count, attr_list);\n"
"\n"
"        case SAI_COMMON_API_REMOVE:\n"
"            return m_vendorSai->remove(metaKey);\n"
"        ...\n"
"\n"
"        default:\n"
"            SWSS_LOG_THROW(\"api %s not supported\", "
"sai_serialize_common_api(api).c_str());\n"
"    }\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"void Syncd::processEvent(_In_ sairedis::SelectableChannel& consumer)\n"
"{\n"
"    // Loop all operations in the queue\n"
"    std::lock_guard<std::mutex> lock(m_mutex);\n"
"    do {\n"
"        swss::KeyOpFieldsValuesTuple kco;\n"
"        consumer.pop(kco, isInitViewMode());\n"
"        processSingleEvent(kco);\n"
"    } while (!consumer.empty());\n"
"}\n"
"\n"
"sai_status_t Syncd::processSingleEvent(_In_ const swss::"
"KeyOpFieldsValuesTuple &kco)\n"
"{\n"
"    auto& op = kfvOp(kco);\n"
"    ...\n"
"\n"
"    if (op == REDIS_ASIC_STATE_COMMAND_CREATE)\n"
"        return processQuadEvent(SAI_COMMON_API_CREATE, kco);\n"
"\n"
"    if (op == REDIS_ASIC_STATE_COMMAND_REMOVE)\n"
"        return processQuadEvent(SAI_COMMON_API_REMOVE, kco);\n"
"    \n"
"    ...\n"
"}\n"
"\n"
"sai_status_t Syncd::processQuadEvent(\n"
"        _In_ sai_common_api_t api,\n"
"        _In_ const swss::KeyOpFieldsValuesTuple &kco)\n"
"{\n"
"    // Parse operation\n"
"    const std::string& key = kfvKey(kco);\n"
"    const std::string& strObjectId = key.substr(key.find(\":\") + 1);\n"
"\n"
"    sai_object_meta_key_t metaKey;\n"
"    sai_deserialize_object_meta_key(key, metaKey);\n"
"\n"
"    auto& values = kfvFieldsValues(kco);\n"
"    SaiAttributeList list(metaKey.objecttype, values, false);\n"
"    sai_attribute_t *attr_list = list.get_attr_list();\n"
"    uint32_t attr_count = list.get_attr_count();\n"
"    ...\n"
"\n"
"    auto info = sai_metadata_get_object_type_info(metaKey.objecttype);\n"
"\n"
"    // Process the operation\n"
"    sai_status_t status;\n"
"    if (info->isnonobjectid) {\n"
"        status = processEntry(metaKey, api, attr_count, attr_list);\n"
"    } else {\n"
"        status = processOid(metaKey.objecttype, strObjectId, api, "
"attr_count, attr_list);\n"
"    }\n"
"\n"
"    // Send response\n"
"    if (api == SAI_COMMON_API_GET) {\n"
"        sai_object_id_t switchVid = VidManager::switchIdQuery(metaKey."
"objectkey.key.object_id);\n"
"        sendGetResponse(metaKey.objecttype, strObjectId, switchVid, status, "
"attr_count, attr_list);\n"
"        ...\n"
"    } else {\n"
"        sendApiResponse(api, status);\n"
"    }\n"
"\n"
"    syncUpdateRedisQuadEvent(status, api, kco);\n"
"    return status;\n"
"}\n"
"\n"
"sai_status_t Syncd::processEntry(_In_ sai_object_meta_key_t metaKey, _In_ "
"sai_common_api_t api,\n"
"                                 _In_ uint32_t attr_count, _In_ "
"sai_attribute_t *attr_list)\n"
"{\n"
"    ...\n"
"\n"
"    switch (api)\n"
"    {\n"
"        case SAI_COMMON_API_CREATE:\n"
"            return m_vendorSai->create(metaKey, SAI_NULL_OBJECT_ID, "
"attr_count, attr_list);\n"
"\n"
"        case SAI_COMMON_API_REMOVE:\n"
"            return m_vendorSai->remove(metaKey);\n"
"        ...\n"
"\n"
"        default:\n"
"            SWSS_LOG_THROW(\"api %s not supported\", "
"sai_serialize_common_api(api).c_str());\n"
"    }\n"
"}\n"
"```"

#: src/5-1-syncd-and-sai.md:549
msgid "## ASIC状态变更上报"
msgstr "## ASIC status change reporting"

#: src/5-1-syncd-and-sai.md:551
msgid ""
"反过来，当ASIC状态发生任何变化，或者需要上报数据，它也会通过SAI来通知我们，此"
"时Syncd会监听这些通知，然后通过ASIC_DB上报给orchagent。其主要工作流如下："
msgstr ""
"In turn, when any change in ASIC status occurs or data needs to be reported, "
"it will also notify us via SAI, at which point Syncd will listen for these "
"notifications and then report them to the orchagent via ASIC_DB. its main "
"workflow is as follows:"

#: src/5-1-syncd-and-sai.md:553
msgid ""
"```mermaid\n"
"sequenceDiagram\n"
"    box purple SAI实现事件处理线程\n"
"    participant SAI as SAI Impl\n"
"    end\n"
"    box darkblue 通知处理线程\n"
"    participant NP as NotificationProcessor\n"
"    participant SD as Syncd\n"
"    participant RNP as RedisNotificationProducer\n"
"    participant R as Redis\n"
"    end\n"
"\n"
"    loop SAI实现事件处理消息循环\n"
"        SAI->>SAI: 通过ASIC SDK获取事件\n"
"        SAI->>SAI: 解析事件，并转换成SAI通知对象\n"
"        SAI->>NP: 将通知对象序列化，<br/>并发送给通知处理线程的队列中\n"
"    end\n"
"\n"
"    loop 通知处理线程消息循环\n"
"        NP->>NP: 从队列中获取通知\n"
"        NP->>SD: 获取Syncd锁\n"
"        critical 给Syncd加锁\n"
"            NP->>NP: 反序列化通知对象，并做一些处理\n"
"            NP->>RNP: 重新序列化通知对象，并请求发送\n"
"            RNP->>R: 将通知以NotificationProducer<br/>的形式写入ASIC_DB\n"
"        end\n"
"    end\n"
"```"
msgstr ""
"```mermaid\n"
"sequenceDiagram\n"
"    box purple SAI实现事件处理线程\n"
"    participant SAI as SAI Impl\n"
"    end\n"
"    box darkblue 通知处理线程\n"
"    participant NP as NotificationProcessor\n"
"    participant SD as Syncd\n"
"    participant RNP as RedisNotificationProducer\n"
"    participant R as Redis\n"
"    end\n"
"\n"
"    loop SAI实现事件处理消息循环\n"
"        SAI->>SAI: 通过ASIC SDK获取事件\n"
"        SAI->>SAI: 解析事件，并转换成SAI通知对象\n"
"        SAI->>NP: 将通知对象序列化，<br/>并发送给通知处理线程的队列中\n"
"    end\n"
"\n"
"    loop 通知处理线程消息循环\n"
"        NP->>NP: 从队列中获取通知\n"
"        NP->>SD: 获取Syncd锁\n"
"        critical 给Syncd加锁\n"
"            NP->>NP: 反序列化通知对象，并做一些处理\n"
"            NP->>RNP: 重新序列化通知对象，并请求发送\n"
"            RNP->>R: 将通知以NotificationProducer<br/>的形式写入ASIC_DB\n"
"        end\n"
"    end\n"
"```"

#: src/5-1-syncd-and-sai.md:582
msgid ""
"这里我们也来看一下具体的实现。为了更加深入的理解，我们还是借助开源的Mellanox"
"的SAI实现来进行分析。"
msgstr ""
"Here we also look at the specific implementation. For a more in-depth "
"understanding, we still analyze it with the help of the open source Mellanox "
"SAI implementation."

#: src/5-1-syncd-and-sai.md:584
msgid ""
"最开始，SAI的实现需要接受到ASIC的通知，这一步是通过ASIC的SDK来实现的，"
"Mellanox的SAI会创建一个事件处理线程（event_thread），然后使用`select`函数来获"
"取并处理ASIC发送过来的通知，核心代码如下："
msgstr ""
"At the very beginning, the SAI implementation needs to receive notifications "
"from ASIC, this step is implemented through the ASIC SDK. Mellanox's SAI "
"creates an event handling thread (event_thread) and then uses the `select` "
"function to get and process the notifications sent from ASIC, the core code "
"is as follows:"

#: src/5-1-syncd-and-sai.md:586
msgid ""
"```cpp\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_switch.c\n"
"static void event_thread_func(void *context)\n"
"{\n"
"#define MAX_PACKET_SIZE MAX(g_resource_limits.port_mtu_max, "
"SX_HOST_EVENT_BUFFER_SIZE_MAX)\n"
"\n"
"    sx_status_t                         status;\n"
"    sx_api_handle_t                     api_handle;\n"
"    sx_user_channel_t                   port_channel, callback_channel;\n"
"    fd_set                              descr_set;\n"
"    int                                 ret_val;\n"
"    sai_object_id_t                     switch_id = "
"(sai_object_id_t)context;\n"
"    sai_port_oper_status_notification_t port_data;\n"
"    sai_fdb_event_notification_data_t  *fdb_events = NULL;\n"
"    sai_attribute_t                    *attr_list = NULL;\n"
"    ...\n"
"\n"
"    // Init SDK API\n"
"    if (SX_STATUS_SUCCESS != (status = sx_api_open(sai_log_cb, "
"&api_handle))) {\n"
"        if (g_notification_callbacks.on_switch_shutdown_request) {\n"
"            g_notification_callbacks.on_switch_shutdown_request(switch_id);\n"
"        }\n"
"        return;\n"
"    }\n"
"\n"
"    if (SX_STATUS_SUCCESS != (status = sx_api_host_ifc_open(api_handle, "
"&port_channel.channel.fd))) {\n"
"        goto out;\n"
"    }\n"
"    ...\n"
"\n"
"    // Register for port and channel notifications\n"
"    port_channel.type = SX_USER_CHANNEL_TYPE_FD;\n"
"    if (SX_STATUS_SUCCESS != (status = "
"sx_api_host_ifc_trap_id_register_set(api_handle, SX_ACCESS_CMD_REGISTER, "
"DEFAULT_ETH_SWID, SX_TRAP_ID_PUDE, &port_channel))) {\n"
"        goto out;\n"
"    }\n"
"    ...\n"
"    for (uint32_t ii = 0; ii < (sizeof(mlnx_trap_ids) / "
"sizeof(*mlnx_trap_ids)); ii++) {\n"
"        status = sx_api_host_ifc_trap_id_register_set(api_handle, "
"SX_ACCESS_CMD_REGISTER, DEFAULT_ETH_SWID, mlnx_trap_ids[ii], "
"&callback_channel);\n"
"    }\n"
"\n"
"    while (!event_thread_asked_to_stop) {\n"
"        FD_ZERO(&descr_set);\n"
"        FD_SET(port_channel.channel.fd.fd, &descr_set);\n"
"        FD_SET(callback_channel.channel.fd.fd, &descr_set);\n"
"        ...\n"
"\n"
"        ret_val = select(FD_SETSIZE, &descr_set, NULL, NULL, &timeout);\n"
"        if (ret_val > 0) {\n"
"            // Port state change event\n"
"            if (FD_ISSET(port_channel.channel.fd.fd, &descr_set)) {\n"
"                // Parse port state event here ...\n"
"                if (g_notification_callbacks.on_port_state_change) {\n"
"                    g_notification_callbacks.on_port_state_change(1, "
"&port_data);\n"
"                }\n"
"            }\n"
"\n"
"            if (FD_ISSET(callback_channel.channel.fd.fd, &descr_set)) {\n"
"                // Receive notification event.\n"
"                packet_size = MAX_PACKET_SIZE;\n"
"                if (SX_STATUS_SUCCESS != (status = "
"sx_lib_host_ifc_recv(&callback_channel.channel.fd, p_packet, &packet_size, "
"receive_info))) {\n"
"                    goto out;\n"
"                }\n"
"\n"
"                // BFD packet event\n"
"                if (SX_TRAP_ID_BFD_PACKET_EVENT == receive_info->trap_id) {\n"
"                    const struct bfd_packet_event *event = (const struct "
"bfd_packet_event*)p_packet;\n"
"                    // Parse and check event valid here ...\n"
"                    status = mlnx_switch_bfd_packet_handle(event);\n"
"                    continue;\n"
"                }\n"
"\n"
"                // Same way to handle BFD timeout event, Bulk counter ready "
"event. Emiited.\n"
"\n"
"                // FDB event and packet event handling\n"
"                if (receive_info->trap_id == SX_TRAP_ID_FDB_EVENT) {\n"
"                    trap_name = \"FDB event\";\n"
"                } else if (SAI_STATUS_SUCCESS != (status = "
"mlnx_translate_sdk_trap_to_sai(receive_info->trap_id, &trap_name, "
"&trap_oid))) {\n"
"                    continue;\n"
"                }\n"
"\n"
"                if (SX_TRAP_ID_FDB_EVENT == receive_info->trap_id) {\n"
"                    // Parse FDB events here ...\n"
"\n"
"                    if (g_notification_callbacks.on_fdb_event) {\n"
"                        g_notification_callbacks.on_fdb_event(event_count, "
"fdb_events);\n"
"                    }\n"
"\n"
"                    continue;\n"
"                }\n"
"\n"
"                // Packet event handling\n"
"                status = mlnx_get_hostif_packet_data(receive_info, "
"&attrs_num, callback_data);\n"
"                if (g_notification_callbacks.on_packet_event) {\n"
"                    g_notification_callbacks.on_packet_event(switch_id, "
"packet_size, p_packet, attrs_num, callback_data);\n"
"                }\n"
"            }\n"
"        }\n"
"    }\n"
"\n"
"out:\n"
"    ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_switch.c\n"
"static void event_thread_func(void *context)\n"
"{\n"
"#define MAX_PACKET_SIZE MAX(g_resource_limits.port_mtu_max, "
"SX_HOST_EVENT_BUFFER_SIZE_MAX)\n"
"\n"
"    sx_status_t                         status;\n"
"    sx_api_handle_t                     api_handle;\n"
"    sx_user_channel_t                   port_channel, callback_channel;\n"
"    fd_set                              descr_set;\n"
"    int                                 ret_val;\n"
"    sai_object_id_t                     switch_id = "
"(sai_object_id_t)context;\n"
"    sai_port_oper_status_notification_t port_data;\n"
"    sai_fdb_event_notification_data_t  *fdb_events = NULL;\n"
"    sai_attribute_t                    *attr_list = NULL;\n"
"    ...\n"
"\n"
"    // Init SDK API\n"
"    if (SX_STATUS_SUCCESS != (status = sx_api_open(sai_log_cb, "
"&api_handle))) {\n"
"        if (g_notification_callbacks.on_switch_shutdown_request) {\n"
"            g_notification_callbacks.on_switch_shutdown_request(switch_id);\n"
"        }\n"
"        return;\n"
"    }\n"
"\n"
"    if (SX_STATUS_SUCCESS != (status = sx_api_host_ifc_open(api_handle, "
"&port_channel.channel.fd))) {\n"
"        goto out;\n"
"    }\n"
"    ...\n"
"\n"
"    // Register for port and channel notifications\n"
"    port_channel.type = SX_USER_CHANNEL_TYPE_FD;\n"
"    if (SX_STATUS_SUCCESS != (status = "
"sx_api_host_ifc_trap_id_register_set(api_handle, SX_ACCESS_CMD_REGISTER, "
"DEFAULT_ETH_SWID, SX_TRAP_ID_PUDE, &port_channel))) {\n"
"        goto out;\n"
"    }\n"
"    ...\n"
"    for (uint32_t ii = 0; ii < (sizeof(mlnx_trap_ids) / "
"sizeof(*mlnx_trap_ids)); ii++) {\n"
"        status = sx_api_host_ifc_trap_id_register_set(api_handle, "
"SX_ACCESS_CMD_REGISTER, DEFAULT_ETH_SWID, mlnx_trap_ids[ii], "
"&callback_channel);\n"
"    }\n"
"\n"
"    while (!event_thread_asked_to_stop) {\n"
"        FD_ZERO(&descr_set);\n"
"        FD_SET(port_channel.channel.fd.fd, &descr_set);\n"
"        FD_SET(callback_channel.channel.fd.fd, &descr_set);\n"
"        ...\n"
"\n"
"        ret_val = select(FD_SETSIZE, &descr_set, NULL, NULL, &timeout);\n"
"        if (ret_val > 0) {\n"
"            // Port state change event\n"
"            if (FD_ISSET(port_channel.channel.fd.fd, &descr_set)) {\n"
"                // Parse port state event here ...\n"
"                if (g_notification_callbacks.on_port_state_change) {\n"
"                    g_notification_callbacks.on_port_state_change(1, "
"&port_data);\n"
"                }\n"
"            }\n"
"\n"
"            if (FD_ISSET(callback_channel.channel.fd.fd, &descr_set)) {\n"
"                // Receive notification event.\n"
"                packet_size = MAX_PACKET_SIZE;\n"
"                if (SX_STATUS_SUCCESS != (status = "
"sx_lib_host_ifc_recv(&callback_channel.channel.fd, p_packet, &packet_size, "
"receive_info))) {\n"
"                    goto out;\n"
"                }\n"
"\n"
"                // BFD packet event\n"
"                if (SX_TRAP_ID_BFD_PACKET_EVENT == receive_info->trap_id) {\n"
"                    const struct bfd_packet_event *event = (const struct "
"bfd_packet_event*)p_packet;\n"
"                    // Parse and check event valid here ...\n"
"                    status = mlnx_switch_bfd_packet_handle(event);\n"
"                    continue;\n"
"                }\n"
"\n"
"                // Same way to handle BFD timeout event, Bulk counter ready "
"event. Emiited.\n"
"\n"
"                // FDB event and packet event handling\n"
"                if (receive_info->trap_id == SX_TRAP_ID_FDB_EVENT) {\n"
"                    trap_name = \"FDB event\";\n"
"                } else if (SAI_STATUS_SUCCESS != (status = "
"mlnx_translate_sdk_trap_to_sai(receive_info->trap_id, &trap_name, "
"&trap_oid))) {\n"
"                    continue;\n"
"                }\n"
"\n"
"                if (SX_TRAP_ID_FDB_EVENT == receive_info->trap_id) {\n"
"                    // Parse FDB events here ...\n"
"\n"
"                    if (g_notification_callbacks.on_fdb_event) {\n"
"                        g_notification_callbacks.on_fdb_event(event_count, "
"fdb_events);\n"
"                    }\n"
"\n"
"                    continue;\n"
"                }\n"
"\n"
"                // Packet event handling\n"
"                status = mlnx_get_hostif_packet_data(receive_info, "
"&attrs_num, callback_data);\n"
"                if (g_notification_callbacks.on_packet_event) {\n"
"                    g_notification_callbacks.on_packet_event(switch_id, "
"packet_size, p_packet, attrs_num, callback_data);\n"
"                }\n"
"            }\n"
"        }\n"
"    }\n"
"\n"
"out:\n"
"    ...\n"
"}\n"
"```"

#: src/5-1-syncd-and-sai.md:690
msgid ""
"接下来，我们用FDB事件来举例，当ASIC收到FDB事件，就会被上面的事件处理循环获取"
"到，并调用`g_notification_callbacks.on_fdb_event`函数来处理。这个函数接下来就"
"会调用到`Syncd`初始化时设置好的`NotificationHandler::onFdbEvent`函数，这个函"
"数会将该事件序列化后，通过消息队列转发给通知处理线程来进行处理："
msgstr ""
"Next, let's use the FDB event as an example. When ASIC receives an FDB "
"event, it will be fetched by the event handling loop above and the "
"`g_notification_callbacks.on_fdb_event` function will be called to handle "
"it. This function then calls the `NotificationHandler::onFdbEvent` function "
"that was set up when `Syncd` was initialized, which serializes the event and "
"forwards it through the message queue to the notification handler thread for "
"processing:"

#: src/5-1-syncd-and-sai.md:692
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationHandler.cpp\n"
"void NotificationHandler::onFdbEvent(_In_ uint32_t count, _In_ const "
"sai_fdb_event_notification_data_t *data)\n"
"{\n"
"    std::string s = sai_serialize_fdb_event_ntf(count, data);\n"
"    enqueueNotification(SAI_SWITCH_NOTIFICATION_NAME_FDB_EVENT, s);\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationHandler.cpp\n"
"void NotificationHandler::onFdbEvent(_In_ uint32_t count, _In_ const "
"sai_fdb_event_notification_data_t *data)\n"
"{\n"
"    std::string s = sai_serialize_fdb_event_ntf(count, data);\n"
"    enqueueNotification(SAI_SWITCH_NOTIFICATION_NAME_FDB_EVENT, s);\n"
"}\n"
"```"

#: src/5-1-syncd-and-sai.md:701
msgid ""
"而此时通知处理线程会被唤醒，从消息队列中取出该事件，然后通过`Syncd`获取到"
"`Syncd`的锁，再开始处理该通知："
msgstr ""
"And then the notification handler thread is woken up, takes the event out of "
"the message queue, and then gets a lock on `Syncd` via `Syncd` and starts "
"processing the notification again: the"

#: src/5-1-syncd-and-sai.md:703
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationProcessor.cpp\n"
"void NotificationProcessor::ntf_process_function()\n"
"{\n"
"    std::mutex ntf_mutex;\n"
"    std::unique_lock<std::mutex> ulock(ntf_mutex);\n"
"\n"
"    while (m_runThread) {\n"
"        // When notification arrives, it will signal this condition "
"variable.\n"
"        m_cv.wait(ulock);\n"
"\n"
"        // Process notifications in the queue.\n"
"        swss::KeyOpFieldsValuesTuple item;\n"
"        while (m_notificationQueue->tryDequeue(item)) {\n"
"            processNotification(item);\n"
"        }\n"
"    }\n"
"}\n"
"\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"// Call from NotificationProcessor::processNotification\n"
"void Syncd::syncProcessNotification(_In_ const swss::KeyOpFieldsValuesTuple& "
"item)\n"
"{\n"
"    std::lock_guard<std::mutex> lock(m_mutex);\n"
"    m_processor->syncProcessNotification(item);\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationProcessor.cpp\n"
"void NotificationProcessor::ntf_process_function()\n"
"{\n"
"    std::mutex ntf_mutex;\n"
"    std::unique_lock<std::mutex> ulock(ntf_mutex);\n"
"\n"
"    while (m_runThread) {\n"
"        // When notification arrives, it will signal this condition "
"variable.\n"
"        m_cv.wait(ulock);\n"
"\n"
"        // Process notifications in the queue.\n"
"        swss::KeyOpFieldsValuesTuple item;\n"
"        while (m_notificationQueue->tryDequeue(item)) {\n"
"            processNotification(item);\n"
"        }\n"
"    }\n"
"}\n"
"\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"// Call from NotificationProcessor::processNotification\n"
"void Syncd::syncProcessNotification(_In_ const swss::KeyOpFieldsValuesTuple& "
"item)\n"
"{\n"
"    std::lock_guard<std::mutex> lock(m_mutex);\n"
"    m_processor->syncProcessNotification(item);\n"
"}\n"
"```"

#: src/5-1-syncd-and-sai.md:731
msgid ""
"接下来就是事件的分发和处理了，`syncProcessNotification`函数是一系列的`if-"
"else`语句，根据事件的类型，调用不同的处理函数来处理该事件："
msgstr ""
"The next step is the distribution and processing of events. The "
"`syncProcessNotification` function is a series of `if-else` statements that, "
"depending on the type of event, call different handler functions to process "
"the event:"

#: src/5-1-syncd-and-sai.md:733
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationProcessor.cpp\n"
"void NotificationProcessor::syncProcessNotification( _In_ const swss::"
"KeyOpFieldsValuesTuple& item)\n"
"{\n"
"    std::string notification = kfvKey(item);\n"
"    std::string data = kfvOp(item);\n"
"\n"
"    if (notification == SAI_SWITCH_NOTIFICATION_NAME_SWITCH_STATE_CHANGE) {\n"
"        handle_switch_state_change(data);\n"
"    } else if (notification == SAI_SWITCH_NOTIFICATION_NAME_FDB_EVENT) {\n"
"        handle_fdb_event(data);\n"
"    } else if ...\n"
"    } else {\n"
"        SWSS_LOG_ERROR(\"unknown notification: %s\", notification.c_str());\n"
"    }\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationProcessor.cpp\n"
"void NotificationProcessor::syncProcessNotification( _In_ const swss::"
"KeyOpFieldsValuesTuple& item)\n"
"{\n"
"    std::string notification = kfvKey(item);\n"
"    std::string data = kfvOp(item);\n"
"\n"
"    if (notification == SAI_SWITCH_NOTIFICATION_NAME_SWITCH_STATE_CHANGE) {\n"
"        handle_switch_state_change(data);\n"
"    } else if (notification == SAI_SWITCH_NOTIFICATION_NAME_FDB_EVENT) {\n"
"        handle_fdb_event(data);\n"
"    } else if ...\n"
"    } else {\n"
"        SWSS_LOG_ERROR(\"unknown notification: %s\", notification.c_str());\n"
"    }\n"
"}\n"
"```"

#: src/5-1-syncd-and-sai.md:751
msgid ""
"而每个事件处理函数都类似，他们会对发送过来的事件进行反序列化，然后调用真正的"
"处理逻辑发送通知，比如，fdb事件对应的`handle_fdb_event`函数和"
"`process_on_fdb_event`："
msgstr ""
"And each event handling function is similar in that they deserialize the "
"events sent to them and then call the real processing logic to send "
"notifications, for example, the `handle_fdb_event` function and "
"`process_on_fdb_event` corresponding to the fdb event:"

#: src/5-1-syncd-and-sai.md:753
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationProcessor.cpp\n"
"void NotificationProcessor::handle_fdb_event(_In_ const std::string &data)\n"
"{\n"
"    uint32_t count;\n"
"    sai_fdb_event_notification_data_t *fdbevent = NULL;\n"
"    sai_deserialize_fdb_event_ntf(data, count, &fdbevent);\n"
"\n"
"    process_on_fdb_event(count, fdbevent);\n"
"\n"
"    sai_deserialize_free_fdb_event_ntf(count, fdbevent);\n"
"}\n"
"\n"
"void NotificationProcessor::process_on_fdb_event( _In_ uint32_t count, _In_ "
"sai_fdb_event_notification_data_t *data)\n"
"{\n"
"    for (uint32_t i = 0; i < count; i++) {\n"
"        sai_fdb_event_notification_data_t *fdb = &data[i];\n"
"        // Check FDB event notification data here\n"
"\n"
"        fdb->fdb_entry.switch_id = m_translator->translateRidToVid(fdb-"
">fdb_entry.switch_id, SAI_NULL_OBJECT_ID);\n"
"        fdb->fdb_entry.bv_id = m_translator->translateRidToVid(fdb-"
">fdb_entry.bv_id, fdb->fdb_entry.switch_id, true);\n"
"        m_translator->translateRidToVid(SAI_OBJECT_TYPE_FDB_ENTRY, fdb-"
">fdb_entry.switch_id, fdb->attr_count, fdb->attr, true);\n"
"\n"
"        ...\n"
"    }\n"
"\n"
"    // Send notification\n"
"    std::string s = sai_serialize_fdb_event_ntf(count, data);\n"
"    sendNotification(SAI_SWITCH_NOTIFICATION_NAME_FDB_EVENT, s);\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationProcessor.cpp\n"
"void NotificationProcessor::handle_fdb_event(_In_ const std::string &data)\n"
"{\n"
"    uint32_t count;\n"
"    sai_fdb_event_notification_data_t *fdbevent = NULL;\n"
"    sai_deserialize_fdb_event_ntf(data, count, &fdbevent);\n"
"\n"
"    process_on_fdb_event(count, fdbevent);\n"
"\n"
"    sai_deserialize_free_fdb_event_ntf(count, fdbevent);\n"
"}\n"
"\n"
"void NotificationProcessor::process_on_fdb_event( _In_ uint32_t count, _In_ "
"sai_fdb_event_notification_data_t *data)\n"
"{\n"
"    for (uint32_t i = 0; i < count; i++) {\n"
"        sai_fdb_event_notification_data_t *fdb = &data[i];\n"
"        // Check FDB event notification data here\n"
"\n"
"        fdb->fdb_entry.switch_id = m_translator->translateRidToVid(fdb-"
">fdb_entry.switch_id, SAI_NULL_OBJECT_ID);\n"
"        fdb->fdb_entry.bv_id = m_translator->translateRidToVid(fdb-"
">fdb_entry.bv_id, fdb->fdb_entry.switch_id, true);\n"
"        m_translator->translateRidToVid(SAI_OBJECT_TYPE_FDB_ENTRY, fdb-"
">fdb_entry.switch_id, fdb->attr_count, fdb->attr, true);\n"
"\n"
"        ...\n"
"    }\n"
"\n"
"    // Send notification\n"
"    std::string s = sai_serialize_fdb_event_ntf(count, data);\n"
"    sendNotification(SAI_SWITCH_NOTIFICATION_NAME_FDB_EVENT, s);\n"
"}\n"
"```"

#: src/5-1-syncd-and-sai.md:785
msgid ""
"具体发送事件的逻辑就非常直接了，最终就是通过[NotificationProducer](./4-2-2-"
"redis-messaging-layer.html#notificationproducer--notificationconsumer)来发送"
"通知到ASIC_DB中："
msgstr ""
"The logic for sending specific events is pretty straightforward, and "
"ultimately it's all about sending notifications to ASIC_DB via "
"[NotificationProducer](. /4-2-2-redis-messaging-layer."
"html#notificationproducer--notificationconsumer) to send notifications to "
"the ASIC_DB:"

#: src/5-1-syncd-and-sai.md:787
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationProcessor.cpp\n"
"void NotificationProcessor::sendNotification(_In_ const std::string& op, "
"_In_ const std::string& data)\n"
"{\n"
"    std::vector<swss::FieldValueTuple> entry;\n"
"    sendNotification(op, data, entry);\n"
"}\n"
"\n"
"void NotificationProcessor::sendNotification(_In_ const std::string& op, "
"_In_ const std::string& data, _In_ std::vector<swss::FieldValueTuple> "
"entry)\n"
"{\n"
"    m_notifications->send(op, data, entry);\n"
"}\n"
"\n"
"// File: src/sonic-sairedis/syncd/RedisNotificationProducer.cpp\n"
"void RedisNotificationProducer::send(_In_ const std::string& op, _In_ const "
"std::string& data, _In_ const std::vector<swss::FieldValueTuple>& values)\n"
"{\n"
"    std::vector<swss::FieldValueTuple> vals = values;\n"
"\n"
"    // The m_notificationProducer is created in the ctor of "
"RedisNotificationProducer as below:\n"
"    // m_notificationProducer = std::make_shared<swss::"
"NotificationProducer>(m_db.get(), "
"REDIS_TABLE_NOTIFICATIONS_PER_DB(dbName));\n"
"    m_notificationProducer->send(op, data, vals);\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationProcessor.cpp\n"
"void NotificationProcessor::sendNotification(_In_ const std::string& op, "
"_In_ const std::string& data)\n"
"{\n"
"    std::vector<swss::FieldValueTuple> entry;\n"
"    sendNotification(op, data, entry);\n"
"}\n"
"\n"
"void NotificationProcessor::sendNotification(_In_ const std::string& op, "
"_In_ const std::string& data, _In_ std::vector<swss::FieldValueTuple> "
"entry)\n"
"{\n"
"    m_notifications->send(op, data, entry);\n"
"}\n"
"\n"
"// File: src/sonic-sairedis/syncd/RedisNotificationProducer.cpp\n"
"void RedisNotificationProducer::send(_In_ const std::string& op, _In_ const "
"std::string& data, _In_ const std::vector<swss::FieldValueTuple>& values)\n"
"{\n"
"    std::vector<swss::FieldValueTuple> vals = values;\n"
"\n"
"    // The m_notificationProducer is created in the ctor of "
"RedisNotificationProducer as below:\n"
"    // m_notificationProducer = std::make_shared<swss::"
"NotificationProducer>(m_db.get(), "
"REDIS_TABLE_NOTIFICATIONS_PER_DB(dbName));\n"
"    m_notificationProducer->send(op, data, vals);\n"
"}\n"
"```"

#: src/5-1-syncd-and-sai.md:811
msgid "到此，`Syncd`中的通知上报的流程就结束了。"
msgstr ""
"At this point, the process of notification upload in `Syncd` is finished."

#: src/5-1-syncd-and-sai.md:815
msgid ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [Github repo: sonic-sairedis][SONiCSAIRedis]\n"
"3. [Github repo: Nvidia (Mellanox) SAI implementation][MnlxSAI]"
msgstr ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [Github repo: sonic-sairedis][SONiCSAIRedis]\n"
"3. [Github repo: Nvidia (Mellanox) SAI implementation][MnlxSAI]"

#: src/5-2-bgp.md:1
msgid "# BGP"
msgstr "# BGP"

#: src/5-2-bgp.md:3
msgid ""
"[BGP][BGP]可能是交换机里面最常用，最重要，或者线上使用的最多的功能了。这一"
"节，我们就来深入的看一下BGP相关的工作流。"
msgstr ""
"[BGP][BGP] is probably the most common, important, or most used feature "
"inside a switch on the wire. In this section, let's take an in-depth look at "
"BGP-related workflows."

#: src/5-2-bgp.md:5
msgid "## BGP相关进程"
msgstr "## BGP-related processes"

#: src/5-2-bgp.md:7
msgid ""
"SONiC使用[FRRouting][FRRouting]作为BGP的实现，用于负责BGP的协议处理。"
"FRRouting是一个开源的路由软件，支持多种路由协议，包括BGP，OSPF，IS-IS，RIP，"
"PIM，LDP等等。当FRR发布新版本后，SONiC会将其同步到[SONiC的FRR实现仓库：sonic-"
"frr][SONiCFRR]中，每一个版本都对应这一个分支，比如`frr/8.2`。"
msgstr ""
"SONiC uses [FRRouting][FRRouting] as the BGP implementation for protocol "
"handling of BGP. FRRouting is an open source routing software that supports "
"multiple routing protocols, including BGP, OSPF, IS-IS, RIP, PIM, LDP, and "
"so on. When a new version of FRR is released, SONiC will synchronize it to "
"[SONiC's FRR implementation repository: sonic-frr][SONiCFRR], and each "
"version corresponds to this branch, such as `frr/8.2`."

#: src/5-2-bgp.md:9
msgid ""
"FRR主要由两个大部分组成，第一个部分是各个协议的实现，这些进程的名字都叫做"
"`*d`，而当它们收到路由更新的通知的时候，就会告诉第二个部分，也就是`zebra`进"
"程，然后`zebra`进程会进行选路，并将最优的路由信息同步到kernel中，其主体结构如"
"下图所示："
msgstr ""
"FRR consists of two main parts, the first part is the implementation of each "
"protocol, these processes are named `*d`, and when they receive notification "
"of routing updates, they tell the second part, which is the `zebra` process, "
"and then the `zebra` process will make the route selection and synchronize "
"the optimal routing information to the kernel, the main structure of which "
"is shown in the following figure The main structure is as follows"

#: src/5-2-bgp.md:11
msgid ""
"```\n"
"+----+  +----+  +-----+  +----+  +----+  +----+  +-----+\n"
"|bgpd|  |ripd|  |ospfd|  |ldpd|  |pbrd|  |pimd|  |.....|\n"
"+----+  +----+  +-----+  +----+  +----+  +----+  +-----+\n"
"     |       |        |       |       |       |        |\n"
"+----v-------v--------v-------v-------v-------v--------v\n"
"|                                                      |\n"
"|                         Zebra                        |\n"
"|                                                      |\n"
"+------------------------------------------------------+\n"
"       |                    |                   |\n"
"       |                    |                   |\n"
"+------v------+   +---------v--------+   +------v------+\n"
"|             |   |                  |   |             |\n"
"| *NIX Kernel |   | Remote dataplane |   | ........... |\n"
"|             |   |                  |   |             |\n"
"+-------------+   +------------------+   +-------------+\n"
"```"
msgstr ""
"```\n"
"+----+  +----+  +-----+  +----+  +----+  +----+  +-----+\n"
"|bgpd|  |ripd|  |ospfd|  |ldpd|  |pbrd|  |pimd|  |.....|\n"
"+----+  +----+  +-----+  +----+  +----+  +----+  +-----+\n"
"     |       |        |       |       |       |        |\n"
"+----v-------v--------v-------v-------v-------v--------v\n"
"|                                                      |\n"
"|                         Zebra                        |\n"
"|                                                      |\n"
"+------------------------------------------------------+\n"
"       |                    |                   |\n"
"       |                    |                   |\n"
"+------v------+   +---------v--------+   +------v------+\n"
"|             |   |                  |   |             |\n"
"| *NIX Kernel |   | Remote dataplane |   | ........... |\n"
"|             |   |                  |   |             |\n"
"+-------------+   +------------------+   +-------------+\n"
"```"

#: src/5-2-bgp.md:30
msgid ""
"在SONiC中，这些FRR的进程都跑在`bgp`的容器中。另外，为了将FRR和Redis连接起来，"
"SONiC在`bgp`容器中还会运行一个叫做`fpgsyncd`的进程（Forwarding Plane Manager "
"syncd），它的主要功能是监听kernel的路由更新，然后将其同步到APP_DB中。但是因为"
"这个进程不是FRR的一部分，所以它的实现被放在了[sonic-swss][SONiCSWSS]仓库中。"
msgstr ""
"In SONiC, these FRR processes are running in the `bgp` container. Also, to "
"connect FRR to Redis, SONiC runs a process called `fpgsyncd` in the `bgp` "
"container (Forwarding Plane Manager syncd), whose main function is to listen "
"to the kernel for routing updates and then synchronize them to APP_DB. "
"However, since this process is not part of FRR, its implementation is placed "
"in the [sonic-swss][SONiCSWSS] repository."

#: src/5-2-bgp.md:34
msgid ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [Github repo: sonic-swss][SONiCSWSS]\n"
"3. [Github repo: sonic-frr][SONiCFRR]\n"
"4. [RFC 4271: A Border Gateway Protocol 4 (BGP-4)][BGP]\n"
"5. [FRRouting][FRRouting]"
msgstr ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [Github repo: sonic-swss][SONiCSWSS]\n"
"3. [Github repo: sonic-frr][SONiCFRR]\n"
"4. [RFC 4271: A Border Gateway Protocol 4 (BGP-4)][BGP]\n"
"5. [FRRouting][FRRouting]"

#: src/5-2-1-bgp-command-impl.md:1
msgid "# BGP命令实现"
msgstr "# BGP command implementation"

#: src/5-2-1-bgp-command-impl.md:3
msgid ""
"由于BGP是使用FRR来实现的，所以自然而然的，`show`命令会将直接请求转发给FRR的"
"`vtysh`，核心代码如下："
msgstr ""
"Since BGP is implemented using FRR, it is natural that the `show` command "
"will forward direct requests to `vtysh` in FRR, with the following core code:"

#: src/5-2-1-bgp-command-impl.md:5
msgid ""
"```python\n"
"# file: src/sonic-utilities/show/bgp_frr_v4.py\n"
"# 'summary' subcommand (\"show ip bgp summary\")\n"
"@bgp.command()\n"
"@multi_asic_util.multi_asic_click_options\n"
"def summary(namespace, display):\n"
"    bgp_summary = bgp_util.get_bgp_summary_from_all_bgp_instances(\n"
"        constants.IPV4, namespace, display)\n"
"    bgp_util.display_bgp_summary(bgp_summary=bgp_summary, af=constants."
"IPV4)\n"
"\n"
"# file: src/sonic-utilities/utilities_common/bgp_util.py\n"
"def get_bgp_summary_from_all_bgp_instances(af, namespace, display):\n"
"    # IPv6 case is omitted here for simplicity\n"
"    vtysh_cmd = \"show ip bgp summary json\"\n"
"    \n"
"    for ns in device.get_ns_list_based_on_options():\n"
"        cmd_output = run_bgp_show_command(vtysh_cmd, ns)\n"
"\n"
"def run_bgp_command(vtysh_cmd, bgp_namespace=multi_asic.DEFAULT_NAMESPACE, "
"vtysh_shell_cmd=constants.VTYSH_COMMAND):\n"
"    cmd = ['sudo', vtysh_shell_cmd] + bgp_instance_id + ['-c', vtysh_cmd]\n"
"    output, ret = clicommon.run_command(cmd, return_cmd=True)\n"
"```"
msgstr ""
"```python\n"
"# file: src/sonic-utilities/show/bgp_frr_v4.py\n"
"# 'summary' subcommand (\"show ip bgp summary\")\n"
"@bgp.command()\n"
"@multi_asic_util.multi_asic_click_options\n"
"def summary(namespace, display):\n"
"    bgp_summary = bgp_util.get_bgp_summary_from_all_bgp_instances(\n"
"        constants.IPV4, namespace, display)\n"
"    bgp_util.display_bgp_summary(bgp_summary=bgp_summary, af=constants."
"IPV4)\n"
"\n"
"# file: src/sonic-utilities/utilities_common/bgp_util.py\n"
"def get_bgp_summary_from_all_bgp_instances(af, namespace, display):\n"
"    # IPv6 case is omitted here for simplicity\n"
"    vtysh_cmd = \"show ip bgp summary json\"\n"
"    \n"
"    for ns in device.get_ns_list_based_on_options():\n"
"        cmd_output = run_bgp_show_command(vtysh_cmd, ns)\n"
"\n"
"def run_bgp_command(vtysh_cmd, bgp_namespace=multi_asic.DEFAULT_NAMESPACE, "
"vtysh_shell_cmd=constants.VTYSH_COMMAND):\n"
"    cmd = ['sudo', vtysh_shell_cmd] + bgp_instance_id + ['-c', vtysh_cmd]\n"
"    output, ret = clicommon.run_command(cmd, return_cmd=True)\n"
"```"

#: src/5-2-1-bgp-command-impl.md:28
msgid "这里，我们也可以通过直接运行`vtysh`来进行验证："
msgstr "Here, we can also verify by running `vtysh` directly as follows:"

#: src/5-2-1-bgp-command-impl.md:30
msgid ""
"```bash\n"
"root@7260cx3:/etc/sonic/frr# which vtysh\n"
"/usr/bin/vtysh\n"
"\n"
"root@7260cx3:/etc/sonic/frr# vtysh\n"
"\n"
"Hello, this is FRRouting (version 7.5.1-sonic).\n"
"Copyright 1996-2005 Kunihiro Ishiguro, et al.\n"
"\n"
"7260cx3# show ip bgp summary\n"
"\n"
"IPv4 Unicast Summary:\n"
"BGP router identifier 10.1.0.32, local AS number 65100 vrf-id 0\n"
"BGP table version 6410\n"
"RIB entries 12809, using 2402 KiB of memory\n"
"Peers 4, using 85 KiB of memory\n"
"Peer groups 4, using 256 bytes of memory\n"
"\n"
"Neighbor        V         AS   MsgRcvd   MsgSent   TblVer  InQ OutQ  Up/Down "
"State/PfxRcd   PfxSnt\n"
"10.0.0.57       4      64600      3702      3704        0    0    0 "
"08:15:03         6401     6406\n"
"10.0.0.59       4      64600      3702      3704        0    0    0 "
"08:15:03         6401     6406\n"
"10.0.0.61       4      64600      3705      3702        0    0    0 "
"08:15:03         6401     6406\n"
"10.0.0.63       4      64600      3702      3702        0    0    0 "
"08:15:03         6401     6406\n"
"\n"
"Total number of neighbors 4\n"
"```"
msgstr ""
"```bash\n"
"root@7260cx3:/etc/sonic/frr# which vtysh\n"
"/usr/bin/vtysh\n"
"\n"
"root@7260cx3:/etc/sonic/frr# vtysh\n"
"\n"
"Hello, this is FRRouting (version 7.5.1-sonic).\n"
"Copyright 1996-2005 Kunihiro Ishiguro, et al.\n"
"\n"
"7260cx3# show ip bgp summary\n"
"\n"
"IPv4 Unicast Summary:\n"
"BGP router identifier 10.1.0.32, local AS number 65100 vrf-id 0\n"
"BGP table version 6410\n"
"RIB entries 12809, using 2402 KiB of memory\n"
"Peers 4, using 85 KiB of memory\n"
"Peer groups 4, using 256 bytes of memory\n"
"\n"
"Neighbor        V         AS   MsgRcvd   MsgSent   TblVer  InQ OutQ  Up/Down "
"State/PfxRcd   PfxSnt\n"
"10.0.0.57       4      64600      3702      3704        0    0    0 "
"08:15:03         6401     6406\n"
"10.0.0.59       4      64600      3702      3704        0    0    0 "
"08:15:03         6401     6406\n"
"10.0.0.61       4      64600      3705      3702        0    0    0 "
"08:15:03         6401     6406\n"
"10.0.0.63       4      64600      3702      3702        0    0    0 "
"08:15:03         6401     6406\n"
"\n"
"Total number of neighbors 4\n"
"```"

#: src/5-2-1-bgp-command-impl.md:57
msgid "而`config`命令则是通过直接操作CONFIG_DB来实现的，核心代码如下："
msgstr ""
"The `config` command, on the other hand, is implemented by directly "
"manipulating CONFIG_DB with the following core code:"

#: src/5-2-1-bgp-command-impl.md:59
msgid ""
"```python\n"
"# file: src/sonic-utilities/config/main.py\n"
"\n"
"@bgp.group(cls=clicommon.AbbreviationGroup)\n"
"def remove():\n"
"    \"Remove BGP neighbor configuration from the device\"\n"
"    pass\n"
"\n"
"@remove.command('neighbor')\n"
"@click.argument('neighbor_ip_or_hostname', "
"metavar='<neighbor_ip_or_hostname>', required=True)\n"
"def remove_neighbor(neighbor_ip_or_hostname):\n"
"    \"\"\"Deletes BGP neighbor configuration of given hostname or ip from "
"devices\n"
"       User can specify either internal or external BGP neighbor to remove\n"
"    \"\"\"\n"
"    namespaces = [DEFAULT_NAMESPACE]\n"
"    removed_neighbor = False\n"
"    ...\n"
"\n"
"    # Connect to CONFIG_DB in linux host (in case of single ASIC) or "
"CONFIG_DB in all the\n"
"    # namespaces (in case of multi ASIC) and do the sepcified \"action\" on "
"the BGP neighbor(s)\n"
"    for namespace in namespaces:\n"
"        config_db = ConfigDBConnector(use_unix_socket_path=True, "
"namespace=namespace)\n"
"        config_db.connect()\n"
"        if _remove_bgp_neighbor_config(config_db, neighbor_ip_or_hostname):\n"
"            removed_neighbor = True\n"
"    ...\n"
"```"
msgstr ""
"```python\n"
"# file: src/sonic-utilities/config/main.py\n"
"\n"
"@bgp.group(cls=clicommon.AbbreviationGroup)\n"
"def remove():\n"
"    \"Remove BGP neighbor configuration from the device\"\n"
"    pass\n"
"\n"
"@remove.command('neighbor')\n"
"@click.argument('neighbor_ip_or_hostname', "
"metavar='<neighbor_ip_or_hostname>', required=True)\n"
"def remove_neighbor(neighbor_ip_or_hostname):\n"
"    \"\"\"Deletes BGP neighbor configuration of given hostname or ip from "
"devices\n"
"       User can specify either internal or external BGP neighbor to remove\n"
"    \"\"\"\n"
"    namespaces = [DEFAULT_NAMESPACE]\n"
"    removed_neighbor = False\n"
"    ...\n"
"\n"
"    # Connect to CONFIG_DB in linux host (in case of single ASIC) or "
"CONFIG_DB in all the\n"
"    # namespaces (in case of multi ASIC) and do the sepcified \"action\" on "
"the BGP neighbor(s)\n"
"    for namespace in namespaces:\n"
"        config_db = ConfigDBConnector(use_unix_socket_path=True, "
"namespace=namespace)\n"
"        config_db.connect()\n"
"        if _remove_bgp_neighbor_config(config_db, neighbor_ip_or_hostname):\n"
"            removed_neighbor = True\n"
"    ...\n"
"```"

#: src/5-2-1-bgp-command-impl.md:89
msgid ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [Github repo: sonic-frr][SONiCFRR]\n"
"3. [Github repo: sonic-utilities][SONiCUtil]\n"
"4. [RFC 4271: A Border Gateway Protocol 4 (BGP-4)][BGP]\n"
"5. [FRRouting][FRRouting]"
msgstr ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [Github repo: sonic-frr][SONiCFRR]\n"
"3. [Github repo: sonic-utilities][SONiCUtil]\n"
"4. [RFC 4271: A Border Gateway Protocol 4 (BGP-4)][BGP]\n"
"5. [FRRouting][FRRouting]"

#: src/5-2-2-bgp-route-update-workflow.md:1
msgid "# BGP路由变更下发"
msgstr "# BGP route change distribution"

#: src/5-2-2-bgp-route-update-workflow.md:3
msgid ""
"路由变更几乎是SONiC中最重要的工作流，它的整个流程从`bgpd`进程开始，到最终通过"
"SAI到达ASIC芯片，中间参与的进程较多，流程也较为复杂，但是弄清楚之后，我们就可"
"以很好的理解SONiC的设计思想，并且举一反三的理解其他配置下发的工作流了。所以这"
"一节，我们就一起来深入的分析一下它的整体流程。"
msgstr ""
"Routing changes are almost the most important workflow in SONiC. The whole "
"process starts from the `bgpd` process to the final arrival of the ASIC chip "
"through the SAI, and there are more processes involved in the middle and the "
"process is more complicated. So this section, we will come together to "
"analyze its overall process in depth."

#: src/5-2-2-bgp-route-update-workflow.md:5
msgid ""
"为了方便我们理解和从代码层面来展示，我们把这个流程分成两个大块来介绍，分别是"
"FRR是如何处理路由变化的，和SONiC的路由变更工作流以及它是如何与FRR进行整合的。"
msgstr ""
"To facilitate our understanding and to show it from the code level, we "
"present this flow in two big chunks, how FRR handles route changes, and "
"SONiC's route change workflow and how it is integrated with FRR."

#: src/5-2-2-bgp-route-update-workflow.md:7
msgid "## FRR处理路由变更"
msgstr "## FRR handles route changes"

#: src/5-2-2-bgp-route-update-workflow.md:9
msgid ""
"```mermaid\n"
"sequenceDiagram\n"
"    autonumber\n"
"    participant N as 邻居节点\n"
"    box purple bgp容器\n"
"    participant B as bgpd\n"
"    participant ZH as zebra<br/>（请求处理线程）\n"
"    participant ZF as zebra<br/>（路由处理线程）\n"
"    participant ZD as zebra<br/>（数据平面处理线程）\n"
"    participant ZFPM as zebra<br/>（FPM转发线程）\n"
"    participant FPM as fpmsyncd\n"
"    end\n"
"    participant K as Linux Kernel\n"
"\n"
"    N->>B: 建立BGP会话，<br/>发送路由变更\n"
"    B->>B: 选路，变更本地路由表（RIB）\n"
"    alt 如果路由发生变化\n"
"    B->>N: 通知其他邻居节点路由变化\n"
"    end\n"
"    B->>ZH: 通过zlient本地Socket<br/>通知Zebra更新路由表\n"
"    ZH->>ZH: 接受bgpd发送的请求\n"
"    ZH->>ZF: 将路由请求放入<br/>路由处理线程的队列中\n"
"    ZF->>ZF: 更新本地路由表（RIB）\n"
"    ZF->>ZD: 将路由表更新请求放入<br/>数据平面处理线程<br/>的消息队列中\n"
"    ZF->>ZFPM: 请求FPM处理线程转发路由变更\n"
"    ZFPM->>FPM: 通过FPM协议通知<br/>fpmsyncd下发<br/>路由变更\n"
"    ZD->>K: 发送Netlink消息更新内核路由表\n"
"```"
msgstr ""
"```mermaid\n"
"sequenceDiagram\n"
"    autonumber\n"
"    participant N as 邻居节点\n"
"    box purple bgp容器\n"
"    participant B as bgpd\n"
"    participant ZH as zebra<br/>（请求处理线程）\n"
"    participant ZF as zebra<br/>（路由处理线程）\n"
"    participant ZD as zebra<br/>（数据平面处理线程）\n"
"    participant ZFPM as zebra<br/>（FPM转发线程）\n"
"    participant FPM as fpmsyncd\n"
"    end\n"
"    participant K as Linux Kernel\n"
"\n"
"    N->>B: 建立BGP会话，<br/>发送路由变更\n"
"    B->>B: 选路，变更本地路由表（RIB）\n"
"    alt 如果路由发生变化\n"
"    B->>N: 通知其他邻居节点路由变化\n"
"    end\n"
"    B->>ZH: 通过zlient本地Socket<br/>通知Zebra更新路由表\n"
"    ZH->>ZH: 接受bgpd发送的请求\n"
"    ZH->>ZF: 将路由请求放入<br/>路由处理线程的队列中\n"
"    ZF->>ZF: 更新本地路由表（RIB）\n"
"    ZF->>ZD: 将路由表更新请求放入<br/>数据平面处理线程<br/>的消息队列中\n"
"    ZF->>ZFPM: 请求FPM处理线程转发路由变更\n"
"    ZFPM->>FPM: 通过FPM协议通知<br/>fpmsyncd下发<br/>路由变更\n"
"    ZD->>K: 发送Netlink消息更新内核路由表\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:38
msgid ""
"```admonish note\n"
"关于FRR的实现，这里更多的是从代码的角度来阐述其工作流的过程，而不是其对BGP的"
"实现细节，如果想要了解FRR的BGP实现细节，可以参考[官方文档](https://docs."
"frrouting.org/en/latest/bgp.html)。\n"
"```"
msgstr ""
"```admonish note\n"
"关于FRR的实现，这里更多的是从代码的角度来阐述其工作流的过程，而不是其对BGP的"
"实现细节，如果想要了解FRR的BGP实现细节，可以参考[官方文档](https://docs."
"frrouting.org/en/latest/bgp.html)。\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:42
msgid "### bgpd处理路由变更"
msgstr "### bgpd handles route changes"

#: src/5-2-2-bgp-route-update-workflow.md:44
msgid ""
"`bgpd`是FRR中专门用来处理BGP会话的进程，它会开放TCP 179端口与邻居节点建立BGP"
"连接，并处理路由表的更新请求。当路由发生变化后，FRR也会通过它来通知其他邻居节"
"点。"
msgstr ""
"`bgpd` is a process in the FRR dedicated to handling BGP sessions. It opens "
"TCP port 179 to establish BGP connections with neighboring nodes and handles "
"routing table update requests. It is also used by FRR to notify other "
"neighboring nodes when a route has changed."

#: src/5-2-2-bgp-route-update-workflow.md:46
msgid ""
"请求来到`bgpd`之后，它会首先来到它的io线程：`bgp_io`。顾名思义，`bgpd`中的网"
"络读写工作都是在这个线程上完成的："
msgstr ""
"After a request comes to `bgpd`, it first comes to its io thread: `bgp_io`. "
"As the name implies, the network reads and writes in `bgpd` are done on this "
"thread: `bgp_io`:"

#: src/5-2-2-bgp-route-update-workflow.md:48
msgid ""
"```c\n"
"// File: src/sonic-frr/frr/bgpd/bgp_io.c\n"
"static int bgp_process_reads(struct thread *thread)\n"
"{\n"
"    ...\n"
"\n"
"    while (more) {\n"
"        // Read packets here\n"
"        ...\n"
"  \n"
"        // If we have more than 1 complete packet, mark it and process it "
"later.\n"
"        if (ringbuf_remain(ibw) >= pktsize) {\n"
"            ...\n"
"            added_pkt = true;\n"
"        } else break;\n"
"    }\n"
"    ...\n"
"\n"
"    if (added_pkt)\n"
"        thread_add_event(bm->master, bgp_process_packet, peer, 0, &peer-"
">t_process_packet);\n"
"\n"
"    return 0;\n"
"}\n"
"```"
msgstr ""
"```c\n"
"// File: src/sonic-frr/frr/bgpd/bgp_io.c\n"
"static int bgp_process_reads(struct thread *thread)\n"
"{\n"
"    ...\n"
"\n"
"    while (more) {\n"
"        // Read packets here\n"
"        ...\n"
"  \n"
"        // If we have more than 1 complete packet, mark it and process it "
"later.\n"
"        if (ringbuf_remain(ibw) >= pktsize) {\n"
"            ...\n"
"            added_pkt = true;\n"
"        } else break;\n"
"    }\n"
"    ...\n"
"\n"
"    if (added_pkt)\n"
"        thread_add_event(bm->master, bgp_process_packet, peer, 0, &peer-"
">t_process_packet);\n"
"\n"
"    return 0;\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:73
msgid ""
"当数据包读完后，`bgpd`会将其发送到主线程进行路由处理。在这里，`bgpd`会根据数"
"据包的类型进行分发，其中路由更新的请求会交给`bpg_update_receive`来进行解析："
msgstr ""
"When the packet has been read, `bgpd` sends it to the main thread for "
"routing. Here, `bgpd` distributes the packets according to their type, where "
"requests for routing updates are given to `bpg_update_receive` for parsing:"

#: src/5-2-2-bgp-route-update-workflow.md:75
msgid ""
"```c\n"
"// File: src/sonic-frr/frr/bgpd/bgp_packet.c\n"
"int bgp_process_packet(struct thread *thread)\n"
"{\n"
"    ...\n"
"    unsigned int processed = 0;\n"
"    while (processed < rpkt_quanta_old) {\n"
"        uint8_t type = 0;\n"
"        bgp_size_t size;\n"
"        ...\n"
"\n"
"        /* read in the packet length and type */\n"
"        size = stream_getw(peer->curr);\n"
"        type = stream_getc(peer->curr);\n"
"        size -= BGP_HEADER_SIZE;\n"
"\n"
"        switch (type) {\n"
"        case BGP_MSG_OPEN:\n"
"            ...\n"
"            break;\n"
"        case BGP_MSG_UPDATE:\n"
"            ...\n"
"            mprc = bgp_update_receive(peer, size);\n"
"            ...\n"
"            break;\n"
"        ...\n"
"}\n"
"\n"
"// Process BGP UPDATE message for peer.\n"
"static int bgp_update_receive(struct peer *peer, bgp_size_t size)\n"
"{\n"
"    struct stream *s;\n"
"    struct attr attr;\n"
"    struct bgp_nlri nlris[NLRI_TYPE_MAX];\n"
"    ...\n"
"\n"
"    // Parse attributes and NLRI\n"
"    memset(&attr, 0, sizeof(struct attr));\n"
"    attr.label_index = BGP_INVALID_LABEL_INDEX;\n"
"    attr.label = MPLS_INVALID_LABEL;\n"
"    ...\n"
"\n"
"    memset(&nlris, 0, sizeof(nlris));\n"
"    ...\n"
"\n"
"    if ((!update_len && !withdraw_len && nlris[NLRI_MP_UPDATE].length == 0)\n"
"        || (attr_parse_ret == BGP_ATTR_PARSE_EOR)) {\n"
"        // More parsing here\n"
"        ...\n"
"\n"
"        if (afi && peer->afc[afi][safi]) {\n"
"            struct vrf *vrf = vrf_lookup_by_id(peer->bgp->vrf_id);\n"
"\n"
"            /* End-of-RIB received */\n"
"            if (!CHECK_FLAG(peer->af_sflags[afi][safi], "
"PEER_STATUS_EOR_RECEIVED)) {\n"
"                ...\n"
"                if (gr_info->eor_required == gr_info->eor_received) {\n"
"                    ...\n"
"                    /* Best path selection */\n"
"                    if (bgp_best_path_select_defer( peer->bgp, afi, safi) < "
"0)\n"
"                        return BGP_Stop;\n"
"                }\n"
"            }\n"
"            ...\n"
"        }\n"
"    }\n"
"    ...\n"
"\n"
"    return Receive_UPDATE_message;\n"
"}\n"
"```"
msgstr ""
"```c\n"
"// File: src/sonic-frr/frr/bgpd/bgp_packet.c\n"
"int bgp_process_packet(struct thread *thread)\n"
"{\n"
"    ...\n"
"    unsigned int processed = 0;\n"
"    while (processed < rpkt_quanta_old) {\n"
"        uint8_t type = 0;\n"
"        bgp_size_t size;\n"
"        ...\n"
"\n"
"        /* read in the packet length and type */\n"
"        size = stream_getw(peer->curr);\n"
"        type = stream_getc(peer->curr);\n"
"        size -= BGP_HEADER_SIZE;\n"
"\n"
"        switch (type) {\n"
"        case BGP_MSG_OPEN:\n"
"            ...\n"
"            break;\n"
"        case BGP_MSG_UPDATE:\n"
"            ...\n"
"            mprc = bgp_update_receive(peer, size);\n"
"            ...\n"
"            break;\n"
"        ...\n"
"}\n"
"\n"
"// Process BGP UPDATE message for peer.\n"
"static int bgp_update_receive(struct peer *peer, bgp_size_t size)\n"
"{\n"
"    struct stream *s;\n"
"    struct attr attr;\n"
"    struct bgp_nlri nlris[NLRI_TYPE_MAX];\n"
"    ...\n"
"\n"
"    // Parse attributes and NLRI\n"
"    memset(&attr, 0, sizeof(struct attr));\n"
"    attr.label_index = BGP_INVALID_LABEL_INDEX;\n"
"    attr.label = MPLS_INVALID_LABEL;\n"
"    ...\n"
"\n"
"    memset(&nlris, 0, sizeof(nlris));\n"
"    ...\n"
"\n"
"    if ((!update_len && !withdraw_len && nlris[NLRI_MP_UPDATE].length == 0)\n"
"        || (attr_parse_ret == BGP_ATTR_PARSE_EOR)) {\n"
"        // More parsing here\n"
"        ...\n"
"\n"
"        if (afi && peer->afc[afi][safi]) {\n"
"            struct vrf *vrf = vrf_lookup_by_id(peer->bgp->vrf_id);\n"
"\n"
"            /* End-of-RIB received */\n"
"            if (!CHECK_FLAG(peer->af_sflags[afi][safi], "
"PEER_STATUS_EOR_RECEIVED)) {\n"
"                ...\n"
"                if (gr_info->eor_required == gr_info->eor_received) {\n"
"                    ...\n"
"                    /* Best path selection */\n"
"                    if (bgp_best_path_select_defer( peer->bgp, afi, safi) < "
"0)\n"
"                        return BGP_Stop;\n"
"                }\n"
"            }\n"
"            ...\n"
"        }\n"
"    }\n"
"    ...\n"
"\n"
"    return Receive_UPDATE_message;\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:147
msgid ""
"然后，`bgpd`会开始检查是否出现更优的路径，并更新自己的本地路由表（RIB，"
"Routing Information Base）："
msgstr ""
"Then, `bgpd` will start checking if a better path appears and update its own "
"local routing table (RIB, Routing Information Base)::"

#: src/5-2-2-bgp-route-update-workflow.md:149
msgid ""
"```c\n"
"// File: src/sonic-frr/frr/bgpd/bgp_route.c\n"
"/* Process the routes with the flag BGP_NODE_SELECT_DEFER set */\n"
"int bgp_best_path_select_defer(struct bgp *bgp, afi_t afi, safi_t safi)\n"
"{\n"
"    struct bgp_dest *dest;\n"
"    int cnt = 0;\n"
"    struct afi_safi_info *thread_info;\n"
"    ...\n"
"\n"
"    /* Process the route list */\n"
"    for (dest = bgp_table_top(bgp->rib[afi][safi]);\n"
"         dest && bgp->gr_info[afi][safi].gr_deferred != 0;\n"
"         dest = bgp_route_next(dest))\n"
"    {\n"
"        ...\n"
"        bgp_process_main_one(bgp, dest, afi, safi);\n"
"        ...\n"
"    }\n"
"    ...\n"
"\n"
"    return 0;\n"
"}\n"
"\n"
"static void bgp_process_main_one(struct bgp *bgp, struct bgp_dest *dest, "
"afi_t afi, safi_t safi)\n"
"{\n"
"    struct bgp_path_info *new_select;\n"
"    struct bgp_path_info *old_select;\n"
"    struct bgp_path_info_pair old_and_new;\n"
"    ...\n"
"\n"
"    const struct prefix *p = bgp_dest_get_prefix(dest);\n"
"    ...\n"
"\n"
"    /* Best path selection. */\n"
"    bgp_best_selection(bgp, dest, &bgp->maxpaths[afi][safi], &old_and_new, "
"afi, safi);\n"
"    old_select = old_and_new.old;\n"
"    new_select = old_and_new.new;\n"
"    ...\n"
"\n"
"    /* FIB update. */\n"
"    if (bgp_fibupd_safi(safi) && (bgp->inst_type != BGP_INSTANCE_TYPE_VIEW)\n"
"        && !bgp_option_check(BGP_OPT_NO_FIB)) {\n"
"\n"
"        if (new_select && new_select->type == ZEBRA_ROUTE_BGP\n"
"            && (new_select->sub_type == BGP_ROUTE_NORMAL\n"
"            || new_select->sub_type == BGP_ROUTE_AGGREGATE\n"
"            || new_select->sub_type == BGP_ROUTE_IMPORTED)) {\n"
"            ...\n"
"\n"
"            if (old_select && is_route_parent_evpn(old_select))\n"
"                bgp_zebra_withdraw(p, old_select, bgp, safi);\n"
"\n"
"            bgp_zebra_announce(dest, p, new_select, bgp, afi, safi);\n"
"        } else {\n"
"            /* Withdraw the route from the kernel. */\n"
"            ...\n"
"        }\n"
"    }\n"
"\n"
"    /* EVPN route injection and clean up */\n"
"    ...\n"
"\n"
"    UNSET_FLAG(dest->flags, BGP_NODE_PROCESS_SCHEDULED);\n"
"    return;\n"
"}\n"
"```"
msgstr ""
"```c\n"
"// File: src/sonic-frr/frr/bgpd/bgp_route.c\n"
"/* Process the routes with the flag BGP_NODE_SELECT_DEFER set */\n"
"int bgp_best_path_select_defer(struct bgp *bgp, afi_t afi, safi_t safi)\n"
"{\n"
"    struct bgp_dest *dest;\n"
"    int cnt = 0;\n"
"    struct afi_safi_info *thread_info;\n"
"    ...\n"
"\n"
"    /* Process the route list */\n"
"    for (dest = bgp_table_top(bgp->rib[afi][safi]);\n"
"         dest && bgp->gr_info[afi][safi].gr_deferred != 0;\n"
"         dest = bgp_route_next(dest))\n"
"    {\n"
"        ...\n"
"        bgp_process_main_one(bgp, dest, afi, safi);\n"
"        ...\n"
"    }\n"
"    ...\n"
"\n"
"    return 0;\n"
"}\n"
"\n"
"static void bgp_process_main_one(struct bgp *bgp, struct bgp_dest *dest, "
"afi_t afi, safi_t safi)\n"
"{\n"
"    struct bgp_path_info *new_select;\n"
"    struct bgp_path_info *old_select;\n"
"    struct bgp_path_info_pair old_and_new;\n"
"    ...\n"
"\n"
"    const struct prefix *p = bgp_dest_get_prefix(dest);\n"
"    ...\n"
"\n"
"    /* Best path selection. */\n"
"    bgp_best_selection(bgp, dest, &bgp->maxpaths[afi][safi], &old_and_new, "
"afi, safi);\n"
"    old_select = old_and_new.old;\n"
"    new_select = old_and_new.new;\n"
"    ...\n"
"\n"
"    /* FIB update. */\n"
"    if (bgp_fibupd_safi(safi) && (bgp->inst_type != BGP_INSTANCE_TYPE_VIEW)\n"
"        && !bgp_option_check(BGP_OPT_NO_FIB)) {\n"
"\n"
"        if (new_select && new_select->type == ZEBRA_ROUTE_BGP\n"
"            && (new_select->sub_type == BGP_ROUTE_NORMAL\n"
"            || new_select->sub_type == BGP_ROUTE_AGGREGATE\n"
"            || new_select->sub_type == BGP_ROUTE_IMPORTED)) {\n"
"            ...\n"
"\n"
"            if (old_select && is_route_parent_evpn(old_select))\n"
"                bgp_zebra_withdraw(p, old_select, bgp, safi);\n"
"\n"
"            bgp_zebra_announce(dest, p, new_select, bgp, afi, safi);\n"
"        } else {\n"
"            /* Withdraw the route from the kernel. */\n"
"            ...\n"
"        }\n"
"    }\n"
"\n"
"    /* EVPN route injection and clean up */\n"
"    ...\n"
"\n"
"    UNSET_FLAG(dest->flags, BGP_NODE_PROCESS_SCHEDULED);\n"
"    return;\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:217
msgid "最后，`bgp_zebra_announce`会通过`zclient`通知`zebra`更新内核路由表。"
msgstr ""
"Finally, `bgp_zebra_announce` will notify `zebra` via `zclient` to update "
"the kernel routing table."

#: src/5-2-2-bgp-route-update-workflow.md:219
msgid ""
"```c\n"
"// File: src/sonic-frr/frr/bgpd/bgp_zebra.c\n"
"void bgp_zebra_announce(struct bgp_node *rn, struct prefix *p, struct "
"bgp_path_info *info, struct bgp *bgp, afi_t afi, safi_t safi)\n"
"{\n"
"    ...\n"
"    zclient_route_send(valid_nh_count ? ZEBRA_ROUTE_ADD : "
"ZEBRA_ROUTE_DELETE, zclient, &api);\n"
"}\n"
"```"
msgstr ""
"```c\n"
"// File: src/sonic-frr/frr/bgpd/bgp_zebra.c\n"
"void bgp_zebra_announce(struct bgp_node *rn, struct prefix *p, struct "
"bgp_path_info *info, struct bgp *bgp, afi_t afi, safi_t safi)\n"
"{\n"
"    ...\n"
"    zclient_route_send(valid_nh_count ? ZEBRA_ROUTE_ADD : "
"ZEBRA_ROUTE_DELETE, zclient, &api);\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:228
msgid ""
"`zclient`使用本地socket与`zebra`通信，并且提供一系列的回调函数用于接收`zebra`"
"的通知，核心代码如下："
msgstr ""
"`zclient` uses a local socket to communicate with `zebra` and provides a "
"series of callback functions for receiving notifications from `zebra`, with "
"the following core code:"

#: src/5-2-2-bgp-route-update-workflow.md:230
msgid ""
"```c\n"
"// File: src/sonic-frr/frr/bgpd/bgp_zebra.c\n"
"void bgp_zebra_init(struct thread_master *master, unsigned short instance)\n"
"{\n"
"    zclient_num_connects = 0;\n"
"\n"
"    /* Set default values. */\n"
"    zclient = zclient_new(master, &zclient_options_default);\n"
"    zclient_init(zclient, ZEBRA_ROUTE_BGP, 0, &bgpd_privs);\n"
"    zclient->zebra_connected = bgp_zebra_connected;\n"
"    zclient->router_id_update = bgp_router_id_update;\n"
"    zclient->interface_add = bgp_interface_add;\n"
"    zclient->interface_delete = bgp_interface_delete;\n"
"    zclient->interface_address_add = bgp_interface_address_add;\n"
"    ...\n"
"}\n"
"\n"
"int zclient_socket_connect(struct zclient *zclient)\n"
"{\n"
"    int sock;\n"
"    int ret;\n"
"\n"
"    sock = socket(zclient_addr.ss_family, SOCK_STREAM, 0);\n"
"    ...\n"
"\n"
"    /* Connect to zebra. */\n"
"    ret = connect(sock, (struct sockaddr *)&zclient_addr, "
"zclient_addr_len);\n"
"    ...\n"
"\n"
"    zclient->sock = sock;\n"
"    return sock;\n"
"}\n"
"```"
msgstr ""
"```c\n"
"// File: src/sonic-frr/frr/bgpd/bgp_zebra.c\n"
"void bgp_zebra_init(struct thread_master *master, unsigned short instance)\n"
"{\n"
"    zclient_num_connects = 0;\n"
"\n"
"    /* Set default values. */\n"
"    zclient = zclient_new(master, &zclient_options_default);\n"
"    zclient_init(zclient, ZEBRA_ROUTE_BGP, 0, &bgpd_privs);\n"
"    zclient->zebra_connected = bgp_zebra_connected;\n"
"    zclient->router_id_update = bgp_router_id_update;\n"
"    zclient->interface_add = bgp_interface_add;\n"
"    zclient->interface_delete = bgp_interface_delete;\n"
"    zclient->interface_address_add = bgp_interface_address_add;\n"
"    ...\n"
"}\n"
"\n"
"int zclient_socket_connect(struct zclient *zclient)\n"
"{\n"
"    int sock;\n"
"    int ret;\n"
"\n"
"    sock = socket(zclient_addr.ss_family, SOCK_STREAM, 0);\n"
"    ...\n"
"\n"
"    /* Connect to zebra. */\n"
"    ret = connect(sock, (struct sockaddr *)&zclient_addr, "
"zclient_addr_len);\n"
"    ...\n"
"\n"
"    zclient->sock = sock;\n"
"    return sock;\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:264
msgid ""
"在`bgpd`容器中，我们可以在`/run/frr`目录下找到`zebra`通信使用的socket文件来进"
"行简单的验证："
msgstr ""
"In the `bgpd` container, we can find the socket file used by `zebra` "
"communication in the `/run/frr` directory for a simple verification:"

#: src/5-2-2-bgp-route-update-workflow.md:266
msgid ""
"```bash\n"
"root@7260cx3:/run/frr# ls -l\n"
"total 12\n"
"...\n"
"srwx------ 1 frr frr    0 Jun 16 09:16 zserv.api\n"
"```"
msgstr ""
"```bash\n"
"root@7260cx3:/run/frr# ls -l\n"
"total 12\n"
"...\n"
"srwx------ 1 frr frr    0 Jun 16 09:16 zserv.api\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:273
msgid "### zebra更新路由表"
msgstr "### zebra update routing table"

#: src/5-2-2-bgp-route-update-workflow.md:275
msgid ""
"由于FRR支持的路由协议很多，如果每个路由协议处理进程都单独的对内核进行操作则必"
"然会产生冲突，很难协调合作，所以FRR使用一个单独的进程用于和所有的路由协议处理"
"进程进行沟通，整合好信息之后统一的进行内核的路由表更新，这个进程就是`zebra`。"
msgstr ""
"Since FRR supports many routing protocols, if each routing protocol process "
"operates separately on the kernel, there will be conflicts and it is "
"difficult to coordinate and cooperate."

#: src/5-2-2-bgp-route-update-workflow.md:277
msgid ""
"在`zebra`中，内核的更新发生在一个独立的数据面处理线程中：`dplane_thread`。所"
"有的请求都会通过`zclient`发送给`zebra`，经过处理之后，最后转发给"
"`dplane_thread`来处理，这样路由的处理就是有序的了，也就不会产生冲突了。"
msgstr ""
"In `zebra`, kernel updates happen in a separate data-plane processing "
"thread: `dplane_thread`. All requests are sent to `zebra` via `zclient`, "
"processed and finally forwarded to `dplane_thread` for processing, so that "
"the routing is ordered and no conflicts arise."

#: src/5-2-2-bgp-route-update-workflow.md:279
msgid ""
"`zebra`启动时，会将所有的请求处理函数进行注册，当请求到来时，就可以根据请求的"
"类型调用相应的处理函数了，核心代码如下："
msgstr ""
"When `zebra` is started, all request handling functions will be registered, "
"and when the request arrives, the corresponding handling function can be "
"called according to the type of request, and the core code is as follows:"

#: src/5-2-2-bgp-route-update-workflow.md:281
msgid ""
"```c\n"
"// File: src/sonic-frr/frr/zebra/zapi_msg.c\n"
"void (*zserv_handlers[])(ZAPI_HANDLER_ARGS) = {\n"
"    [ZEBRA_ROUTER_ID_ADD] = zread_router_id_add,\n"
"    [ZEBRA_ROUTER_ID_DELETE] = zread_router_id_delete,\n"
"    [ZEBRA_INTERFACE_ADD] = zread_interface_add,\n"
"    [ZEBRA_INTERFACE_DELETE] = zread_interface_delete,\n"
"    [ZEBRA_ROUTE_ADD] = zread_route_add,\n"
"    [ZEBRA_ROUTE_DELETE] = zread_route_del,\n"
"    [ZEBRA_REDISTRIBUTE_ADD] = zebra_redistribute_add,\n"
"    [ZEBRA_REDISTRIBUTE_DELETE] = zebra_redistribute_delete,\n"
"    ...\n"
"```"
msgstr ""
"```c\n"
"// File: src/sonic-frr/frr/zebra/zapi_msg.c\n"
"void (*zserv_handlers[])(ZAPI_HANDLER_ARGS) = {\n"
"    [ZEBRA_ROUTER_ID_ADD] = zread_router_id_add,\n"
"    [ZEBRA_ROUTER_ID_DELETE] = zread_router_id_delete,\n"
"    [ZEBRA_INTERFACE_ADD] = zread_interface_add,\n"
"    [ZEBRA_INTERFACE_DELETE] = zread_interface_delete,\n"
"    [ZEBRA_ROUTE_ADD] = zread_route_add,\n"
"    [ZEBRA_ROUTE_DELETE] = zread_route_del,\n"
"    [ZEBRA_REDISTRIBUTE_ADD] = zebra_redistribute_add,\n"
"    [ZEBRA_REDISTRIBUTE_DELETE] = zebra_redistribute_delete,\n"
"    ...\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:295
msgid ""
"我们这里拿添加路由`zread_route_add`作为例子，来继续分析后续的流程。从以下代码"
"我们可以看到，当新的路由到来后，`zebra`会开始查看并更新自己内部的路由表："
msgstr ""
"Let's take adding a route `zread_route_add` as an example here to continue "
"the analysis of the subsequent process. As we can see from the following "
"code, `zebra` will start looking at and updating its own internal routing "
"table when a new route arrives:"

#: src/5-2-2-bgp-route-update-workflow.md:297
msgid ""
"```c\n"
"// File: src/sonic-frr/frr/zebra/zapi_msg.c\n"
"static void zread_route_add(ZAPI_HANDLER_ARGS)\n"
"{\n"
"    struct stream *s;\n"
"    struct route_entry *re;\n"
"    struct nexthop_group *ng = NULL;\n"
"    struct nhg_hash_entry nhe;\n"
"    ...\n"
"\n"
"    // Decode zclient request\n"
"    s = msg;\n"
"    if (zapi_route_decode(s, &api) < 0) {\n"
"        return;\n"
"    }\n"
"    ...\n"
"\n"
"    // Allocate new route entry.\n"
"    re = XCALLOC(MTYPE_RE, sizeof(struct route_entry));\n"
"    re->type = api.type;\n"
"    re->instance = api.instance;\n"
"    ...\n"
" \n"
"    // Init nexthop entry, if we have an id, then add route.\n"
"    if (!re->nhe_id) {\n"
"        zebra_nhe_init(&nhe, afi, ng->nexthop);\n"
"        nhe.nhg.nexthop = ng->nexthop;\n"
"        nhe.backup_info = bnhg;\n"
"    }\n"
"    ret = rib_add_multipath_nhe(afi, api.safi, &api.prefix, src_p, re, "
"&nhe);\n"
"\n"
"    // Update stats. IPv6 is omitted here for simplicity.\n"
"    if (ret > 0) client->v4_route_add_cnt++;\n"
"    else if (ret < 0) client->v4_route_upd8_cnt++;\n"
"}\n"
"\n"
"// File: src/sonic-frr/frr/zebra/zebra_rib.c\n"
"int rib_add_multipath_nhe(afi_t afi, safi_t safi, struct prefix *p,\n"
"              struct prefix_ipv6 *src_p, struct route_entry *re,\n"
"              struct nhg_hash_entry *re_nhe)\n"
"{\n"
"    struct nhg_hash_entry *nhe = NULL;\n"
"    struct route_table *table;\n"
"    struct route_node *rn;\n"
"    int ret = 0;\n"
"    ...\n"
"\n"
"    /* Find table and nexthop entry */\n"
"    table = zebra_vrf_get_table_with_table_id(afi, safi, re->vrf_id, re-"
">table);\n"
"    if (re->nhe_id > 0) nhe = zebra_nhg_lookup_id(re->nhe_id);\n"
"    else nhe = zebra_nhg_rib_find_nhe(re_nhe, afi);\n"
"\n"
"    /* Attach the re to the nhe's nexthop group. */\n"
"    route_entry_update_nhe(re, nhe);\n"
"\n"
"    /* Make it sure prefixlen is applied to the prefix. */\n"
"    /* Set default distance by route type. */\n"
"    ...\n"
"\n"
"    /* Lookup route node.*/\n"
"    rn = srcdest_rnode_get(table, p, src_p);\n"
"    ...\n"
"\n"
"    /* If this route is kernel/connected route, notify the dataplane to "
"update kernel route table. */\n"
"    if (RIB_SYSTEM_ROUTE(re)) {\n"
"        dplane_sys_route_add(rn, re);\n"
"    }\n"
"\n"
"    /* Link new re to node. */\n"
"    SET_FLAG(re->status, ROUTE_ENTRY_CHANGED);\n"
"    rib_addnode(rn, re, 1);\n"
"\n"
"    /* Clean up */\n"
"    ...\n"
"    return ret;\n"
"}\n"
"```"
msgstr ""
"```c\n"
"// File: src/sonic-frr/frr/zebra/zapi_msg.c\n"
"static void zread_route_add(ZAPI_HANDLER_ARGS)\n"
"{\n"
"    struct stream *s;\n"
"    struct route_entry *re;\n"
"    struct nexthop_group *ng = NULL;\n"
"    struct nhg_hash_entry nhe;\n"
"    ...\n"
"\n"
"    // Decode zclient request\n"
"    s = msg;\n"
"    if (zapi_route_decode(s, &api) < 0) {\n"
"        return;\n"
"    }\n"
"    ...\n"
"\n"
"    // Allocate new route entry.\n"
"    re = XCALLOC(MTYPE_RE, sizeof(struct route_entry));\n"
"    re->type = api.type;\n"
"    re->instance = api.instance;\n"
"    ...\n"
" \n"
"    // Init nexthop entry, if we have an id, then add route.\n"
"    if (!re->nhe_id) {\n"
"        zebra_nhe_init(&nhe, afi, ng->nexthop);\n"
"        nhe.nhg.nexthop = ng->nexthop;\n"
"        nhe.backup_info = bnhg;\n"
"    }\n"
"    ret = rib_add_multipath_nhe(afi, api.safi, &api.prefix, src_p, re, "
"&nhe);\n"
"\n"
"    // Update stats. IPv6 is omitted here for simplicity.\n"
"    if (ret > 0) client->v4_route_add_cnt++;\n"
"    else if (ret < 0) client->v4_route_upd8_cnt++;\n"
"}\n"
"\n"
"// File: src/sonic-frr/frr/zebra/zebra_rib.c\n"
"int rib_add_multipath_nhe(afi_t afi, safi_t safi, struct prefix *p,\n"
"              struct prefix_ipv6 *src_p, struct route_entry *re,\n"
"              struct nhg_hash_entry *re_nhe)\n"
"{\n"
"    struct nhg_hash_entry *nhe = NULL;\n"
"    struct route_table *table;\n"
"    struct route_node *rn;\n"
"    int ret = 0;\n"
"    ...\n"
"\n"
"    /* Find table and nexthop entry */\n"
"    table = zebra_vrf_get_table_with_table_id(afi, safi, re->vrf_id, re-"
">table);\n"
"    if (re->nhe_id > 0) nhe = zebra_nhg_lookup_id(re->nhe_id);\n"
"    else nhe = zebra_nhg_rib_find_nhe(re_nhe, afi);\n"
"\n"
"    /* Attach the re to the nhe's nexthop group. */\n"
"    route_entry_update_nhe(re, nhe);\n"
"\n"
"    /* Make it sure prefixlen is applied to the prefix. */\n"
"    /* Set default distance by route type. */\n"
"    ...\n"
"\n"
"    /* Lookup route node.*/\n"
"    rn = srcdest_rnode_get(table, p, src_p);\n"
"    ...\n"
"\n"
"    /* If this route is kernel/connected route, notify the dataplane to "
"update kernel route table. */\n"
"    if (RIB_SYSTEM_ROUTE(re)) {\n"
"        dplane_sys_route_add(rn, re);\n"
"    }\n"
"\n"
"    /* Link new re to node. */\n"
"    SET_FLAG(re->status, ROUTE_ENTRY_CHANGED);\n"
"    rib_addnode(rn, re, 1);\n"
"\n"
"    /* Clean up */\n"
"    ...\n"
"    return ret;\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:375
msgid ""
"`rib_addnode`会将这个路由添加请求转发给rib的处理线程，并由它顺序的进行处理："
msgstr ""
"`rib_addnode` forwards this route add request to the rib's processing "
"thread, and it sequentially processes:"

#: src/5-2-2-bgp-route-update-workflow.md:377
msgid ""
"```cpp\n"
"static void rib_addnode(struct route_node *rn, struct route_entry *re, int "
"process)\n"
"{\n"
"    ...\n"
"    rib_link(rn, re, process);\n"
"}\n"
"\n"
"static void rib_link(struct route_node *rn, struct route_entry *re, int "
"process)\n"
"{\n"
"    rib_dest_t *dest = rib_dest_from_rnode(rn);\n"
"    if (!dest) dest = zebra_rib_create_dest(rn);\n"
"    re_list_add_head(&dest->routes, re);\n"
"    ...\n"
"\n"
"    if (process) rib_queue_add(rn);\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"static void rib_addnode(struct route_node *rn, struct route_entry *re, int "
"process)\n"
"{\n"
"    ...\n"
"    rib_link(rn, re, process);\n"
"}\n"
"\n"
"static void rib_link(struct route_node *rn, struct route_entry *re, int "
"process)\n"
"{\n"
"    rib_dest_t *dest = rib_dest_from_rnode(rn);\n"
"    if (!dest) dest = zebra_rib_create_dest(rn);\n"
"    re_list_add_head(&dest->routes, re);\n"
"    ...\n"
"\n"
"    if (process) rib_queue_add(rn);\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:395
msgid ""
"请求会来到RIB的处理线程：`rib_process`，并由它来进行进一步的选路，然后将最优"
"的路由添加到`zebra`的内部路由表（RIB）中："
msgstr ""
"The request comes to the RIB's processing thread: `rib_process`, which "
"performs further routing and then adds the best route to `zebra`'s internal "
"routing table (RIB):"

#: src/5-2-2-bgp-route-update-workflow.md:397
msgid ""
"```cpp\n"
"/* Core function for processing routing information base. */\n"
"static void rib_process(struct route_node *rn)\n"
"{\n"
"    struct route_entry *re;\n"
"    struct route_entry *next;\n"
"    struct route_entry *old_selected = NULL;\n"
"    struct route_entry *new_selected = NULL;\n"
"    struct route_entry *old_fib = NULL;\n"
"    struct route_entry *new_fib = NULL;\n"
"    struct route_entry *best = NULL;\n"
"    rib_dest_t *dest;\n"
"    ...\n"
"\n"
"    dest = rib_dest_from_rnode(rn);\n"
"    old_fib = dest->selected_fib;\n"
"    ...\n"
"\n"
"    /* Check every route entry and select the best route. */\n"
"    RNODE_FOREACH_RE_SAFE (rn, re, next) {\n"
"        ...\n"
"\n"
"        if (CHECK_FLAG(re->flags, ZEBRA_FLAG_FIB_OVERRIDE)) {\n"
"            best = rib_choose_best(new_fib, re);\n"
"            if (new_fib && best != new_fib)\n"
"                UNSET_FLAG(new_fib->status, ROUTE_ENTRY_CHANGED);\n"
"            new_fib = best;\n"
"        } else {\n"
"            best = rib_choose_best(new_selected, re);\n"
"            if (new_selected && best != new_selected)\n"
"                UNSET_FLAG(new_selected->status, ROUTE_ENTRY_CHANGED);\n"
"            new_selected = best;\n"
"        }\n"
"\n"
"        if (best != re)\n"
"            UNSET_FLAG(re->status, ROUTE_ENTRY_CHANGED);\n"
"    } /* RNODE_FOREACH_RE */\n"
"    ...\n"
"\n"
"    /* Update fib according to selection results */\n"
"    if (new_fib && old_fib)\n"
"        rib_process_update_fib(zvrf, rn, old_fib, new_fib);\n"
"    else if (new_fib)\n"
"        rib_process_add_fib(zvrf, rn, new_fib);\n"
"    else if (old_fib)\n"
"        rib_process_del_fib(zvrf, rn, old_fib);\n"
"\n"
"    /* Remove all RE entries queued for removal */\n"
"    /* Check if the dest can be deleted now.  */\n"
"    ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"/* Core function for processing routing information base. */\n"
"static void rib_process(struct route_node *rn)\n"
"{\n"
"    struct route_entry *re;\n"
"    struct route_entry *next;\n"
"    struct route_entry *old_selected = NULL;\n"
"    struct route_entry *new_selected = NULL;\n"
"    struct route_entry *old_fib = NULL;\n"
"    struct route_entry *new_fib = NULL;\n"
"    struct route_entry *best = NULL;\n"
"    rib_dest_t *dest;\n"
"    ...\n"
"\n"
"    dest = rib_dest_from_rnode(rn);\n"
"    old_fib = dest->selected_fib;\n"
"    ...\n"
"\n"
"    /* Check every route entry and select the best route. */\n"
"    RNODE_FOREACH_RE_SAFE (rn, re, next) {\n"
"        ...\n"
"\n"
"        if (CHECK_FLAG(re->flags, ZEBRA_FLAG_FIB_OVERRIDE)) {\n"
"            best = rib_choose_best(new_fib, re);\n"
"            if (new_fib && best != new_fib)\n"
"                UNSET_FLAG(new_fib->status, ROUTE_ENTRY_CHANGED);\n"
"            new_fib = best;\n"
"        } else {\n"
"            best = rib_choose_best(new_selected, re);\n"
"            if (new_selected && best != new_selected)\n"
"                UNSET_FLAG(new_selected->status, ROUTE_ENTRY_CHANGED);\n"
"            new_selected = best;\n"
"        }\n"
"\n"
"        if (best != re)\n"
"            UNSET_FLAG(re->status, ROUTE_ENTRY_CHANGED);\n"
"    } /* RNODE_FOREACH_RE */\n"
"    ...\n"
"\n"
"    /* Update fib according to selection results */\n"
"    if (new_fib && old_fib)\n"
"        rib_process_update_fib(zvrf, rn, old_fib, new_fib);\n"
"    else if (new_fib)\n"
"        rib_process_add_fib(zvrf, rn, new_fib);\n"
"    else if (old_fib)\n"
"        rib_process_del_fib(zvrf, rn, old_fib);\n"
"\n"
"    /* Remove all RE entries queued for removal */\n"
"    /* Check if the dest can be deleted now.  */\n"
"    ...\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:450
msgid ""
"对于新的路由，会调用`rib_process_add_fib`来将其添加到`zebra`的内部路由表中，"
"然后通知dplane进行内核路由表的更新："
msgstr ""
"For new routes, `rib_process_add_fib` is called to add them to `zebra`'s "
"internal routing table, and then dplane is notified of the kernel routing "
"table update at"

#: src/5-2-2-bgp-route-update-workflow.md:452
msgid ""
"```cpp\n"
"static void rib_process_add_fib(struct zebra_vrf *zvrf, struct route_node "
"*rn, struct route_entry *new)\n"
"{\n"
"    hook_call(rib_update, rn, \"new route selected\");\n"
"    ...\n"
"\n"
"    /* If labeled-unicast route, install transit LSP. */\n"
"    if (zebra_rib_labeled_unicast(new))\n"
"        zebra_mpls_lsp_install(zvrf, rn, new);\n"
"\n"
"    rib_install_kernel(rn, new, NULL);\n"
"    UNSET_FLAG(new->status, ROUTE_ENTRY_CHANGED);\n"
"}\n"
"\n"
"void rib_install_kernel(struct route_node *rn, struct route_entry *re,\n"
"            struct route_entry *old)\n"
"{\n"
"    struct rib_table_info *info = srcdest_rnode_table_info(rn);\n"
"    enum zebra_dplane_result ret;\n"
"    rib_dest_t *dest = rib_dest_from_rnode(rn);\n"
"    ...\n"
"\n"
"    /* Install the resolved nexthop object first. */\n"
"    zebra_nhg_install_kernel(re->nhe);\n"
"\n"
"    /* If this is a replace to a new RE let the originator of the RE know "
"that they've lost */\n"
"    if (old && (old != re) && (old->type != re->type))\n"
"        zsend_route_notify_owner(rn, old, ZAPI_ROUTE_BETTER_ADMIN_WON, info-"
">afi, info->safi);\n"
"\n"
"    /* Update fib selection */\n"
"    dest->selected_fib = re;\n"
"\n"
"    /* Make sure we update the FPM any time we send new information to the "
"kernel. */\n"
"    hook_call(rib_update, rn, \"installing in kernel\");\n"
"\n"
"    /* Send add or update */\n"
"    if (old) ret = dplane_route_update(rn, re, old);\n"
"    else ret = dplane_route_add(rn, re);\n"
"    ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"static void rib_process_add_fib(struct zebra_vrf *zvrf, struct route_node "
"*rn, struct route_entry *new)\n"
"{\n"
"    hook_call(rib_update, rn, \"new route selected\");\n"
"    ...\n"
"\n"
"    /* If labeled-unicast route, install transit LSP. */\n"
"    if (zebra_rib_labeled_unicast(new))\n"
"        zebra_mpls_lsp_install(zvrf, rn, new);\n"
"\n"
"    rib_install_kernel(rn, new, NULL);\n"
"    UNSET_FLAG(new->status, ROUTE_ENTRY_CHANGED);\n"
"}\n"
"\n"
"void rib_install_kernel(struct route_node *rn, struct route_entry *re,\n"
"            struct route_entry *old)\n"
"{\n"
"    struct rib_table_info *info = srcdest_rnode_table_info(rn);\n"
"    enum zebra_dplane_result ret;\n"
"    rib_dest_t *dest = rib_dest_from_rnode(rn);\n"
"    ...\n"
"\n"
"    /* Install the resolved nexthop object first. */\n"
"    zebra_nhg_install_kernel(re->nhe);\n"
"\n"
"    /* If this is a replace to a new RE let the originator of the RE know "
"that they've lost */\n"
"    if (old && (old != re) && (old->type != re->type))\n"
"        zsend_route_notify_owner(rn, old, ZAPI_ROUTE_BETTER_ADMIN_WON, info-"
">afi, info->safi);\n"
"\n"
"    /* Update fib selection */\n"
"    dest->selected_fib = re;\n"
"\n"
"    /* Make sure we update the FPM any time we send new information to the "
"kernel. */\n"
"    hook_call(rib_update, rn, \"installing in kernel\");\n"
"\n"
"    /* Send add or update */\n"
"    if (old) ret = dplane_route_update(rn, re, old);\n"
"    else ret = dplane_route_add(rn, re);\n"
"    ...\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:494
msgid ""
"这里有两个重要的操作，一个自然是调用`dplane_route_*`函数来进行内核的路由表更"
"新，另一个则是出现了两次的`hook_call`，fpm的钩子函数就是挂在这个地方，用来接"
"收并转发路由表的更新通知。这里我们一个一个来看："
msgstr ""
"There are two important operations here, one is naturally the call to the "
"`dplane_route_*` function to perform kernel routing table updates, and the "
"other is the `hook_call` that appears twice, where the fpm hook function is "
"hung to receive and forward routing table update notifications. Here we look "
"at them one by one:"

#: src/5-2-2-bgp-route-update-workflow.md:496
msgid "#### dplane更新内核路由表"
msgstr "#### dplane updates the kernel routing table"

#: src/5-2-2-bgp-route-update-workflow.md:498
msgid ""
"首先是dplane的`dplane_route_*`函数，它们的做的事情都一样：把请求打包，然后放"
"入`dplane_thread`的消息队列中，并不会做任何实质的操作："
msgstr ""
"First is the `dplane_route_*` function of dplane, which does the same thing: "
"it packs the request and puts it in the `dplane_thread` message queue, "
"without doing anything of substance: the"

#: src/5-2-2-bgp-route-update-workflow.md:500
msgid ""
"```c\n"
"// File: src/sonic-frr/frr/zebra/zebra_dplane.c\n"
"enum zebra_dplane_result dplane_route_add(struct route_node *rn, struct "
"route_entry *re) {\n"
"    return dplane_route_update_internal(rn, re, NULL, "
"DPLANE_OP_ROUTE_INSTALL);\n"
"}\n"
"\n"
"enum zebra_dplane_result dplane_route_update(struct route_node *rn, struct "
"route_entry *re, struct route_entry *old_re) {\n"
"    return dplane_route_update_internal(rn, re, old_re, "
"DPLANE_OP_ROUTE_UPDATE);\n"
"}\n"
"\n"
"enum zebra_dplane_result dplane_sys_route_add(struct route_node *rn, struct "
"route_entry *re) {\n"
"    return dplane_route_update_internal(rn, re, NULL, "
"DPLANE_OP_SYS_ROUTE_ADD);\n"
"}\n"
"\n"
"static enum zebra_dplane_result\n"
"dplane_route_update_internal(struct route_node *rn, struct route_entry *re, "
"struct route_entry *old_re, enum dplane_op_e op)\n"
"{\n"
"    enum zebra_dplane_result result = ZEBRA_DPLANE_REQUEST_FAILURE;\n"
"    int ret = EINVAL;\n"
"\n"
"    /* Create and init context */\n"
"    struct zebra_dplane_ctx *ctx = ...;\n"
"\n"
"    /* Enqueue context for processing */\n"
"    ret = dplane_route_enqueue(ctx);\n"
"\n"
"    /* Update counter */\n"
"    atomic_fetch_add_explicit(&zdplane_info.dg_routes_in, 1, "
"memory_order_relaxed);\n"
"\n"
"    if (ret == AOK)\n"
"        result = ZEBRA_DPLANE_REQUEST_QUEUED;\n"
"\n"
"    return result;\n"
"}\n"
"```"
msgstr ""
"```c\n"
"// File: src/sonic-frr/frr/zebra/zebra_dplane.c\n"
"enum zebra_dplane_result dplane_route_add(struct route_node *rn, struct "
"route_entry *re) {\n"
"    return dplane_route_update_internal(rn, re, NULL, "
"DPLANE_OP_ROUTE_INSTALL);\n"
"}\n"
"\n"
"enum zebra_dplane_result dplane_route_update(struct route_node *rn, struct "
"route_entry *re, struct route_entry *old_re) {\n"
"    return dplane_route_update_internal(rn, re, old_re, "
"DPLANE_OP_ROUTE_UPDATE);\n"
"}\n"
"\n"
"enum zebra_dplane_result dplane_sys_route_add(struct route_node *rn, struct "
"route_entry *re) {\n"
"    return dplane_route_update_internal(rn, re, NULL, "
"DPLANE_OP_SYS_ROUTE_ADD);\n"
"}\n"
"\n"
"static enum zebra_dplane_result\n"
"dplane_route_update_internal(struct route_node *rn, struct route_entry *re, "
"struct route_entry *old_re, enum dplane_op_e op)\n"
"{\n"
"    enum zebra_dplane_result result = ZEBRA_DPLANE_REQUEST_FAILURE;\n"
"    int ret = EINVAL;\n"
"\n"
"    /* Create and init context */\n"
"    struct zebra_dplane_ctx *ctx = ...;\n"
"\n"
"    /* Enqueue context for processing */\n"
"    ret = dplane_route_enqueue(ctx);\n"
"\n"
"    /* Update counter */\n"
"    atomic_fetch_add_explicit(&zdplane_info.dg_routes_in, 1, "
"memory_order_relaxed);\n"
"\n"
"    if (ret == AOK)\n"
"        result = ZEBRA_DPLANE_REQUEST_QUEUED;\n"
"\n"
"    return result;\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:536
msgid ""
"然后，我们就来到了数据面处理线程`dplane_thread`，其消息循环很简单，就是从队列"
"中一个个取出消息，然后通过调用其处理函数："
msgstr ""
"Then, we come to the dataface processing thread `dplane_thread`, whose "
"message loop is simple: it takes messages one by one from the queue and then "
"calls its processing function by"

#: src/5-2-2-bgp-route-update-workflow.md:538
msgid ""
"```c\n"
"// File: src/sonic-frr/frr/zebra/zebra_dplane.c\n"
"static int dplane_thread_loop(struct thread *event)\n"
"{\n"
"    ...\n"
"\n"
"    while (prov) {\n"
"        ...\n"
"\n"
"        /* Process work here */\n"
"        (*prov->dp_fp)(prov);\n"
"\n"
"        /* Check for zebra shutdown */\n"
"        /* Dequeue completed work from the provider */\n"
"        ...\n"
"\n"
"        /* Locate next provider */\n"
"        DPLANE_LOCK();\n"
"        prov = TAILQ_NEXT(prov, dp_prov_link);\n"
"        DPLANE_UNLOCK();\n"
"    }\n"
"}\n"
"```"
msgstr ""
"```c\n"
"// File: src/sonic-frr/frr/zebra/zebra_dplane.c\n"
"static int dplane_thread_loop(struct thread *event)\n"
"{\n"
"    ...\n"
"\n"
"    while (prov) {\n"
"        ...\n"
"\n"
"        /* Process work here */\n"
"        (*prov->dp_fp)(prov);\n"
"\n"
"        /* Check for zebra shutdown */\n"
"        /* Dequeue completed work from the provider */\n"
"        ...\n"
"\n"
"        /* Locate next provider */\n"
"        DPLANE_LOCK();\n"
"        prov = TAILQ_NEXT(prov, dp_prov_link);\n"
"        DPLANE_UNLOCK();\n"
"    }\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:562
msgid ""
"默认情况下，`dplane_thread`会使用`kernel_dplane_process_func`来进行消息的处"
"理，内部会根据请求的类型对内核的操作进行分发："
msgstr ""
"By default, `dplane_thread` uses `kernel_dplane_process_func` for message "
"processing, and internally distributes the kernel operations according to "
"the type of request:"

#: src/5-2-2-bgp-route-update-workflow.md:564
msgid ""
"```c\n"
"static int kernel_dplane_process_func(struct zebra_dplane_provider *prov)\n"
"{\n"
"    enum zebra_dplane_result res;\n"
"    struct zebra_dplane_ctx *ctx;\n"
"    int counter, limit;\n"
"    limit = dplane_provider_get_work_limit(prov);\n"
"\n"
"    for (counter = 0; counter < limit; counter++) {\n"
"        ctx = dplane_provider_dequeue_in_ctx(prov);\n"
"        if (ctx == NULL) break;\n"
"\n"
"        /* A previous provider plugin may have asked to skip the kernel "
"update.  */\n"
"        if (dplane_ctx_is_skip_kernel(ctx)) {\n"
"            res = ZEBRA_DPLANE_REQUEST_SUCCESS;\n"
"            goto skip_one;\n"
"        }\n"
"\n"
"        /* Dispatch to appropriate kernel-facing apis */\n"
"        switch (dplane_ctx_get_op(ctx)) {\n"
"        case DPLANE_OP_ROUTE_INSTALL:\n"
"        case DPLANE_OP_ROUTE_UPDATE:\n"
"        case DPLANE_OP_ROUTE_DELETE:\n"
"            res = kernel_dplane_route_update(ctx);\n"
"            break;\n"
"        ...\n"
"        }\n"
"        ...\n"
"    }\n"
"    ...\n"
"}\n"
"\n"
"static enum zebra_dplane_result\n"
"kernel_dplane_route_update(struct zebra_dplane_ctx *ctx)\n"
"{\n"
"    enum zebra_dplane_result res;\n"
"    /* Call into the synchronous kernel-facing code here */\n"
"    res = kernel_route_update(ctx);\n"
"    return res;\n"
"}\n"
"```"
msgstr ""
"```c\n"
"static int kernel_dplane_process_func(struct zebra_dplane_provider *prov)\n"
"{\n"
"    enum zebra_dplane_result res;\n"
"    struct zebra_dplane_ctx *ctx;\n"
"    int counter, limit;\n"
"    limit = dplane_provider_get_work_limit(prov);\n"
"\n"
"    for (counter = 0; counter < limit; counter++) {\n"
"        ctx = dplane_provider_dequeue_in_ctx(prov);\n"
"        if (ctx == NULL) break;\n"
"\n"
"        /* A previous provider plugin may have asked to skip the kernel "
"update.  */\n"
"        if (dplane_ctx_is_skip_kernel(ctx)) {\n"
"            res = ZEBRA_DPLANE_REQUEST_SUCCESS;\n"
"            goto skip_one;\n"
"        }\n"
"\n"
"        /* Dispatch to appropriate kernel-facing apis */\n"
"        switch (dplane_ctx_get_op(ctx)) {\n"
"        case DPLANE_OP_ROUTE_INSTALL:\n"
"        case DPLANE_OP_ROUTE_UPDATE:\n"
"        case DPLANE_OP_ROUTE_DELETE:\n"
"            res = kernel_dplane_route_update(ctx);\n"
"            break;\n"
"        ...\n"
"        }\n"
"        ...\n"
"    }\n"
"    ...\n"
"}\n"
"\n"
"static enum zebra_dplane_result\n"
"kernel_dplane_route_update(struct zebra_dplane_ctx *ctx)\n"
"{\n"
"    enum zebra_dplane_result res;\n"
"    /* Call into the synchronous kernel-facing code here */\n"
"    res = kernel_route_update(ctx);\n"
"    return res;\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:606
msgid ""
"而`kernel_route_update`则是真正的内核操作了，它会通过netlink来通知内核路由更"
"新："
msgstr ""
"And `kernel_route_update` is a real kernel operation, which notifies the "
"kernel of routing updates via netlink: `kernel_route_update`:"

#: src/5-2-2-bgp-route-update-workflow.md:608
msgid ""
"```c\n"
"// File: src/sonic-frr/frr/zebra/rt_netlink.c\n"
"// Update or delete a prefix from the kernel, using info from a dataplane "
"context.\n"
"enum zebra_dplane_result kernel_route_update(struct zebra_dplane_ctx *ctx)\n"
"{\n"
"    int cmd, ret;\n"
"    const struct prefix *p = dplane_ctx_get_dest(ctx);\n"
"    struct nexthop *nexthop;\n"
"\n"
"    if (dplane_ctx_get_op(ctx) == DPLANE_OP_ROUTE_DELETE) {\n"
"        cmd = RTM_DELROUTE;\n"
"    } else if (dplane_ctx_get_op(ctx) == DPLANE_OP_ROUTE_INSTALL) {\n"
"        cmd = RTM_NEWROUTE;\n"
"    } else if (dplane_ctx_get_op(ctx) == DPLANE_OP_ROUTE_UPDATE) {\n"
"        cmd = RTM_NEWROUTE;\n"
"    }\n"
"\n"
"    if (!RSYSTEM_ROUTE(dplane_ctx_get_type(ctx)))\n"
"        ret = netlink_route_multipath(cmd, ctx);\n"
"    ...\n"
"\n"
"    return (ret == 0 ? ZEBRA_DPLANE_REQUEST_SUCCESS : "
"ZEBRA_DPLANE_REQUEST_FAILURE);\n"
"}\n"
"\n"
"// Routing table change via netlink interface, using a dataplane context "
"object\n"
"static int netlink_route_multipath(int cmd, struct zebra_dplane_ctx *ctx)\n"
"{\n"
"    // Build netlink request.\n"
"    struct {\n"
"        struct nlmsghdr n;\n"
"        struct rtmsg r;\n"
"        char buf[NL_PKT_BUF_SIZE];\n"
"    } req;\n"
"\n"
"    req.n.nlmsg_len = NLMSG_LENGTH(sizeof(struct rtmsg));\n"
"    req.n.nlmsg_flags = NLM_F_CREATE | NLM_F_REQUEST;\n"
"    ...\n"
"\n"
"    /* Talk to netlink socket. */\n"
"    return netlink_talk_info(netlink_talk_filter, &req.n, "
"dplane_ctx_get_ns(ctx), 0);\n"
"}\n"
"```"
msgstr ""
"```c\n"
"// File: src/sonic-frr/frr/zebra/rt_netlink.c\n"
"// Update or delete a prefix from the kernel, using info from a dataplane "
"context.\n"
"enum zebra_dplane_result kernel_route_update(struct zebra_dplane_ctx *ctx)\n"
"{\n"
"    int cmd, ret;\n"
"    const struct prefix *p = dplane_ctx_get_dest(ctx);\n"
"    struct nexthop *nexthop;\n"
"\n"
"    if (dplane_ctx_get_op(ctx) == DPLANE_OP_ROUTE_DELETE) {\n"
"        cmd = RTM_DELROUTE;\n"
"    } else if (dplane_ctx_get_op(ctx) == DPLANE_OP_ROUTE_INSTALL) {\n"
"        cmd = RTM_NEWROUTE;\n"
"    } else if (dplane_ctx_get_op(ctx) == DPLANE_OP_ROUTE_UPDATE) {\n"
"        cmd = RTM_NEWROUTE;\n"
"    }\n"
"\n"
"    if (!RSYSTEM_ROUTE(dplane_ctx_get_type(ctx)))\n"
"        ret = netlink_route_multipath(cmd, ctx);\n"
"    ...\n"
"\n"
"    return (ret == 0 ? ZEBRA_DPLANE_REQUEST_SUCCESS : "
"ZEBRA_DPLANE_REQUEST_FAILURE);\n"
"}\n"
"\n"
"// Routing table change via netlink interface, using a dataplane context "
"object\n"
"static int netlink_route_multipath(int cmd, struct zebra_dplane_ctx *ctx)\n"
"{\n"
"    // Build netlink request.\n"
"    struct {\n"
"        struct nlmsghdr n;\n"
"        struct rtmsg r;\n"
"        char buf[NL_PKT_BUF_SIZE];\n"
"    } req;\n"
"\n"
"    req.n.nlmsg_len = NLMSG_LENGTH(sizeof(struct rtmsg));\n"
"    req.n.nlmsg_flags = NLM_F_CREATE | NLM_F_REQUEST;\n"
"    ...\n"
"\n"
"    /* Talk to netlink socket. */\n"
"    return netlink_talk_info(netlink_talk_filter, &req.n, "
"dplane_ctx_get_ns(ctx), 0);\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:651
msgid "#### FPM路由更新转发"
msgstr "#### FPM Routing Update Forwarding"

#: src/5-2-2-bgp-route-update-workflow.md:653
msgid ""
"FPM（Forwarding Plane Manager）是FRR中用于通知其他进程路由变更的协议，其主要"
"逻辑代码在`src/sonic-frr/frr/zebra/zebra_fpm.c`中。它默认有两套协议实现："
"protobuf和netlink，SONiC就是使用的是netlink协议。"
msgstr ""
"FPM (Forwarding Plane Manager) is a protocol used in FRR to notify other "
"processes of routing changes, and its main logic code is in `src/sonic-frr/"
"frr/zebra/zebra_fpm.c`. It has two protocol implementations by default: "
"protobuf and netlink, and SONiC is using the netlink protocol."

#: src/5-2-2-bgp-route-update-workflow.md:655
msgid ""
"上面我们已经提到，它通过钩子函数实现，监听RIB中的路由变化，并通过本地Socket转"
"发给其他的进程。这个钩子会在启动的时候就注册好，其中和我们现在看的最相关的就"
"是`rib_update`钩子了，如下所示："
msgstr ""
"As we have already mentioned above, it is implemented through a hook "
"function that listens for routing changes in the RIB and forwards them to "
"other processes via local sockets. This hook will be registered at startup, "
"the most relevant one to what we are looking at is the `rib_update` hook, as "
"follows:"

#: src/5-2-2-bgp-route-update-workflow.md:657
msgid ""
"```c\n"
"static int zebra_fpm_module_init(void)\n"
"{\n"
"    hook_register(rib_update, zfpm_trigger_update);\n"
"    hook_register(zebra_rmac_update, zfpm_trigger_rmac_update);\n"
"    hook_register(frr_late_init, zfpm_init);\n"
"    hook_register(frr_early_fini, zfpm_fini);\n"
"    return 0;\n"
"}\n"
"\n"
"FRR_MODULE_SETUP(.name = \"zebra_fpm\", .version = FRR_VERSION,\n"
"         .description = \"zebra FPM (Forwarding Plane Manager) module\",\n"
"         .init = zebra_fpm_module_init,\n"
");\n"
"```"
msgstr ""
"```c\n"
"static int zebra_fpm_module_init(void)\n"
"{\n"
"    hook_register(rib_update, zfpm_trigger_update);\n"
"    hook_register(zebra_rmac_update, zfpm_trigger_rmac_update);\n"
"    hook_register(frr_late_init, zfpm_init);\n"
"    hook_register(frr_early_fini, zfpm_fini);\n"
"    return 0;\n"
"}\n"
"\n"
"FRR_MODULE_SETUP(.name = \"zebra_fpm\", .version = FRR_VERSION,\n"
"         .description = \"zebra FPM (Forwarding Plane Manager) module\",\n"
"         .init = zebra_fpm_module_init,\n"
");\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:673
msgid ""
"当`rib_update`钩子被调用时，`zfpm_trigger_update`函数会被调用，它会将路由变更"
"信息再次放入fpm的转发队列中，并触发写操作："
msgstr ""
"When the `rib_update` hook is called, the `zfpm_trigger_update` function is "
"invoked, which puts the route change information into the fpm forwarding "
"queue again and triggers a write operation: the"

#: src/5-2-2-bgp-route-update-workflow.md:675
msgid ""
"```c\n"
"static int zfpm_trigger_update(struct route_node *rn, const char *reason)\n"
"{\n"
"    rib_dest_t *dest;\n"
"    ...\n"
"\n"
"    // Queue the update request\n"
"    dest = rib_dest_from_rnode(rn);\n"
"    SET_FLAG(dest->flags, RIB_DEST_UPDATE_FPM);\n"
"    TAILQ_INSERT_TAIL(&zfpm_g->dest_q, dest, fpm_q_entries);\n"
"    ...\n"
"\n"
"    zfpm_write_on();\n"
"    return 0;\n"
"}\n"
"\n"
"static inline void zfpm_write_on(void) {\n"
"    thread_add_write(zfpm_g->master, zfpm_write_cb, 0, zfpm_g->sock, &zfpm_g-"
">t_write);\n"
"}\n"
"```"
msgstr ""
"```c\n"
"static int zfpm_trigger_update(struct route_node *rn, const char *reason)\n"
"{\n"
"    rib_dest_t *dest;\n"
"    ...\n"
"\n"
"    // Queue the update request\n"
"    dest = rib_dest_from_rnode(rn);\n"
"    SET_FLAG(dest->flags, RIB_DEST_UPDATE_FPM);\n"
"    TAILQ_INSERT_TAIL(&zfpm_g->dest_q, dest, fpm_q_entries);\n"
"    ...\n"
"\n"
"    zfpm_write_on();\n"
"    return 0;\n"
"}\n"
"\n"
"static inline void zfpm_write_on(void) {\n"
"    thread_add_write(zfpm_g->master, zfpm_write_cb, 0, zfpm_g->sock, &zfpm_g-"
">t_write);\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:696
msgid ""
"这个写操作的回调就会将其从队列中取出，并转换成FPM的消息格式，然后通过本地"
"Socket转发给其他进程："
msgstr ""
"The callback for this write operation then takes it out of the queue and "
"converts it into the FPM message format, which is then forwarded to other "
"processes via the local socket: the"

#: src/5-2-2-bgp-route-update-workflow.md:698
msgid ""
"```c\n"
"static int zfpm_write_cb(struct thread *thread)\n"
"{\n"
"    struct stream *s;\n"
"\n"
"    do {\n"
"        int bytes_to_write, bytes_written;\n"
"        s = zfpm_g->obuf;\n"
"\n"
"        // Convert route info to buffer here.\n"
"        if (stream_empty(s)) zfpm_build_updates();\n"
"\n"
"        // Write to socket until we don' have anything to write or cannot "
"write anymore (partial write).\n"
"        bytes_to_write = stream_get_endp(s) - stream_get_getp(s);\n"
"        bytes_written = write(zfpm_g->sock, stream_pnt(s), bytes_to_write);\n"
"        ...\n"
"    } while (1);\n"
"\n"
"    if (zfpm_writes_pending()) zfpm_write_on();\n"
"    return 0;\n"
"}\n"
"\n"
"static void zfpm_build_updates(void)\n"
"{\n"
"    struct stream *s = zfpm_g->obuf;\n"
"    do {\n"
"        /* Stop processing the queues if zfpm_g->obuf is full or we do not "
"have more updates to process */\n"
"        if (zfpm_build_mac_updates() == FPM_WRITE_STOP) break;\n"
"        if (zfpm_build_route_updates() == FPM_WRITE_STOP) break;\n"
"    } while (zfpm_updates_pending());\n"
"}\n"
"```"
msgstr ""
"```c\n"
"static int zfpm_write_cb(struct thread *thread)\n"
"{\n"
"    struct stream *s;\n"
"\n"
"    do {\n"
"        int bytes_to_write, bytes_written;\n"
"        s = zfpm_g->obuf;\n"
"\n"
"        // Convert route info to buffer here.\n"
"        if (stream_empty(s)) zfpm_build_updates();\n"
"\n"
"        // Write to socket until we don' have anything to write or cannot "
"write anymore (partial write).\n"
"        bytes_to_write = stream_get_endp(s) - stream_get_getp(s);\n"
"        bytes_written = write(zfpm_g->sock, stream_pnt(s), bytes_to_write);\n"
"        ...\n"
"    } while (1);\n"
"\n"
"    if (zfpm_writes_pending()) zfpm_write_on();\n"
"    return 0;\n"
"}\n"
"\n"
"static void zfpm_build_updates(void)\n"
"{\n"
"    struct stream *s = zfpm_g->obuf;\n"
"    do {\n"
"        /* Stop processing the queues if zfpm_g->obuf is full or we do not "
"have more updates to process */\n"
"        if (zfpm_build_mac_updates() == FPM_WRITE_STOP) break;\n"
"        if (zfpm_build_route_updates() == FPM_WRITE_STOP) break;\n"
"    } while (zfpm_updates_pending());\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:731
msgid "到此，FRR的工作就完成了。"
msgstr "At this point, FRR's work is complete."

#: src/5-2-2-bgp-route-update-workflow.md:733
msgid "## SONiC路由变更工作流"
msgstr "## SONiC Routing Change Workflow"

#: src/5-2-2-bgp-route-update-workflow.md:735
msgid ""
"当FRR变更内核路由配置后，SONiC便会收到来自Netlink和FPM的通知，然后进行一系列"
"操作将其下发给ASIC，其主要流程如下："
msgstr ""
"When the FRR changes the kernel routing configuration, SONiC receives a "
"notification from Netlink and FPM, and then performs a series of operations "
"to send it down to the ASIC, the main process of which is as follows:"

#: src/5-2-2-bgp-route-update-workflow.md:737
msgid ""
"```mermaid\n"
"sequenceDiagram\n"
"    autonumber\n"
"    participant K as Linux Kernel\n"
"    box purple bgp容器\n"
"    participant Z as zebra\n"
"    participant FPM as fpmsyncd\n"
"    end\n"
"    box darkred database容器\n"
"    participant R as Redis\n"
"    end\n"
"    box darkblue swss容器\n"
"    participant OA as orchagent\n"
"    end\n"
"    box darkgreen syncd容器\n"
"    participant SD as syncd\n"
"    end\n"
"    participant A as ASIC\n"
"\n"
"    K->>FPM: 内核路由变更时通过Netlink发送通知\n"
"    Z->>FPM: 通过FPM接口和Netlink<br/>消息格式发送路由变更通知\n"
"\n"
"    FPM->>R: 通过ProducerStateTable<br/>将路由变更信息写入<br/>APPL_DB\n"
"\n"
"    R->>OA: 通过ConsumerStateTable<br/>接收路由变更信息\n"
"    \n"
"    OA->>OA: 处理路由变更信息<br/>生成SAI路由对象\n"
"    OA->>SD: 通过ProducerTable<br/>或者ZMQ将SAI路由对象<br/>发给syncd\n"
"\n"
"    SD->>R: 接收SAI路由对象，写入ASIC_DB\n"
"    SD->>A: 通过SAI接口<br/>配置ASIC\n"
"```"
msgstr ""
"```mermaid\n"
"sequenceDiagram\n"
"    autonumber\n"
"    participant K as Linux Kernel\n"
"    box purple bgp容器\n"
"    participant Z as zebra\n"
"    participant FPM as fpmsyncd\n"
"    end\n"
"    box darkred database容器\n"
"    participant R as Redis\n"
"    end\n"
"    box darkblue swss容器\n"
"    participant OA as orchagent\n"
"    end\n"
"    box darkgreen syncd容器\n"
"    participant SD as syncd\n"
"    end\n"
"    participant A as ASIC\n"
"\n"
"    K->>FPM: 内核路由变更时通过Netlink发送通知\n"
"    Z->>FPM: 通过FPM接口和Netlink<br/>消息格式发送路由变更通知\n"
"\n"
"    FPM->>R: 通过ProducerStateTable<br/>将路由变更信息写入<br/>APPL_DB\n"
"\n"
"    R->>OA: 通过ConsumerStateTable<br/>接收路由变更信息\n"
"    \n"
"    OA->>OA: 处理路由变更信息<br/>生成SAI路由对象\n"
"    OA->>SD: 通过ProducerTable<br/>或者ZMQ将SAI路由对象<br/>发给syncd\n"
"\n"
"    SD->>R: 接收SAI路由对象，写入ASIC_DB\n"
"    SD->>A: 通过SAI接口<br/>配置ASIC\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:770
msgid "### fpmsyncd更新Redis中的路由配置"
msgstr "### fpmsyncd updates the routing configuration in Redis"

#: src/5-2-2-bgp-route-update-workflow.md:772
msgid ""
"首先，我们从源头看起。`fpmsyncd`在启动的时候便会开始监听FPM和Netlink的事件，"
"用于接收路由变更消息："
msgstr ""
"First, let's look at the source. `fpmsyncd` starts listening for FPM and "
"Netlink events when it starts up, and is used to receive routing change "
"messages:"

#: src/5-2-2-bgp-route-update-workflow.md:774
msgid ""
"```cpp\n"
"// File: src/sonic-swss/fpmsyncd/fpmsyncd.cpp\n"
"int main(int argc, char **argv)\n"
"{\n"
"    ...\n"
"\n"
"    DBConnector db(\"APPL_DB\", 0);\n"
"    RedisPipeline pipeline(&db);\n"
"    RouteSync sync(&pipeline);\n"
"    \n"
"    // Register netlink message handler\n"
"    NetLink netlink;\n"
"    netlink.registerGroup(RTNLGRP_LINK);\n"
"\n"
"    NetDispatcher::getInstance().registerMessageHandler(RTM_NEWROUTE, "
"&sync);\n"
"    NetDispatcher::getInstance().registerMessageHandler(RTM_DELROUTE, "
"&sync);\n"
"    NetDispatcher::getInstance().registerMessageHandler(RTM_NEWLINK, "
"&sync);\n"
"    NetDispatcher::getInstance().registerMessageHandler(RTM_DELLINK, "
"&sync);\n"
"\n"
"    rtnl_route_read_protocol_names(DefaultRtProtoPath);\n"
"    ...\n"
"\n"
"    while (true) {\n"
"        try {\n"
"            // Launching FPM server and wait for zebra to connect.\n"
"            FpmLink fpm(&sync);\n"
"            ...\n"
"\n"
"            fpm.accept();\n"
"            ...\n"
"        } catch (FpmLink::FpmConnectionClosedException &e) {\n"
"            // If connection is closed, keep retrying until it succeeds, "
"before handling any other events.\n"
"            cout << \"Connection lost, reconnecting...\" << endl;\n"
"        }\n"
"        ...\n"
"    }\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-swss/fpmsyncd/fpmsyncd.cpp\n"
"int main(int argc, char **argv)\n"
"{\n"
"    ...\n"
"\n"
"    DBConnector db(\"APPL_DB\", 0);\n"
"    RedisPipeline pipeline(&db);\n"
"    RouteSync sync(&pipeline);\n"
"    \n"
"    // Register netlink message handler\n"
"    NetLink netlink;\n"
"    netlink.registerGroup(RTNLGRP_LINK);\n"
"\n"
"    NetDispatcher::getInstance().registerMessageHandler(RTM_NEWROUTE, "
"&sync);\n"
"    NetDispatcher::getInstance().registerMessageHandler(RTM_DELROUTE, "
"&sync);\n"
"    NetDispatcher::getInstance().registerMessageHandler(RTM_NEWLINK, "
"&sync);\n"
"    NetDispatcher::getInstance().registerMessageHandler(RTM_DELLINK, "
"&sync);\n"
"\n"
"    rtnl_route_read_protocol_names(DefaultRtProtoPath);\n"
"    ...\n"
"\n"
"    while (true) {\n"
"        try {\n"
"            // Launching FPM server and wait for zebra to connect.\n"
"            FpmLink fpm(&sync);\n"
"            ...\n"
"\n"
"            fpm.accept();\n"
"            ...\n"
"        } catch (FpmLink::FpmConnectionClosedException &e) {\n"
"            // If connection is closed, keep retrying until it succeeds, "
"before handling any other events.\n"
"            cout << \"Connection lost, reconnecting...\" << endl;\n"
"        }\n"
"        ...\n"
"    }\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:813
msgid ""
"这样，所有的路由变更消息都会以Netlink的形式发送给`RouteSync`，其中[EVPN Type "
"5][EVPN]必须以原始消息的形式进行处理，所以会发送给`onMsgRaw`，其他的消息都会"
"统一的发给处理Netlink的`onMsg`回调：（关于Netlink如何接收和处理消息，请移步"
"[4.1.2 Netlink](./4-1-2-netlink.html)）"
msgstr ""
"In this way, all route change messages are sent to `RouteSync` as Netlink, "
"where [EVPN Type 5][EVPN] must be processed as raw messages, so they are "
"sent to `onMsgRaw`, and all other messages are sent uniformly to the `onMsg` "
"callback that handles Netlink: (for more information on For more information "
"on how Netlink receives and processes messages, please go to [4.1.2 Netlink]"
"(. /4-1-2-netlink.html))"

#: src/5-2-2-bgp-route-update-workflow.md:815
msgid ""
"```cpp\n"
"// File: src/sonic-swss/fpmsyncd/fpmlink.cpp\n"
"// Called from: FpmLink::readData()\n"
"void FpmLink::processFpmMessage(fpm_msg_hdr_t* hdr)\n"
"{\n"
"    size_t msg_len = fpm_msg_len(hdr);\n"
"    nlmsghdr *nl_hdr = (nlmsghdr *)fpm_msg_data(hdr);\n"
"    ...\n"
"\n"
"    /* Read all netlink messages inside FPM message */\n"
"    for (; NLMSG_OK (nl_hdr, msg_len); nl_hdr = NLMSG_NEXT(nl_hdr, "
"msg_len))\n"
"    {\n"
"        /*\n"
"         * EVPN Type5 Add Routes need to be process in Raw mode as they "
"contain\n"
"         * RMAC, VLAN and L3VNI information.\n"
"         * Where as all other route will be using rtnl api to extract "
"information\n"
"         * from the netlink msg.\n"
"         */\n"
"        bool isRaw = isRawProcessing(nl_hdr);\n"
"        \n"
"        nl_msg *msg = nlmsg_convert(nl_hdr);\n"
"        ...\n"
"        nlmsg_set_proto(msg, NETLINK_ROUTE);\n"
"\n"
"        if (isRaw) {\n"
"            /* EVPN Type5 Add route processing */\n"
"            /* This will call into onRawMsg() */\n"
"            processRawMsg(nl_hdr);\n"
"        } else {\n"
"            /* This will call into onMsg() */\n"
"            NetDispatcher::getInstance().onNetlinkMessage(msg);\n"
"        }\n"
"\n"
"        nlmsg_free(msg);\n"
"    }\n"
"}\n"
"\n"
"void FpmLink::processRawMsg(struct nlmsghdr *h)\n"
"{\n"
"    m_routesync->onMsgRaw(h);\n"
"};\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-swss/fpmsyncd/fpmlink.cpp\n"
"// Called from: FpmLink::readData()\n"
"void FpmLink::processFpmMessage(fpm_msg_hdr_t* hdr)\n"
"{\n"
"    size_t msg_len = fpm_msg_len(hdr);\n"
"    nlmsghdr *nl_hdr = (nlmsghdr *)fpm_msg_data(hdr);\n"
"    ...\n"
"\n"
"    /* Read all netlink messages inside FPM message */\n"
"    for (; NLMSG_OK (nl_hdr, msg_len); nl_hdr = NLMSG_NEXT(nl_hdr, "
"msg_len))\n"
"    {\n"
"        /*\n"
"         * EVPN Type5 Add Routes need to be process in Raw mode as they "
"contain\n"
"         * RMAC, VLAN and L3VNI information.\n"
"         * Where as all other route will be using rtnl api to extract "
"information\n"
"         * from the netlink msg.\n"
"         */\n"
"        bool isRaw = isRawProcessing(nl_hdr);\n"
"        \n"
"        nl_msg *msg = nlmsg_convert(nl_hdr);\n"
"        ...\n"
"        nlmsg_set_proto(msg, NETLINK_ROUTE);\n"
"\n"
"        if (isRaw) {\n"
"            /* EVPN Type5 Add route processing */\n"
"            /* This will call into onRawMsg() */\n"
"            processRawMsg(nl_hdr);\n"
"        } else {\n"
"            /* This will call into onMsg() */\n"
"            NetDispatcher::getInstance().onNetlinkMessage(msg);\n"
"        }\n"
"\n"
"        nlmsg_free(msg);\n"
"    }\n"
"}\n"
"\n"
"void FpmLink::processRawMsg(struct nlmsghdr *h)\n"
"{\n"
"    m_routesync->onMsgRaw(h);\n"
"};\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:858
msgid ""
"接着，`RouteSync`收到路由变更的消息之后，会在`onMsg`和`onMsgRaw`中进行判断和"
"分发："
msgstr ""
"Then, after `RouteSync` receives the route change message, it will determine "
"and distribute it in `onMsg` and `onMsgRaw`:"

#: src/5-2-2-bgp-route-update-workflow.md:860
msgid ""
"```cpp\n"
"// File: src/sonic-swss/fpmsyncd/routesync.cpp\n"
"void RouteSync::onMsgRaw(struct nlmsghdr *h)\n"
"{\n"
"    if ((h->nlmsg_type != RTM_NEWROUTE) && (h->nlmsg_type != RTM_DELROUTE))\n"
"        return;\n"
"    ...\n"
"    onEvpnRouteMsg(h, len);\n"
"}\n"
"\n"
"void RouteSync::onMsg(int nlmsg_type, struct nl_object *obj)\n"
"{\n"
"    // Refill Netlink cache here\n"
"    ...\n"
"\n"
"    struct rtnl_route *route_obj = (struct rtnl_route *)obj;\n"
"    auto family = rtnl_route_get_family(route_obj);\n"
"    if (family == AF_MPLS) {\n"
"        onLabelRouteMsg(nlmsg_type, obj);\n"
"        return;\n"
"    }\n"
"    ...\n"
"\n"
"    unsigned int master_index = rtnl_route_get_table(route_obj);\n"
"    char master_name[IFNAMSIZ] = {0};\n"
"    if (master_index) {\n"
"        /* If the master device name starts with VNET_PREFIX, it is a VNET "
"route.\n"
"        The VNET name is exactly the name of the associated master device. "
"*/\n"
"        getIfName(master_index, master_name, IFNAMSIZ);\n"
"        if (string(master_name).find(VNET_PREFIX) == 0) {\n"
"            onVnetRouteMsg(nlmsg_type, obj, string(master_name));\n"
"        }\n"
"\n"
"        /* Otherwise, it is a regular route (include VRF route). */\n"
"        else {\n"
"            onRouteMsg(nlmsg_type, obj, master_name);\n"
"        }\n"
"    } else {\n"
"        onRouteMsg(nlmsg_type, obj, NULL);\n"
"    }\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-swss/fpmsyncd/routesync.cpp\n"
"void RouteSync::onMsgRaw(struct nlmsghdr *h)\n"
"{\n"
"    if ((h->nlmsg_type != RTM_NEWROUTE) && (h->nlmsg_type != RTM_DELROUTE))\n"
"        return;\n"
"    ...\n"
"    onEvpnRouteMsg(h, len);\n"
"}\n"
"\n"
"void RouteSync::onMsg(int nlmsg_type, struct nl_object *obj)\n"
"{\n"
"    // Refill Netlink cache here\n"
"    ...\n"
"\n"
"    struct rtnl_route *route_obj = (struct rtnl_route *)obj;\n"
"    auto family = rtnl_route_get_family(route_obj);\n"
"    if (family == AF_MPLS) {\n"
"        onLabelRouteMsg(nlmsg_type, obj);\n"
"        return;\n"
"    }\n"
"    ...\n"
"\n"
"    unsigned int master_index = rtnl_route_get_table(route_obj);\n"
"    char master_name[IFNAMSIZ] = {0};\n"
"    if (master_index) {\n"
"        /* If the master device name starts with VNET_PREFIX, it is a VNET "
"route.\n"
"        The VNET name is exactly the name of the associated master device. "
"*/\n"
"        getIfName(master_index, master_name, IFNAMSIZ);\n"
"        if (string(master_name).find(VNET_PREFIX) == 0) {\n"
"            onVnetRouteMsg(nlmsg_type, obj, string(master_name));\n"
"        }\n"
"\n"
"        /* Otherwise, it is a regular route (include VRF route). */\n"
"        else {\n"
"            onRouteMsg(nlmsg_type, obj, master_name);\n"
"        }\n"
"    } else {\n"
"        onRouteMsg(nlmsg_type, obj, NULL);\n"
"    }\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:903
msgid ""
"从上面的代码中，我们可以看到这里会有四种不同的路由处理入口，这些不同的路由会"
"被最终通过各自的[ProducerStateTable](./4-2-2-redis-messaging-layer."
"html#producerstatetable--consumerstatetable)写入到`APPL_DB`中的不同的Table"
"中："
msgstr ""
"From the code above, we can see that there will be four different route "
"processing entries here, and these different routes will be eventually "
"written to different Tables in `APPL_DB` via their respective "
"[ProducerStateTable](. /4-2-2-redis-messaging-layer.html#producerstatetable--"
"consumerstatetable) to different Tables in `APPL_DB`:"

#: src/5-2-2-bgp-route-update-workflow.md:905
msgid ""
"| 路由类型 | 处理函数 | Table |\n"
"| --- | --- | --- |\n"
"| MPLS | `onLabelRouteMsg` | LABLE_ROUTE_TABLE |\n"
"| Vnet VxLan Tunnel Route | `onVnetRouteMsg` | VNET_ROUTE_TUNNEL_TABLE |\n"
"| 其他Vnet路由 | `onVnetRouteMsg` | VNET_ROUTE_TABLE |\n"
"| EVPN Type 5 | `onEvpnRouteMsg` | ROUTE_TABLE |\n"
"| 普通路由 | `onRouteMsg` | ROUTE_TABLE |"
msgstr ""
"| Routing Type | Handler | Table |\n"
"| --- | --- | --- |\n"
"| MPLS | `onLabelRouteMsg` | LABLE_ROUTE_TABLE |\n"
"| Vnet VxLan Tunnel Route | `onVnetRouteMsg` | VNET_ROUTE_TUNNEL_TABLE |\n"
"| Other Vnet Routes | `onVnetRouteMsg` | VNET_ROUTE_TABLE |\n"
"| EVPN Type 5 | `onEvpnRouteMsg` | ROUTE_TABLE |\n"
"| ROUTE_TABLE | `onRouteMsg` | ROUTE_TABLE |"

#: src/5-2-2-bgp-route-update-workflow.md:913
msgid ""
"这里以普通路由来举例子，其他的函数的实现虽然有所不同，但是主体的思路是一样"
"的："
msgstr ""
"Here is an example of ordinary routing, the implementation of other "
"functions is different, but the main idea is the same: the"

#: src/5-2-2-bgp-route-update-workflow.md:915
msgid ""
"```cpp\n"
"// File: src/sonic-swss/fpmsyncd/routesync.cpp\n"
"void RouteSync::onRouteMsg(int nlmsg_type, struct nl_object *obj, char "
"*vrf)\n"
"{\n"
"    // Parse route info from nl_object here.\n"
"    ...\n"
"    \n"
"    // Get nexthop lists\n"
"    string gw_list;\n"
"    string intf_list;\n"
"    string mpls_list;\n"
"    getNextHopList(route_obj, gw_list, mpls_list, intf_list);\n"
"    ...\n"
"\n"
"    // Build route info here, including protocol, interface, next hops, "
"MPLS, weights etc.\n"
"    vector<FieldValueTuple> fvVector;\n"
"    FieldValueTuple proto(\"protocol\", proto_str);\n"
"    FieldValueTuple gw(\"nexthop\", gw_list);\n"
"    ...\n"
"\n"
"    fvVector.push_back(proto);\n"
"    fvVector.push_back(gw);\n"
"    ...\n"
"    \n"
"    // Push to ROUTE_TABLE via ProducerStateTable.\n"
"    m_routeTable.set(destipprefix, fvVector);\n"
"    SWSS_LOG_DEBUG(\"RouteTable set msg: %s %s %s %s\", destipprefix, "
"gw_list.c_str(), intf_list.c_str(), mpls_list.c_str());\n"
"    ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-swss/fpmsyncd/routesync.cpp\n"
"void RouteSync::onRouteMsg(int nlmsg_type, struct nl_object *obj, char "
"*vrf)\n"
"{\n"
"    // Parse route info from nl_object here.\n"
"    ...\n"
"    \n"
"    // Get nexthop lists\n"
"    string gw_list;\n"
"    string intf_list;\n"
"    string mpls_list;\n"
"    getNextHopList(route_obj, gw_list, mpls_list, intf_list);\n"
"    ...\n"
"\n"
"    // Build route info here, including protocol, interface, next hops, "
"MPLS, weights etc.\n"
"    vector<FieldValueTuple> fvVector;\n"
"    FieldValueTuple proto(\"protocol\", proto_str);\n"
"    FieldValueTuple gw(\"nexthop\", gw_list);\n"
"    ...\n"
"\n"
"    fvVector.push_back(proto);\n"
"    fvVector.push_back(gw);\n"
"    ...\n"
"    \n"
"    // Push to ROUTE_TABLE via ProducerStateTable.\n"
"    m_routeTable.set(destipprefix, fvVector);\n"
"    SWSS_LOG_DEBUG(\"RouteTable set msg: %s %s %s %s\", destipprefix, "
"gw_list.c_str(), intf_list.c_str(), mpls_list.c_str());\n"
"    ...\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:946
msgid "### orchagent处理路由配置变化"
msgstr "### orchagent handles routing configuration changes"

#: src/5-2-2-bgp-route-update-workflow.md:948
msgid ""
"接下来，这些路由信息会来到orchagent。在orchagent启动的时候，它会创建好"
"`VNetRouteOrch`和`RouteOrch`对象，这两个对象分别用来监听和处理Vnet相关路由和"
"EVPN/普通路由："
msgstr ""
"Next, this routing information comes to the orchagent. when the orchagent "
"starts, it creates `VNetRouteOrch` and `RouteOrch` objects, which are used "
"to listen to and process Vnet-related routes and EVPN/general routes, "
"respectively:"

#: src/5-2-2-bgp-route-update-workflow.md:950
msgid ""
"```cpp\n"
"// File: src/sonic-swss/orchagent/orchdaemon.cpp\n"
"bool OrchDaemon::init()\n"
"{\n"
"    ...\n"
"\n"
"    vector<string> vnet_tables = { APP_VNET_RT_TABLE_NAME, "
"APP_VNET_RT_TUNNEL_TABLE_NAME };\n"
"    VNetRouteOrch *vnet_rt_orch = new VNetRouteOrch(m_applDb, vnet_tables, "
"vnet_orch);\n"
"    ...\n"
"\n"
"    const int routeorch_pri = 5;\n"
"    vector<table_name_with_pri_t> route_tables = {\n"
"        { APP_ROUTE_TABLE_NAME,        routeorch_pri },\n"
"        { APP_LABEL_ROUTE_TABLE_NAME,  routeorch_pri }\n"
"    };\n"
"    gRouteOrch = new RouteOrch(m_applDb, route_tables, gSwitchOrch, "
"gNeighOrch, gIntfsOrch, vrf_orch, gFgNhgOrch, gSrv6Orch);\n"
"    ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-swss/orchagent/orchdaemon.cpp\n"
"bool OrchDaemon::init()\n"
"{\n"
"    ...\n"
"\n"
"    vector<string> vnet_tables = { APP_VNET_RT_TABLE_NAME, "
"APP_VNET_RT_TUNNEL_TABLE_NAME };\n"
"    VNetRouteOrch *vnet_rt_orch = new VNetRouteOrch(m_applDb, vnet_tables, "
"vnet_orch);\n"
"    ...\n"
"\n"
"    const int routeorch_pri = 5;\n"
"    vector<table_name_with_pri_t> route_tables = {\n"
"        { APP_ROUTE_TABLE_NAME,        routeorch_pri },\n"
"        { APP_LABEL_ROUTE_TABLE_NAME,  routeorch_pri }\n"
"    };\n"
"    gRouteOrch = new RouteOrch(m_applDb, route_tables, gSwitchOrch, "
"gNeighOrch, gIntfsOrch, vrf_orch, gFgNhgOrch, gSrv6Orch);\n"
"    ...\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:970
msgid ""
"所有Orch对象的消息处理入口都是`doTask`，这里`RouteOrch`和`VNetRouteOrch`也不"
"例外，这里我们以`RouteOrch`为例子，看看它是如何处理路由变化的。"
msgstr ""
"The message processing entry for all Orch objects is `doTask`, here "
"`RouteOrch` and `VNetRouteOrch` are no exception, here we take `RouteOrch` "
"as an example to see how it handles route changes."

#: src/5-2-2-bgp-route-update-workflow.md:972
msgid ""
"```admonish note\n"
"从`RouteOrch`上，我们可以真切的感受到为什么这些类被命名为`Orch`。`RouteOrch`"
"有2500多行，其中会有和很多其他Orch的交互，以及各种各样的细节…… 代码是相对难"
"读，请大家读的时候一定保持耐心。\n"
"```"
msgstr ""
"```admonish note\n"
"从`RouteOrch`上，我们可以真切的感受到为什么这些类被命名为`Orch`。`RouteOrch`"
"有2500多行，其中会有和很多其他Orch的交互，以及各种各样的细节…… 代码是相对难"
"读，请大家读的时候一定保持耐心。\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:976
msgid "`RouteOrch`在处理路由消息的时候有几点需要注意："
msgstr "`RouteOrch` has a few points to note when processing routing messages:"

#: src/5-2-2-bgp-route-update-workflow.md:978
msgid ""
"- 从上面`init`函数，我们可以看到`RouteOrch`不仅会管理普通路由，还会管理MPLS路"
"由，这两种路由的处理逻辑是不一样的，所以在下面的代码中，为了简化，我们只展示"
"普通路由的处理逻辑。\n"
"- 因为`ProducerStateTable`在传递和接受消息的时候都是批量传输的，所以，"
"`RouteOrch`在处理消息的时候，也是批量处理的。为了支持批量处理，`RouteOrch`会"
"借用`EntityBulker<sai_route_api_t> gRouteBulker`将需要改动的SAI路由对象缓存起"
"来，然后在`doTask()`函数的最后，一次性将这些路由对象的改动应用到SAI中。\n"
"- 路由的操作会需要很多其他的信息，比如每个Port的状态，每个Neighbor的状态，每"
"个VRF的状态等等。为了获取这些信息，`RouteOrch`会与其他的Orch对象进行交互，比"
"如`PortOrch`，`NeighOrch`，`VRFOrch`等等。"
msgstr ""
"- From the `init` function above, we can see that `RouteOrch` will manage "
"not only normal routes but also MPLS routes. The processing logic of these "
"two routes is different, so in the following code, for simplicity, we only "
"show the processing logic of normal routes.\n"
"- Because `ProducerStateTable` is transmitted in bulk when delivering and "
"receiving messages, `RouteOrch` is also processed in bulk when processing "
"messages. To support bulk processing, `RouteOrch` borrows "
"`EntityBulker<sai_route_api_t> gRouteBulker` to cache SAI routing objects "
"that need to be changed, and then applies the changes to those routing "
"objects to the SAI at once at the end of the `doTask()` function.\n"
"- The routing operation will require a lot of other information, such as the "
"state of each Port, the state of each Neighbor, the state of each VRF, and "
"so on. To get this information, `RouteOrch` will interact with other Orch "
"objects, such as `PortOrch`, `NeighOrch`, `VRFOrch`, etc."

#: src/5-2-2-bgp-route-update-workflow.md:982
msgid ""
"```cpp\n"
"// File: src/sonic-swss/orchagent/routeorch.cpp\n"
"void RouteOrch::doTask(Consumer& consumer)\n"
"{\n"
"    // Calling PortOrch to make sure all ports are ready before processing "
"route messages.\n"
"    if (!gPortsOrch->allPortsReady()) { return; }\n"
"\n"
"    // Call doLabelTask() instead, if the incoming messages are from MPLS "
"messages. Otherwise, move on as regular routes.\n"
"    ...\n"
"\n"
"    /* Default handling is for ROUTE_TABLE (regular routes) */\n"
"    auto it = consumer.m_toSync.begin();\n"
"    while (it != consumer.m_toSync.end()) {\n"
"        // Add or remove routes with a route bulker\n"
"        while (it != consumer.m_toSync.end())\n"
"        {\n"
"            KeyOpFieldsValuesTuple t = it->second;\n"
"\n"
"            // Parse route operation from the incoming message here.\n"
"            string key = kfvKey(t);\n"
"            string op = kfvOp(t);\n"
"            ...\n"
"\n"
"            // resync application:\n"
"            // - When routeorch receives 'resync' message (key = \"resync\", "
"op = \"SET\"), it marks all current routes as dirty\n"
"            //   and waits for 'resync complete' message. For all newly "
"received routes, if they match current dirty routes,\n"
"            //   it unmarks them dirty.\n"
"            // - After receiving 'resync complete' (key = \"resync\", op != "
"\"SET\") message, it creates all newly added routes\n"
"            //   and removes all dirty routes.\n"
"            ...\n"
"\n"
"            // Parsing VRF and IP prefix from the incoming message here.\n"
"            ...\n"
"\n"
"            // Process regular route operations.\n"
"            if (op == SET_COMMAND)\n"
"            {\n"
"                // Parse and validate route attributes from the incoming "
"message here.\n"
"                string ips;\n"
"                string aliases;\n"
"                ...\n"
"\n"
"                // If the nexthop_group is empty, create the next hop group "
"key based on the IPs and aliases. \n"
"                // Otherwise, get the key from the NhgOrch. The result will "
"be stored in the \"nhg\" variable below.\n"
"                NextHopGroupKey& nhg = ctx.nhg;\n"
"                ...\n"
"                if (nhg_index.empty())\n"
"                {\n"
"                    // Here the nexthop_group is empty, so we create the "
"next hop group key based on the IPs and aliases.\n"
"                    ...\n"
"\n"
"                    string nhg_str = \"\";\n"
"                    if (blackhole) {\n"
"                        nhg = NextHopGroupKey();\n"
"                    } else if (srv6_nh == true) {\n"
"                        ...\n"
"                        nhg = NextHopGroupKey(nhg_str, overlay_nh, "
"srv6_nh);\n"
"                    } else if (overlay_nh == false) {\n"
"                        ...\n"
"                        nhg = NextHopGroupKey(nhg_str, weights);\n"
"                    } else {\n"
"                        ...\n"
"                        nhg = NextHopGroupKey(nhg_str, overlay_nh, "
"srv6_nh);\n"
"                    }\n"
"                }\n"
"                else\n"
"                {\n"
"                    // Here we have a nexthop_group, so we get the key from "
"the NhgOrch.\n"
"                    const NhgBase& nh_group = getNhg(nhg_index);\n"
"                    nhg = nh_group.getNhgKey();\n"
"                    ...\n"
"                }\n"
"                ...\n"
"\n"
"                // Now we start to create the SAI route entry.\n"
"                if (nhg.getSize() == 1 && nhg.hasIntfNextHop())\n"
"                {\n"
"                    // Skip certain routes, such as not valid, directly "
"routes to tun0, linklocal or multicast routes, etc.\n"
"                    ...\n"
"\n"
"                    // Create SAI route entry in addRoute function.\n"
"                    if (addRoute(ctx, nhg)) it = consumer.m_toSync."
"erase(it);\n"
"                    else it++;\n"
"                }\n"
"\n"
"                /*\n"
"                 * Check if the route does not exist or needs to be updated "
"or\n"
"                 * if the route is using a temporary next hop group owned "
"by\n"
"                 * NhgOrch.\n"
"                 */\n"
"                else if (m_syncdRoutes.find(vrf_id) == m_syncdRoutes.end() "
"||\n"
"                    m_syncdRoutes.at(vrf_id).find(ip_prefix) == "
"m_syncdRoutes.at(vrf_id).end() ||\n"
"                    m_syncdRoutes.at(vrf_id).at(ip_prefix) != RouteNhg(nhg, "
"ctx.nhg_index) ||\n"
"                    gRouteBulker.bulk_entry_pending_removal(route_entry) ||\n"
"                    ctx.using_temp_nhg)\n"
"                {\n"
"                    if (addRoute(ctx, nhg)) it = consumer.m_toSync."
"erase(it);\n"
"                    else it++;\n"
"                }\n"
"                ...\n"
"            }\n"
"            // Handle other ops, like DEL_COMMAND for route deletion, etc.\n"
"            ...\n"
"        }\n"
"\n"
"        // Flush the route bulker, so routes will be written to syncd and "
"ASIC\n"
"        gRouteBulker.flush();\n"
"\n"
"        // Go through the bulker results.\n"
"        // Handle SAI failures, update neighbors, counters, send "
"notifications in add/removeRoutePost functions.\n"
"        ... \n"
"\n"
"        /* Remove next hop group if the reference count decreases to zero "
"*/\n"
"        ...\n"
"    }\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-swss/orchagent/routeorch.cpp\n"
"void RouteOrch::doTask(Consumer& consumer)\n"
"{\n"
"    // Calling PortOrch to make sure all ports are ready before processing "
"route messages.\n"
"    if (!gPortsOrch->allPortsReady()) { return; }\n"
"\n"
"    // Call doLabelTask() instead, if the incoming messages are from MPLS "
"messages. Otherwise, move on as regular routes.\n"
"    ...\n"
"\n"
"    /* Default handling is for ROUTE_TABLE (regular routes) */\n"
"    auto it = consumer.m_toSync.begin();\n"
"    while (it != consumer.m_toSync.end()) {\n"
"        // Add or remove routes with a route bulker\n"
"        while (it != consumer.m_toSync.end())\n"
"        {\n"
"            KeyOpFieldsValuesTuple t = it->second;\n"
"\n"
"            // Parse route operation from the incoming message here.\n"
"            string key = kfvKey(t);\n"
"            string op = kfvOp(t);\n"
"            ...\n"
"\n"
"            // resync application:\n"
"            // - When routeorch receives 'resync' message (key = \"resync\", "
"op = \"SET\"), it marks all current routes as dirty\n"
"            //   and waits for 'resync complete' message. For all newly "
"received routes, if they match current dirty routes,\n"
"            //   it unmarks them dirty.\n"
"            // - After receiving 'resync complete' (key = \"resync\", op != "
"\"SET\") message, it creates all newly added routes\n"
"            //   and removes all dirty routes.\n"
"            ...\n"
"\n"
"            // Parsing VRF and IP prefix from the incoming message here.\n"
"            ...\n"
"\n"
"            // Process regular route operations.\n"
"            if (op == SET_COMMAND)\n"
"            {\n"
"                // Parse and validate route attributes from the incoming "
"message here.\n"
"                string ips;\n"
"                string aliases;\n"
"                ...\n"
"\n"
"                // If the nexthop_group is empty, create the next hop group "
"key based on the IPs and aliases. \n"
"                // Otherwise, get the key from the NhgOrch. The result will "
"be stored in the \"nhg\" variable below.\n"
"                NextHopGroupKey& nhg = ctx.nhg;\n"
"                ...\n"
"                if (nhg_index.empty())\n"
"                {\n"
"                    // Here the nexthop_group is empty, so we create the "
"next hop group key based on the IPs and aliases.\n"
"                    ...\n"
"\n"
"                    string nhg_str = \"\";\n"
"                    if (blackhole) {\n"
"                        nhg = NextHopGroupKey();\n"
"                    } else if (srv6_nh == true) {\n"
"                        ...\n"
"                        nhg = NextHopGroupKey(nhg_str, overlay_nh, "
"srv6_nh);\n"
"                    } else if (overlay_nh == false) {\n"
"                        ...\n"
"                        nhg = NextHopGroupKey(nhg_str, weights);\n"
"                    } else {\n"
"                        ...\n"
"                        nhg = NextHopGroupKey(nhg_str, overlay_nh, "
"srv6_nh);\n"
"                    }\n"
"                }\n"
"                else\n"
"                {\n"
"                    // Here we have a nexthop_group, so we get the key from "
"the NhgOrch.\n"
"                    const NhgBase& nh_group = getNhg(nhg_index);\n"
"                    nhg = nh_group.getNhgKey();\n"
"                    ...\n"
"                }\n"
"                ...\n"
"\n"
"                // Now we start to create the SAI route entry.\n"
"                if (nhg.getSize() == 1 && nhg.hasIntfNextHop())\n"
"                {\n"
"                    // Skip certain routes, such as not valid, directly "
"routes to tun0, linklocal or multicast routes, etc.\n"
"                    ...\n"
"\n"
"                    // Create SAI route entry in addRoute function.\n"
"                    if (addRoute(ctx, nhg)) it = consumer.m_toSync."
"erase(it);\n"
"                    else it++;\n"
"                }\n"
"\n"
"                /*\n"
"                 * Check if the route does not exist or needs to be updated "
"or\n"
"                 * if the route is using a temporary next hop group owned "
"by\n"
"                 * NhgOrch.\n"
"                 */\n"
"                else if (m_syncdRoutes.find(vrf_id) == m_syncdRoutes.end() "
"||\n"
"                    m_syncdRoutes.at(vrf_id).find(ip_prefix) == "
"m_syncdRoutes.at(vrf_id).end() ||\n"
"                    m_syncdRoutes.at(vrf_id).at(ip_prefix) != RouteNhg(nhg, "
"ctx.nhg_index) ||\n"
"                    gRouteBulker.bulk_entry_pending_removal(route_entry) ||\n"
"                    ctx.using_temp_nhg)\n"
"                {\n"
"                    if (addRoute(ctx, nhg)) it = consumer.m_toSync."
"erase(it);\n"
"                    else it++;\n"
"                }\n"
"                ...\n"
"            }\n"
"            // Handle other ops, like DEL_COMMAND for route deletion, etc.\n"
"            ...\n"
"        }\n"
"\n"
"        // Flush the route bulker, so routes will be written to syncd and "
"ASIC\n"
"        gRouteBulker.flush();\n"
"\n"
"        // Go through the bulker results.\n"
"        // Handle SAI failures, update neighbors, counters, send "
"notifications in add/removeRoutePost functions.\n"
"        ... \n"
"\n"
"        /* Remove next hop group if the reference count decreases to zero "
"*/\n"
"        ...\n"
"    }\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:1100
msgid ""
"解析完路由操作后，`RouteOrch`会调用`addRoute`或者`removeRoute`函数来创建或者"
"删除路由。这里以添加路由`addRoute`为例子来继续分析。它的逻辑主要分为几个大部"
"分："
msgstr ""
"After parsing the route operation, `RouteOrch` will call the `addRoute` or "
"`removeRoute` functions to create or remove routes. Here is an example of "
"adding a route `addRoute` to continue the analysis. Its logic is divided "
"into several main parts:"

#: src/5-2-2-bgp-route-update-workflow.md:1102
msgid ""
"1. 从NeighOrch中获取下一跳信息，并检查下一跳是否真的可用。\n"
"2. 如果是新路由，或者是重新添加正在等待删除的路由，那么就会创建一个新的SAI路"
"由对象\n"
"3. 如果是已有的路由，那么就更新已有的SAI路由对象"
msgstr ""
"1. Get the next hop information from NeighOrch and check if the next hop is "
"really available.\n"
"2. If it is a new route, or a re-add route that is waiting to be deleted, "
"then a new SAI route object is created\n"
"3. If it is an existing route, then update the existing SAI routing object"

#: src/5-2-2-bgp-route-update-workflow.md:1106
msgid ""
"```cpp\n"
"// File: src/sonic-swss/orchagent/routeorch.cpp\n"
"bool RouteOrch::addRoute(RouteBulkContext& ctx, const NextHopGroupKey "
"&nextHops)\n"
"{\n"
"    // Get nexthop information from NeighOrch.\n"
"    // We also need to check PortOrch for inband port, IntfsOrch to ensure "
"the related interface is created and etc.\n"
"    ...\n"
"    \n"
"    // Start to sync the SAI route entry.\n"
"    sai_route_entry_t route_entry;\n"
"    route_entry.vr_id = vrf_id;\n"
"    route_entry.switch_id = gSwitchId;\n"
"    copy(route_entry.destination, ipPrefix);\n"
"\n"
"    sai_attribute_t route_attr;\n"
"    auto& object_statuses = ctx.object_statuses;\n"
"    \n"
"    // Create a new route entry in this case.\n"
"    //\n"
"    // In case the entry is already pending removal in the bulk, it would be "
"removed from m_syncdRoutes during the bulk call.\n"
"    // Therefore, such entries need to be re-created rather than set "
"attribute.\n"
"    if (it_route == m_syncdRoutes.at(vrf_id).end() || gRouteBulker."
"bulk_entry_pending_removal(route_entry)) {\n"
"        if (blackhole) {\n"
"            route_attr.id = SAI_ROUTE_ENTRY_ATTR_PACKET_ACTION;\n"
"            route_attr.value.s32 = SAI_PACKET_ACTION_DROP;\n"
"        } else {\n"
"            route_attr.id = SAI_ROUTE_ENTRY_ATTR_NEXT_HOP_ID;\n"
"            route_attr.value.oid = next_hop_id;\n"
"        }\n"
"\n"
"        /* Default SAI_ROUTE_ATTR_PACKET_ACTION is SAI_PACKET_ACTION_FORWARD "
"*/\n"
"        object_statuses.emplace_back();\n"
"        sai_status_t status = gRouteBulker.create_entry(&object_statuses."
"back(), &route_entry, 1, &route_attr);\n"
"        if (status == SAI_STATUS_ITEM_ALREADY_EXISTS) {\n"
"            return false;\n"
"        }\n"
"    }\n"
"    \n"
"    // Update existing route entry in this case.\n"
"    else {\n"
"        // Set the packet action to forward when there was no next hop "
"(dropped) and not pointing to blackhole.\n"
"        if (it_route->second.nhg_key.getSize() == 0 && !blackhole) {\n"
"            route_attr.id = SAI_ROUTE_ENTRY_ATTR_PACKET_ACTION;\n"
"            route_attr.value.s32 = SAI_PACKET_ACTION_FORWARD;\n"
"\n"
"            object_statuses.emplace_back();\n"
"            gRouteBulker.set_entry_attribute(&object_statuses.back(), "
"&route_entry, &route_attr);\n"
"        }\n"
"\n"
"        // Only 1 case is listed here as an example. Other cases are handled "
"with similar logic by calling set_entry_attributes as well.\n"
"        ...\n"
"    }\n"
"    ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-swss/orchagent/routeorch.cpp\n"
"bool RouteOrch::addRoute(RouteBulkContext& ctx, const NextHopGroupKey "
"&nextHops)\n"
"{\n"
"    // Get nexthop information from NeighOrch.\n"
"    // We also need to check PortOrch for inband port, IntfsOrch to ensure "
"the related interface is created and etc.\n"
"    ...\n"
"    \n"
"    // Start to sync the SAI route entry.\n"
"    sai_route_entry_t route_entry;\n"
"    route_entry.vr_id = vrf_id;\n"
"    route_entry.switch_id = gSwitchId;\n"
"    copy(route_entry.destination, ipPrefix);\n"
"\n"
"    sai_attribute_t route_attr;\n"
"    auto& object_statuses = ctx.object_statuses;\n"
"    \n"
"    // Create a new route entry in this case.\n"
"    //\n"
"    // In case the entry is already pending removal in the bulk, it would be "
"removed from m_syncdRoutes during the bulk call.\n"
"    // Therefore, such entries need to be re-created rather than set "
"attribute.\n"
"    if (it_route == m_syncdRoutes.at(vrf_id).end() || gRouteBulker."
"bulk_entry_pending_removal(route_entry)) {\n"
"        if (blackhole) {\n"
"            route_attr.id = SAI_ROUTE_ENTRY_ATTR_PACKET_ACTION;\n"
"            route_attr.value.s32 = SAI_PACKET_ACTION_DROP;\n"
"        } else {\n"
"            route_attr.id = SAI_ROUTE_ENTRY_ATTR_NEXT_HOP_ID;\n"
"            route_attr.value.oid = next_hop_id;\n"
"        }\n"
"\n"
"        /* Default SAI_ROUTE_ATTR_PACKET_ACTION is SAI_PACKET_ACTION_FORWARD "
"*/\n"
"        object_statuses.emplace_back();\n"
"        sai_status_t status = gRouteBulker.create_entry(&object_statuses."
"back(), &route_entry, 1, &route_attr);\n"
"        if (status == SAI_STATUS_ITEM_ALREADY_EXISTS) {\n"
"            return false;\n"
"        }\n"
"    }\n"
"    \n"
"    // Update existing route entry in this case.\n"
"    else {\n"
"        // Set the packet action to forward when there was no next hop "
"(dropped) and not pointing to blackhole.\n"
"        if (it_route->second.nhg_key.getSize() == 0 && !blackhole) {\n"
"            route_attr.id = SAI_ROUTE_ENTRY_ATTR_PACKET_ACTION;\n"
"            route_attr.value.s32 = SAI_PACKET_ACTION_FORWARD;\n"
"\n"
"            object_statuses.emplace_back();\n"
"            gRouteBulker.set_entry_attribute(&object_statuses.back(), "
"&route_entry, &route_attr);\n"
"        }\n"
"\n"
"        // Only 1 case is listed here as an example. Other cases are handled "
"with similar logic by calling set_entry_attributes as well.\n"
"        ...\n"
"    }\n"
"    ...\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:1162
msgid ""
"在创建和设置好所有的路由后，`RouteOrch`会调用`gRouteBulker.flush()`来将所有的"
"路由写入到ASIC_DB中。`flush()`函数很简单，就是将所有的请求分批次进行处理，默"
"认情况下每一批是1000个，这个定义在`OrchDaemon`中，并通过构造函数传入："
msgstr ""
"After all the routes have been created and set up, `RouteOrch` calls "
"`gRouteBulker.flush()` to write all the routes to the ASIC_DB. The `flush()` "
"function is simply a function that processes all requests in batches, by "
"default 1000 per batch, this is defined in the `OrchDaemon` and passed in "
"via the constructor:"

#: src/5-2-2-bgp-route-update-workflow.md:1164
msgid ""
"```cpp\n"
"// File: src/sonic-swss/orchagent/orchdaemon.cpp\n"
"#define DEFAULT_MAX_BULK_SIZE 1000\n"
"size_t gMaxBulkSize = DEFAULT_MAX_BULK_SIZE;\n"
"\n"
"// File: src/sonic-swss/orchagent/bulker.h\n"
"template <typename T>\n"
"class EntityBulker\n"
"{\n"
"public:\n"
"    using Ts = SaiBulkerTraits<T>;\n"
"    using Te = typename Ts::entry_t;\n"
"    ...\n"
"\n"
"    void flush()\n"
"    {\n"
"        // Bulk remove entries\n"
"        if (!removing_entries.empty()) {\n"
"            // Split into batches of max_bulk_size, then call flush. Similar "
"to creating_entries, so details are omitted.\n"
"            std::vector<Te> rs;\n"
"            ...\n"
"            flush_removing_entries(rs);\n"
"            removing_entries.clear();\n"
"        }\n"
"\n"
"        // Bulk create entries\n"
"        if (!creating_entries.empty()) {\n"
"            // Split into batches of max_bulk_size, then call "
"flush_creating_entries to call SAI batch create API to create\n"
"            // the objects in batch.\n"
"            std::vector<Te> rs;\n"
"            std::vector<sai_attribute_t const*> tss;\n"
"            std::vector<uint32_t> cs;\n"
"            \n"
"            for (auto const& i: creating_entries) {\n"
"                sai_object_id_t *pid = std::get<0>(i);\n"
"                auto const& attrs = std::get<1>(i);\n"
"                if (*pid == SAI_NULL_OBJECT_ID) {\n"
"                    rs.push_back(pid);\n"
"                    tss.push_back(attrs.data());\n"
"                    cs.push_back((uint32_t)attrs.size());\n"
"\n"
"                    // Batch create here.\n"
"                    if (rs.size() >= max_bulk_size) {\n"
"                        flush_creating_entries(rs, tss, cs);\n"
"                    }\n"
"                }\n"
"            }\n"
"\n"
"            flush_creating_entries(rs, tss, cs);\n"
"            creating_entries.clear();\n"
"        }\n"
"\n"
"        // Bulk update existing entries\n"
"        if (!setting_entries.empty()) {\n"
"            // Split into batches of max_bulk_size, then call flush. Similar "
"to creating_entries, so details are omitted.\n"
"            std::vector<Te> rs;\n"
"            std::vector<sai_attribute_t> ts;\n"
"            std::vector<sai_status_t*> status_vector;\n"
"            ...\n"
"            flush_setting_entries(rs, ts, status_vector);\n"
"            setting_entries.clear();\n"
"        }\n"
"    }\n"
"\n"
"    sai_status_t flush_creating_entries(\n"
"        _Inout_ std::vector<Te> &rs,\n"
"        _Inout_ std::vector<sai_attribute_t const*> &tss,\n"
"        _Inout_ std::vector<uint32_t> &cs)\n"
"    {\n"
"        ...\n"
"\n"
"        // Call SAI bulk create API\n"
"        size_t count = rs.size();\n"
"        std::vector<sai_status_t> statuses(count);\n"
"        sai_status_t status = (*create_entries)((uint32_t)count, rs.data(), "
"cs.data(), tss.data()\n"
"            , SAI_BULK_OP_ERROR_MODE_IGNORE_ERROR, statuses.data());\n"
"\n"
"        // Set results back to input entries and clean up the batch below.\n"
"        for (size_t ir = 0; ir < count; ir++) {\n"
"            auto& entry = rs[ir];\n"
"            sai_status_t *object_status = creating_entries[entry].second;\n"
"            if (object_status) {\n"
"                *object_status = statuses[ir];\n"
"            }\n"
"        }\n"
"\n"
"        rs.clear(); tss.clear(); cs.clear();\n"
"        return status;\n"
"    }\n"
"\n"
"    // flush_removing_entries and flush_setting_entries are similar to "
"flush_creating_entries, so we omit them here.\n"
"    ...\n"
"};\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-swss/orchagent/orchdaemon.cpp\n"
"#define DEFAULT_MAX_BULK_SIZE 1000\n"
"size_t gMaxBulkSize = DEFAULT_MAX_BULK_SIZE;\n"
"\n"
"// File: src/sonic-swss/orchagent/bulker.h\n"
"template <typename T>\n"
"class EntityBulker\n"
"{\n"
"public:\n"
"    using Ts = SaiBulkerTraits<T>;\n"
"    using Te = typename Ts::entry_t;\n"
"    ...\n"
"\n"
"    void flush()\n"
"    {\n"
"        // Bulk remove entries\n"
"        if (!removing_entries.empty()) {\n"
"            // Split into batches of max_bulk_size, then call flush. Similar "
"to creating_entries, so details are omitted.\n"
"            std::vector<Te> rs;\n"
"            ...\n"
"            flush_removing_entries(rs);\n"
"            removing_entries.clear();\n"
"        }\n"
"\n"
"        // Bulk create entries\n"
"        if (!creating_entries.empty()) {\n"
"            // Split into batches of max_bulk_size, then call "
"flush_creating_entries to call SAI batch create API to create\n"
"            // the objects in batch.\n"
"            std::vector<Te> rs;\n"
"            std::vector<sai_attribute_t const*> tss;\n"
"            std::vector<uint32_t> cs;\n"
"            \n"
"            for (auto const& i: creating_entries) {\n"
"                sai_object_id_t *pid = std::get<0>(i);\n"
"                auto const& attrs = std::get<1>(i);\n"
"                if (*pid == SAI_NULL_OBJECT_ID) {\n"
"                    rs.push_back(pid);\n"
"                    tss.push_back(attrs.data());\n"
"                    cs.push_back((uint32_t)attrs.size());\n"
"\n"
"                    // Batch create here.\n"
"                    if (rs.size() >= max_bulk_size) {\n"
"                        flush_creating_entries(rs, tss, cs);\n"
"                    }\n"
"                }\n"
"            }\n"
"\n"
"            flush_creating_entries(rs, tss, cs);\n"
"            creating_entries.clear();\n"
"        }\n"
"\n"
"        // Bulk update existing entries\n"
"        if (!setting_entries.empty()) {\n"
"            // Split into batches of max_bulk_size, then call flush. Similar "
"to creating_entries, so details are omitted.\n"
"            std::vector<Te> rs;\n"
"            std::vector<sai_attribute_t> ts;\n"
"            std::vector<sai_status_t*> status_vector;\n"
"            ...\n"
"            flush_setting_entries(rs, ts, status_vector);\n"
"            setting_entries.clear();\n"
"        }\n"
"    }\n"
"\n"
"    sai_status_t flush_creating_entries(\n"
"        _Inout_ std::vector<Te> &rs,\n"
"        _Inout_ std::vector<sai_attribute_t const*> &tss,\n"
"        _Inout_ std::vector<uint32_t> &cs)\n"
"    {\n"
"        ...\n"
"\n"
"        // Call SAI bulk create API\n"
"        size_t count = rs.size();\n"
"        std::vector<sai_status_t> statuses(count);\n"
"        sai_status_t status = (*create_entries)((uint32_t)count, rs.data(), "
"cs.data(), tss.data()\n"
"            , SAI_BULK_OP_ERROR_MODE_IGNORE_ERROR, statuses.data());\n"
"\n"
"        // Set results back to input entries and clean up the batch below.\n"
"        for (size_t ir = 0; ir < count; ir++) {\n"
"            auto& entry = rs[ir];\n"
"            sai_status_t *object_status = creating_entries[entry].second;\n"
"            if (object_status) {\n"
"                *object_status = statuses[ir];\n"
"            }\n"
"        }\n"
"\n"
"        rs.clear(); tss.clear(); cs.clear();\n"
"        return status;\n"
"    }\n"
"\n"
"    // flush_removing_entries and flush_setting_entries are similar to "
"flush_creating_entries, so we omit them here.\n"
"    ...\n"
"};\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:1259
msgid "### orchagent中的SAI对象转发"
msgstr "### SAI object forwarding in orchagent"

#: src/5-2-2-bgp-route-update-workflow.md:1261
msgid ""
"细心的小伙伴肯定已经发现了奇怪的地方，这里`EntityBulker`怎么看着像在直接调用"
"SAI API呢？难道它们不应该是在syncd中调用的吗？如果我们对传入`EntityBulker`的"
"SAI API对象进行跟踪，我们甚至会找到sai_route_api_t就是SAI的接口，而"
"`orchagent`中还有SAI的初始化代码，如下："
msgstr ""
"Careful partners must have found a strange place, here `EntityBulker` how to "
"look like in a direct call to the SAI API it? Aren't they supposed to be "
"called in syncd? If we trace the SAI API object passed into `EntityBulker`, "
"we will even find that sai_route_api_t is the SAI interface, and there is "
"SAI initialization code in `orchagent`, as follows:"

#: src/5-2-2-bgp-route-update-workflow.md:1263
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/debian/libsaivs-dev/usr/include/sai/sairoute.h\n"
"/**\n"
" * @brief Router entry methods table retrieved with sai_api_query()\n"
" */\n"
"typedef struct _sai_route_api_t\n"
"{\n"
"    sai_create_route_entry_fn                   create_route_entry;\n"
"    sai_remove_route_entry_fn                   remove_route_entry;\n"
"    sai_set_route_entry_attribute_fn            set_route_entry_attribute;\n"
"    sai_get_route_entry_attribute_fn            get_route_entry_attribute;\n"
"\n"
"    sai_bulk_create_route_entry_fn              create_route_entries;\n"
"    sai_bulk_remove_route_entry_fn              remove_route_entries;\n"
"    sai_bulk_set_route_entry_attribute_fn       "
"set_route_entries_attribute;\n"
"    sai_bulk_get_route_entry_attribute_fn       "
"get_route_entries_attribute;\n"
"} sai_route_api_t;\n"
"\n"
"// File: src/sonic-swss/orchagent/saihelper.cpp\n"
"void initSaiApi()\n"
"{\n"
"    SWSS_LOG_ENTER();\n"
"\n"
"    if (ifstream(CONTEXT_CFG_FILE))\n"
"    {\n"
"        SWSS_LOG_NOTICE(\"Context config file %s exists\", "
"CONTEXT_CFG_FILE);\n"
"        gProfileMap[SAI_REDIS_KEY_CONTEXT_CONFIG] = CONTEXT_CFG_FILE;\n"
"    }\n"
"\n"
"    sai_api_initialize(0, (const sai_service_method_table_t "
"*)&test_services);\n"
"    sai_api_query(SAI_API_SWITCH,               (void **)&sai_switch_api);\n"
"    ...\n"
"    sai_api_query(SAI_API_NEIGHBOR,             (void "
"**)&sai_neighbor_api);\n"
"    sai_api_query(SAI_API_NEXT_HOP,             (void "
"**)&sai_next_hop_api);\n"
"    sai_api_query(SAI_API_NEXT_HOP_GROUP,       (void "
"**)&sai_next_hop_group_api);\n"
"    sai_api_query(SAI_API_ROUTE,                (void **)&sai_route_api);\n"
"    ...\n"
"\n"
"    sai_log_set(SAI_API_SWITCH,                 SAI_LOG_LEVEL_NOTICE);\n"
"    ...\n"
"    sai_log_set(SAI_API_NEIGHBOR,               SAI_LOG_LEVEL_NOTICE);\n"
"    sai_log_set(SAI_API_NEXT_HOP,               SAI_LOG_LEVEL_NOTICE);\n"
"    sai_log_set(SAI_API_NEXT_HOP_GROUP,         SAI_LOG_LEVEL_NOTICE);\n"
"    sai_log_set(SAI_API_ROUTE,                  SAI_LOG_LEVEL_NOTICE);\n"
"    ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/debian/libsaivs-dev/usr/include/sai/sairoute.h\n"
"/**\n"
" * @brief Router entry methods table retrieved with sai_api_query()\n"
" */\n"
"typedef struct _sai_route_api_t\n"
"{\n"
"    sai_create_route_entry_fn                   create_route_entry;\n"
"    sai_remove_route_entry_fn                   remove_route_entry;\n"
"    sai_set_route_entry_attribute_fn            set_route_entry_attribute;\n"
"    sai_get_route_entry_attribute_fn            get_route_entry_attribute;\n"
"\n"
"    sai_bulk_create_route_entry_fn              create_route_entries;\n"
"    sai_bulk_remove_route_entry_fn              remove_route_entries;\n"
"    sai_bulk_set_route_entry_attribute_fn       "
"set_route_entries_attribute;\n"
"    sai_bulk_get_route_entry_attribute_fn       "
"get_route_entries_attribute;\n"
"} sai_route_api_t;\n"
"\n"
"// File: src/sonic-swss/orchagent/saihelper.cpp\n"
"void initSaiApi()\n"
"{\n"
"    SWSS_LOG_ENTER();\n"
"\n"
"    if (ifstream(CONTEXT_CFG_FILE))\n"
"    {\n"
"        SWSS_LOG_NOTICE(\"Context config file %s exists\", "
"CONTEXT_CFG_FILE);\n"
"        gProfileMap[SAI_REDIS_KEY_CONTEXT_CONFIG] = CONTEXT_CFG_FILE;\n"
"    }\n"
"\n"
"    sai_api_initialize(0, (const sai_service_method_table_t "
"*)&test_services);\n"
"    sai_api_query(SAI_API_SWITCH,               (void **)&sai_switch_api);\n"
"    ...\n"
"    sai_api_query(SAI_API_NEIGHBOR,             (void "
"**)&sai_neighbor_api);\n"
"    sai_api_query(SAI_API_NEXT_HOP,             (void "
"**)&sai_next_hop_api);\n"
"    sai_api_query(SAI_API_NEXT_HOP_GROUP,       (void "
"**)&sai_next_hop_group_api);\n"
"    sai_api_query(SAI_API_ROUTE,                (void **)&sai_route_api);\n"
"    ...\n"
"\n"
"    sai_log_set(SAI_API_SWITCH,                 SAI_LOG_LEVEL_NOTICE);\n"
"    ...\n"
"    sai_log_set(SAI_API_NEIGHBOR,               SAI_LOG_LEVEL_NOTICE);\n"
"    sai_log_set(SAI_API_NEXT_HOP,               SAI_LOG_LEVEL_NOTICE);\n"
"    sai_log_set(SAI_API_NEXT_HOP_GROUP,         SAI_LOG_LEVEL_NOTICE);\n"
"    sai_log_set(SAI_API_ROUTE,                  SAI_LOG_LEVEL_NOTICE);\n"
"    ...\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:1311
msgid ""
"相信大家第一次看到这个代码会感觉到非常的困惑。不过别着急，这其实就是"
"`orchagent`中SAI对象的转发机制。"
msgstr ""
"I believe you will feel very confused when you see this code for the first "
"time. But don't worry, this is actually the forwarding mechanism of SAI "
"objects in `orchagent`."

#: src/5-2-2-bgp-route-update-workflow.md:1313
msgid ""
"熟悉RPC的小伙伴一定不会对`proxy-stub`模式感到陌生 —— 利用统一的接口来定义通信"
"双方调用接口，在调用方实现序列化和发送，然后再接收方实现接收，反序列化与分"
"发。这里SONiC的做法也是类似的：利用SAI API本身作为统一的接口，并实现好序列化"
"和发送功能给`orchagent`来调用，然后再`syncd`中实现接收，反序列化与分发功能。"
msgstr ""
"The `proxy-stub` pattern must be familiar to the RPC partners will not be "
"unfamiliar to the `proxy-stub` pattern -- the use of a unified interface to "
"define the communication between the two sides to call the interface, the "
"caller to achieve serialization and send, and then the receiver to achieve "
"the reception, deserialization and distribution. The SONiC approach is "
"similar: use the SAI API itself as a unified interface, and implement the "
"serialization and sending functions for `orchagent` to call, and then "
"implement the receiving, deserialization and distribution functions in "
"`syncd`."

#: src/5-2-2-bgp-route-update-workflow.md:1315
msgid ""
"这里，发送端叫做`ClientSai`，实现在`src/sonic-sairedis/lib/ClientSai.*`中。而"
"序列化与反序列化实现在SAI metadata中：`src/sonic-sairedis/meta/sai_serialize."
"h`："
msgstr ""
"Here, the sender is called `ClientSai`, and the implementation is in `src/"
"sonic-sairedis/lib/ClientSai.*`. And the serialization and deserialization "
"implementation is in the SAI metadata: `src/sonic-sairedis/meta/"
"sai_serialize.h`:"

#: src/5-2-2-bgp-route-update-workflow.md:1317
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/lib/ClientSai.h\n"
"namespace sairedis\n"
"{\n"
"    class ClientSai:\n"
"        public sairedis::SaiInterface\n"
"    {\n"
"        ...\n"
"    };\n"
"}\n"
"\n"
"// File: src/sonic-sairedis/meta/sai_serialize.h\n"
"// Serialize\n"
"std::string sai_serialize_route_entry(_In_ const sai_route_entry_t "
"&route_entry);\n"
"...\n"
"\n"
"// Deserialize\n"
"void sai_deserialize_route_entry(_In_ const std::string& s, _In_ "
"sai_route_entry_t &route_entry);\n"
"...\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/lib/ClientSai.h\n"
"namespace sairedis\n"
"{\n"
"    class ClientSai:\n"
"        public sairedis::SaiInterface\n"
"    {\n"
"        ...\n"
"    };\n"
"}\n"
"\n"
"// File: src/sonic-sairedis/meta/sai_serialize.h\n"
"// Serialize\n"
"std::string sai_serialize_route_entry(_In_ const sai_route_entry_t "
"&route_entry);\n"
"...\n"
"\n"
"// Deserialize\n"
"void sai_deserialize_route_entry(_In_ const std::string& s, _In_ "
"sai_route_entry_t &route_entry);\n"
"...\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:1338
msgid ""
"`orchagent`在编译的时候，会去链接`libsairedis`，从而实现调用SAI API时，对SAI"
"对象进行序列化和发送："
msgstr ""
"`orchagent` goes to link `libsairedis` at compile time, thus enabling "
"serialization and sending of SAI objects when calling the SAI API:"

#: src/5-2-2-bgp-route-update-workflow.md:1340
msgid ""
"```makefile\n"
"# File: src/sonic-swss/orchagent/Makefile.am\n"
"orchagent_LDADD = $(LDFLAGS_ASAN) -lnl-3 -lnl-route-3 -lpthread -lsairedis -"
"lsaimeta -lsaimetadata -lswsscommon -lzmq\n"
"```"
msgstr ""
"```makefile\n"
"# File: src/sonic-swss/orchagent/Makefile.am\n"
"orchagent_LDADD = $(LDFLAGS_ASAN) -lnl-3 -lnl-route-3 -lpthread -lsairedis -"
"lsaimeta -lsaimetadata -lswsscommon -lzmq\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:1345
msgid ""
"我们这里用Bulk Create作为例子，来看看`ClientSai`是如何实现序列化和发送的："
msgstr ""
"We use Bulk Create as an example here to see how `ClientSai` implements "
"serialization and sends:"

#: src/5-2-2-bgp-route-update-workflow.md:1347
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/lib/ClientSai.cpp\n"
"sai_status_t ClientSai::bulkCreate(\n"
"        _In_ sai_object_type_t object_type,\n"
"        _In_ sai_object_id_t switch_id,\n"
"        _In_ uint32_t object_count,\n"
"        _In_ const uint32_t *attr_count,\n"
"        _In_ const sai_attribute_t **attr_list,\n"
"        _In_ sai_bulk_op_error_mode_t mode,\n"
"        _Out_ sai_object_id_t *object_id,\n"
"        _Out_ sai_status_t *object_statuses)\n"
"{\n"
"    MUTEX();\n"
"    REDIS_CHECK_API_INITIALIZED();\n"
"\n"
"    std::vector<std::string> serialized_object_ids;\n"
"\n"
"    // Server is responsible for generate new OID but for that we need "
"switch ID\n"
"    // to be sent to server as well, so instead of sending empty oids we "
"will\n"
"    // send switch IDs\n"
"    for (uint32_t idx = 0; idx < object_count; idx++) {\n"
"        serialized_object_ids."
"emplace_back(sai_serialize_object_id(switch_id));\n"
"    }\n"
"    auto status = bulkCreate(object_type, serialized_object_ids, attr_count, "
"attr_list, mode, object_statuses);\n"
"\n"
"    // Since user requested create, OID value was created remotely and it "
"was returned in m_lastCreateOids\n"
"    for (uint32_t idx = 0; idx < object_count; idx++) {\n"
"        if (object_statuses[idx] == SAI_STATUS_SUCCESS) {\n"
"            object_id[idx] = m_lastCreateOids.at(idx);\n"
"        } else {\n"
"            object_id[idx] = SAI_NULL_OBJECT_ID;\n"
"        }\n"
"    }\n"
"\n"
"    return status;\n"
"}\n"
"\n"
"sai_status_t ClientSai::bulkCreate(\n"
"        _In_ sai_object_type_t object_type,\n"
"        _In_ const std::vector<std::string> &serialized_object_ids,\n"
"        _In_ const uint32_t *attr_count,\n"
"        _In_ const sai_attribute_t **attr_list,\n"
"        _In_ sai_bulk_op_error_mode_t mode,\n"
"        _Inout_ sai_status_t *object_statuses)\n"
"{\n"
"    ...\n"
"\n"
"    // Calling SAI serialize APIs to serialize all objects\n"
"    std::string str_object_type = sai_serialize_object_type(object_type);\n"
"    std::vector<swss::FieldValueTuple> entries;\n"
"    for (size_t idx = 0; idx < serialized_object_ids.size(); ++idx) {\n"
"        auto entry = SaiAttributeList::serialize_attr_list(object_type, "
"attr_count[idx], attr_list[idx], false);\n"
"        if (entry.empty()) {\n"
"            swss::FieldValueTuple null(\"NULL\", \"NULL\");\n"
"            entry.push_back(null);\n"
"        }\n"
"\n"
"        std::string str_attr = Globals::joinFieldValues(entry);\n"
"        swss::FieldValueTuple fvtNoStatus(serialized_object_ids[idx] , "
"str_attr);\n"
"        entries.push_back(fvtNoStatus);\n"
"    }\n"
"    std::string key = str_object_type + \":\" + std::to_string(entries."
"size());\n"
"\n"
"    // Send to syncd via the communication channel.\n"
"    m_communicationChannel->set(key, entries, "
"REDIS_ASIC_STATE_COMMAND_BULK_CREATE);\n"
"\n"
"    // Wait for response from syncd.\n"
"    return waitForBulkResponse(SAI_COMMON_API_BULK_CREATE, "
"(uint32_t)serialized_object_ids.size(), object_statuses);\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/lib/ClientSai.cpp\n"
"sai_status_t ClientSai::bulkCreate(\n"
"        _In_ sai_object_type_t object_type,\n"
"        _In_ sai_object_id_t switch_id,\n"
"        _In_ uint32_t object_count,\n"
"        _In_ const uint32_t *attr_count,\n"
"        _In_ const sai_attribute_t **attr_list,\n"
"        _In_ sai_bulk_op_error_mode_t mode,\n"
"        _Out_ sai_object_id_t *object_id,\n"
"        _Out_ sai_status_t *object_statuses)\n"
"{\n"
"    MUTEX();\n"
"    REDIS_CHECK_API_INITIALIZED();\n"
"\n"
"    std::vector<std::string> serialized_object_ids;\n"
"\n"
"    // Server is responsible for generate new OID but for that we need "
"switch ID\n"
"    // to be sent to server as well, so instead of sending empty oids we "
"will\n"
"    // send switch IDs\n"
"    for (uint32_t idx = 0; idx < object_count; idx++) {\n"
"        serialized_object_ids."
"emplace_back(sai_serialize_object_id(switch_id));\n"
"    }\n"
"    auto status = bulkCreate(object_type, serialized_object_ids, attr_count, "
"attr_list, mode, object_statuses);\n"
"\n"
"    // Since user requested create, OID value was created remotely and it "
"was returned in m_lastCreateOids\n"
"    for (uint32_t idx = 0; idx < object_count; idx++) {\n"
"        if (object_statuses[idx] == SAI_STATUS_SUCCESS) {\n"
"            object_id[idx] = m_lastCreateOids.at(idx);\n"
"        } else {\n"
"            object_id[idx] = SAI_NULL_OBJECT_ID;\n"
"        }\n"
"    }\n"
"\n"
"    return status;\n"
"}\n"
"\n"
"sai_status_t ClientSai::bulkCreate(\n"
"        _In_ sai_object_type_t object_type,\n"
"        _In_ const std::vector<std::string> &serialized_object_ids,\n"
"        _In_ const uint32_t *attr_count,\n"
"        _In_ const sai_attribute_t **attr_list,\n"
"        _In_ sai_bulk_op_error_mode_t mode,\n"
"        _Inout_ sai_status_t *object_statuses)\n"
"{\n"
"    ...\n"
"\n"
"    // Calling SAI serialize APIs to serialize all objects\n"
"    std::string str_object_type = sai_serialize_object_type(object_type);\n"
"    std::vector<swss::FieldValueTuple> entries;\n"
"    for (size_t idx = 0; idx < serialized_object_ids.size(); ++idx) {\n"
"        auto entry = SaiAttributeList::serialize_attr_list(object_type, "
"attr_count[idx], attr_list[idx], false);\n"
"        if (entry.empty()) {\n"
"            swss::FieldValueTuple null(\"NULL\", \"NULL\");\n"
"            entry.push_back(null);\n"
"        }\n"
"\n"
"        std::string str_attr = Globals::joinFieldValues(entry);\n"
"        swss::FieldValueTuple fvtNoStatus(serialized_object_ids[idx] , "
"str_attr);\n"
"        entries.push_back(fvtNoStatus);\n"
"    }\n"
"    std::string key = str_object_type + \":\" + std::to_string(entries."
"size());\n"
"\n"
"    // Send to syncd via the communication channel.\n"
"    m_communicationChannel->set(key, entries, "
"REDIS_ASIC_STATE_COMMAND_BULK_CREATE);\n"
"\n"
"    // Wait for response from syncd.\n"
"    return waitForBulkResponse(SAI_COMMON_API_BULK_CREATE, "
"(uint32_t)serialized_object_ids.size(), object_statuses);\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:1418
msgid ""
"最终，`ClientSai`会调用`m_communicationChannel->set()`，将序列化后的SAI对象发"
"送给`syncd`。而这个Channel，在202106版本之前，就是[基于Redis的ProducerTable]"
"(https://github.com/sonic-net/sonic-sairedis/blob/202106/lib/inc/"
"RedisChannel.h)了。可能是基于效率的考虑，从202111版本开始，这个Channel已经更"
"改为[ZMQ](https://github.com/sonic-net/sonic-sairedis/blob/202111/lib/"
"ZeroMQChannel.h)了。"
msgstr ""
"Eventually, `ClientSai` will call `m_communicationChannel->set()` to send "
"the serialized SAI object to `syncd`. And this Channel, before version "
"202106, was the [Redis-based ProducerTable](https://github.com/sonic-net/"
"sonic-sairedis/blob/202106/lib/inc/RedisChannel.h). This Channel has been "
"changed to [ZMQ](https://github.com/sonic-net/sonic-sairedis/blob/202111/lib/"
"ZeroMQChannel.h) since version 202111, probably due to efficiency "
"considerations."

#: src/5-2-2-bgp-route-update-workflow.md:1420
msgid ""
"```cpp\n"
"// File: https://github.com/sonic-net/sonic-sairedis/blob/202106/lib/inc/"
"RedisChannel.h\n"
"class RedisChannel: public Channel\n"
"{\n"
"    ...\n"
"\n"
"    /**\n"
"      * @brief Asic state channel.\n"
"      *\n"
"      * Used to sent commands like create/remove/set/get to syncd.\n"
"      */\n"
"    std::shared_ptr<swss::ProducerTable>  m_asicState;\n"
"\n"
"    ...\n"
"};\n"
"\n"
"// File: src/sonic-sairedis/lib/ClientSai.cpp\n"
"sai_status_t ClientSai::initialize(\n"
"        _In_ uint64_t flags,\n"
"        _In_ const sai_service_method_table_t *service_method_table)\n"
"{\n"
"    ...\n"
"    \n"
"    m_communicationChannel = std::make_shared<ZeroMQChannel>(\n"
"            cc->m_zmqEndpoint,\n"
"            cc->m_zmqNtfEndpoint,\n"
"            std::bind(&ClientSai::handleNotification, this, _1, _2, _3));\n"
"\n"
"    m_apiInitialized = true;\n"
"\n"
"    return SAI_STATUS_SUCCESS;\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: https://github.com/sonic-net/sonic-sairedis/blob/202106/lib/inc/"
"RedisChannel.h\n"
"class RedisChannel: public Channel\n"
"{\n"
"    ...\n"
"\n"
"    /**\n"
"      * @brief Asic state channel.\n"
"      *\n"
"      * Used to sent commands like create/remove/set/get to syncd.\n"
"      */\n"
"    std::shared_ptr<swss::ProducerTable>  m_asicState;\n"
"\n"
"    ...\n"
"};\n"
"\n"
"// File: src/sonic-sairedis/lib/ClientSai.cpp\n"
"sai_status_t ClientSai::initialize(\n"
"        _In_ uint64_t flags,\n"
"        _In_ const sai_service_method_table_t *service_method_table)\n"
"{\n"
"    ...\n"
"    \n"
"    m_communicationChannel = std::make_shared<ZeroMQChannel>(\n"
"            cc->m_zmqEndpoint,\n"
"            cc->m_zmqNtfEndpoint,\n"
"            std::bind(&ClientSai::handleNotification, this, _1, _2, _3));\n"
"\n"
"    m_apiInitialized = true;\n"
"\n"
"    return SAI_STATUS_SUCCESS;\n"
"}\n"
"```"

#: src/5-2-2-bgp-route-update-workflow.md:1454
msgid ""
"关于进程通信的方法，这里就不再赘述了，大家可以参考第四章描述的[进程间的通信机"
"制](./4-2-2-redis-messaging-layer.html)。"
msgstr ""
"For more information about the method of process communication, you can "
"refer to [Inter-process communication mechanism] described in Chapter 4 "
"(. /4-2-2-redis-messaging-layer.html)."

#: src/5-2-2-bgp-route-update-workflow.md:1456
msgid "### syncd更新ASIC"
msgstr "### syncd update ASIC"

#: src/5-2-2-bgp-route-update-workflow.md:1458
msgid ""
"最后，当SAI对象生成好并发送给`syncd`后，`syncd`会接收，处理，更新ASIC_DB，最"
"后更新ASIC。这一段的工作流，我们已经在[Syncd-SAI工作流](./5-1-syncd-sai-"
"workflow.html)中详细介绍过了，这里就不再赘述了，大家可以移步去查看。"
msgstr ""
"Finally, when the SAI object is generated and sent to `syncd`, `syncd` will "
"receive it, process it, update ASIC_DB, and finally update ASIC. /5-1-syncd-"
"sai-workflow.html) in detail, so we won't repeat it here, you can move to "
"check it out."

#: src/5-2-2-bgp-route-update-workflow.md:1462
msgid ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [Github repo: sonic-swss][SONiCSWSS]\n"
"3. [Github repo: sonic-swss-common][SONiCSWSSCommon]\n"
"4. [Github repo: sonic-frr][SONiCFRR]\n"
"5. [Github repo: sonic-utilities][SONiCUtil]\n"
"6. [Github repo: sonic-sairedis][SONiCSAIRedis]\n"
"7. [RFC 4271: A Border Gateway Protocol 4 (BGP-4)][BGP]\n"
"8. [FRRouting][FRRouting]\n"
"9.  [FRRouting - BGP][BGP]\n"
"10. [FRRouting - FPM][FPM]\n"
"11. [Understanding EVPN Pure Type 5 Routes][EVPN]"
msgstr ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [Github repo: sonic-swss][SONiCSWSS]\n"
"3. [Github repo: sonic-swss-common][SONiCSWSSCommon]\n"
"4. [Github repo: sonic-frr][SONiCFRR]\n"
"5. [Github repo: sonic-utilities][SONiCUtil]\n"
"6. [Github repo: sonic-sairedis][SONiCSAIRedis]\n"
"7. [RFC 4271: A Border Gateway Protocol 4 (BGP-4)][BGP]\n"
"8. [FRRouting][FRRouting]\n"
"9.  [FRRouting - BGP][BGP]\n"
"10. [FRRouting - FPM][FPM]\n"
"11. [Understanding EVPN Pure Type 5 Routes][EVPN]"

#: src/6-boot.md:1
msgid "# 启动流程"
msgstr "# Boot"

#: src/6-1-cold-boot.md:1
msgid "# 冷启动"
msgstr "# Cold boot "

#: src/6-2-fast-boot.md:1
msgid "# 快速启动"
msgstr "# Fast boot"

#: src/6-3-warm-boot.md:1
msgid "# 热启动"
msgstr "# Warm boot"
